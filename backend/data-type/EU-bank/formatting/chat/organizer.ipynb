{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f90431ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MongoDB...\n",
      "Database: sparzaai\n",
      "🚀 Starting chat chunk-cluster matching process...\n",
      "This will match chat chunks to clusters with data: 'chat-chunks'\n",
      "============================================================\n",
      "✓ Database connection successful\n",
      "\n",
      "Fetching clusters with data: 'chat-chunks'...\n",
      "Found 10 clusters with data='chat-chunks' to process\n",
      "\n",
      "Processing Cluster ID: 0\n",
      "Cluster Name: Workforce & HR Management\n",
      "Keyphrases: ['Shift Coverage Request', 'Training Schedule Update', 'Performance Review Planning', 'Break Schedule Coordination', 'Overtime Approval Need', 'Team Meeting Reminder', 'Staff Management Discussion', 'Workforce Planning Update', 'Employee Relations Coordination', 'Attendance Management Alert', 'Leave Request Approval', 'Skill Development Update']\n",
      "Normalized keyphrases: ['shift coverage request', 'training schedule update', 'performance review planning', 'break schedule coordination', 'overtime approval need', 'team meeting reminder', 'staff management discussion', 'workforce planning update', 'employee relations coordination', 'attendance management alert', 'leave request approval', 'skill development update']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525233508dc58e3ead36 - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8525333508dc58e3ead39 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8525433508dc58e3ead3c - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8525733508dc58e3ead42 - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a8525833508dc58e3ead45 - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8525a33508dc58e3ead4b - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8525c33508dc58e3ead51 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8525d33508dc58e3ead53 - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a8525e33508dc58e3ead57 - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a8526033508dc58e3ead5d - Topic: 'Overtime Approval Need' matches keyphrase: 'overtime approval need'\n",
      "    Match found: 68a8526133508dc58e3ead5e - Topic: 'Training Schedule Update' matches keyphrase: 'training schedule update'\n",
      "    Match found: 68a8526233508dc58e3ead61 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8526333508dc58e3ead63 - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a8526833508dc58e3ead70 - Topic: 'Leave Request Approval' matches keyphrase: 'leave request approval'\n",
      "    Match found: 68a8526b33508dc58e3ead79 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8526c33508dc58e3ead7b - Topic: 'Leave Request Approval' matches keyphrase: 'leave request approval'\n",
      "    Match found: 68a8526d33508dc58e3ead7e - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8526f33508dc58e3ead85 - Topic: 'Performance Review Planning' matches keyphrase: 'performance review planning'\n",
      "    Match found: 68a8527033508dc58e3ead88 - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a8527133508dc58e3ead8b - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8527633508dc58e3ead98 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8527733508dc58e3ead9a - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8527a33508dc58e3eada1 - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8527b33508dc58e3eada4 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8527d33508dc58e3eada8 - Topic: 'Performance Review Planning' matches keyphrase: 'performance review planning'\n",
      "    Match found: 68a8528333508dc58e3eadb3 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8528a33508dc58e3eadc7 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8528b33508dc58e3eadc9 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8528c33508dc58e3eadcc - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a8528e33508dc58e3eadd0 - Topic: 'Performance Review Planning' matches keyphrase: 'performance review planning'\n",
      "    Match found: 68a8529433508dc58e3eade2 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8529733508dc58e3eade9 - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a8529b33508dc58e3eadf4 - Topic: 'Leave Request Approval' matches keyphrase: 'leave request approval'\n",
      "    Match found: 68a8529b33508dc58e3eadf5 - Topic: 'Performance Review Planning' matches keyphrase: 'performance review planning'\n",
      "    Match found: 68a8529c33508dc58e3eadf8 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8529e33508dc58e3eadfd - Topic: 'Overtime Approval Need' matches keyphrase: 'overtime approval need'\n",
      "    Match found: 68a852a333508dc58e3eae0b - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a852a433508dc58e3eae0e - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a852a533508dc58e3eae0f - Topic: 'Leave Request Approval' matches keyphrase: 'leave request approval'\n",
      "    Match found: 68a852a833508dc58e3eae18 - Topic: 'Staff Management Discussion' matches keyphrase: 'staff management discussion'\n",
      "    Match found: 68a852ad33508dc58e3eae24 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a852af33508dc58e3eae2b - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852b033508dc58e3eae2c - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852b033508dc58e3eae2e - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a852b133508dc58e3eae31 - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852bc33508dc58e3eae4b - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a852bc33508dc58e3eae4c - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852bf33508dc58e3eae55 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a852c333508dc58e3eae5f - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a852c733508dc58e3eae69 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a852c933508dc58e3eae6f - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a852ce33508dc58e3eae7a - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852cf33508dc58e3eae7c - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a852d033508dc58e3eae7e - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a852d033508dc58e3eae7f - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a852d433508dc58e3eae87 - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a852d533508dc58e3eae8a - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a852d733508dc58e3eae91 - Topic: 'Shift Coverage Request' matches keyphrase: 'shift coverage request'\n",
      "    Match found: 68a852d833508dc58e3eae93 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a852d833508dc58e3eae94 - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852e233508dc58e3eaeae - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a852e433508dc58e3eaeb3 - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852e633508dc58e3eaeb8 - Topic: 'Skill Development Update' matches keyphrase: 'skill development update'\n",
      "    Match found: 68a852e933508dc58e3eaec1 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a852eb33508dc58e3eaec6 - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a852ec33508dc58e3eaec9 - Topic: 'Training Schedule Update' matches keyphrase: 'training schedule update'\n",
      "    Match found: 68a852f033508dc58e3eaed4 - Topic: 'Training Schedule Update' matches keyphrase: 'training schedule update'\n",
      "    Match found: 68a852f233508dc58e3eaed9 - Topic: 'Staff Management Discussion' matches keyphrase: 'staff management discussion'\n",
      "    Match found: 68a852f733508dc58e3eaee5 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a852f833508dc58e3eaee7 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a852f933508dc58e3eaeea - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a852fa33508dc58e3eaeeb - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a852fb33508dc58e3eaef0 - Topic: 'Employee Relations Coordination' matches keyphrase: 'employee relations coordination'\n",
      "    Match found: 68a8530233508dc58e3eaeff - Topic: 'Staff Management Discussion' matches keyphrase: 'staff management discussion'\n",
      "    Match found: 68a8530233508dc58e3eaf00 - Topic: 'Overtime Approval Need' matches keyphrase: 'overtime approval need'\n",
      "    Match found: 68a8530633508dc58e3eaf09 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8530933508dc58e3eaf12 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8530b33508dc58e3eaf15 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8530c33508dc58e3eaf19 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8531133508dc58e3eaf25 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8531333508dc58e3eaf2a - Topic: 'Overtime Approval Need' matches keyphrase: 'overtime approval need'\n",
      "    Match found: 68a8531633508dc58e3eaf34 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8531733508dc58e3eaf35 - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a8531733508dc58e3eaf36 - Topic: 'Leave Request Approval' matches keyphrase: 'leave request approval'\n",
      "    Match found: 68a8531933508dc58e3eaf3c - Topic: 'Overtime Approval Need' matches keyphrase: 'overtime approval need'\n",
      "    Match found: 68a8531e33508dc58e3eaf48 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8532233508dc58e3eaf54 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8532333508dc58e3eaf57 - Topic: 'Attendance Management Alert' matches keyphrase: 'attendance management alert'\n",
      "    Match found: 68a8532433508dc58e3eaf58 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8532733508dc58e3eaf60 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8532933508dc58e3eaf65 - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a8532933508dc58e3eaf66 - Topic: 'Workforce Planning Update' matches keyphrase: 'workforce planning update'\n",
      "    Match found: 68a8532a33508dc58e3eaf67 - Topic: 'Team Meeting Reminder' matches keyphrase: 'team meeting reminder'\n",
      "    Match found: 68a8532b33508dc58e3eaf6a - Topic: 'Performance Review Planning' matches keyphrase: 'performance review planning'\n",
      "    Match found: 68a8532e33508dc58e3eaf71 - Topic: 'Staff Management Discussion' matches keyphrase: 'staff management discussion'\n",
      "    Match found: 68a8533333508dc58e3eaf7d - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a8533433508dc58e3eaf7f - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "    Match found: 68a8533533508dc58e3eaf82 - Topic: 'Break Schedule Coordination' matches keyphrase: 'break schedule coordination'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 0 with 98 chat chunk IDs\n",
      "  Total unique chat chunks matched: 98\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 1\n",
      "Cluster Name: IT Infrastructure & Systems\n",
      "Keyphrases: ['System Status Alert', 'Network Performance Issue', 'Application Server Warning', 'Authentication Service Down', 'Technology Rollout Update', 'System Integration Progress']\n",
      "Normalized keyphrases: ['system status alert', 'network performance issue', 'application server warning', 'authentication service down', 'technology rollout update', 'system integration progress']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525433508dc58e3ead3b - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8525933508dc58e3ead48 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "    Match found: 68a8525b33508dc58e3ead4f - Topic: 'Technology Rollout Update' matches keyphrase: 'technology rollout update'\n",
      "    Match found: 68a8526533508dc58e3ead69 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8526933508dc58e3ead74 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "    Match found: 68a8526d33508dc58e3ead7f - Topic: 'Application Server Warning' matches keyphrase: 'application server warning'\n",
      "    Match found: 68a8527533508dc58e3ead95 - Topic: 'Application Server Warning' matches keyphrase: 'application server warning'\n",
      "    Match found: 68a8527d33508dc58e3eada9 - Topic: 'Technology Rollout Update' matches keyphrase: 'technology rollout update'\n",
      "    Match found: 68a8528533508dc58e3eadb9 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8528633508dc58e3eadbd - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8528933508dc58e3eadc4 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a8528a33508dc58e3eadc5 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8528f33508dc58e3eadd4 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8529233508dc58e3eaddc - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8529c33508dc58e3eadf6 - Topic: 'System Integration Progress' matches keyphrase: 'system integration progress'\n",
      "    Match found: 68a852a233508dc58e3eae07 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a852a733508dc58e3eae16 - Topic: 'Technology Rollout Update' matches keyphrase: 'technology rollout update'\n",
      "    Match found: 68a852aa33508dc58e3eae1c - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a852ae33508dc58e3eae29 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "    Match found: 68a852b333508dc58e3eae36 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a852bd33508dc58e3eae50 - Topic: 'Technology Rollout Update' matches keyphrase: 'technology rollout update'\n",
      "    Match found: 68a852c433508dc58e3eae62 - Topic: 'Technology Rollout Update' matches keyphrase: 'technology rollout update'\n",
      "    Match found: 68a852c433508dc58e3eae63 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a852c533508dc58e3eae64 - Topic: 'Technology Rollout Update' matches keyphrase: 'technology rollout update'\n",
      "    Match found: 68a852ca33508dc58e3eae71 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a852cb33508dc58e3eae73 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a852cb33508dc58e3eae74 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a852d233508dc58e3eae83 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "    Match found: 68a852d833508dc58e3eae92 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a852da33508dc58e3eae98 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a852db33508dc58e3eae9b - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a852ed33508dc58e3eaeca - Topic: 'System Integration Progress' matches keyphrase: 'system integration progress'\n",
      "    Match found: 68a852f533508dc58e3eaedf - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a852fd33508dc58e3eaef4 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8530333508dc58e3eaf01 - Topic: 'Application Server Warning' matches keyphrase: 'application server warning'\n",
      "    Match found: 68a8530c33508dc58e3eaf18 - Topic: 'Application Server Warning' matches keyphrase: 'application server warning'\n",
      "    Match found: 68a8530f33508dc58e3eaf20 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a8531033508dc58e3eaf22 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "    Match found: 68a8531533508dc58e3eaf31 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8531b33508dc58e3eaf41 - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8531c33508dc58e3eaf43 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a8531f33508dc58e3eaf4c - Topic: 'System Integration Progress' matches keyphrase: 'system integration progress'\n",
      "    Match found: 68a8532133508dc58e3eaf51 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "    Match found: 68a8532a33508dc58e3eaf69 - Topic: 'System Status Alert' matches keyphrase: 'system status alert'\n",
      "    Match found: 68a8532c33508dc58e3eaf6e - Topic: 'Network Performance Issue' matches keyphrase: 'network performance issue'\n",
      "    Match found: 68a8533533508dc58e3eaf81 - Topic: 'Authentication Service Down' matches keyphrase: 'authentication service down'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 1 with 46 chat chunk IDs\n",
      "  Total unique chat chunks matched: 46\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 2\n",
      "Cluster Name: IT Security & Support\n",
      "Keyphrases: ['Database Access Problem', 'Security Protocol Change', 'Hardware Troubleshooting Help', 'Software Issue Resolution', 'User Access Problem', 'Cybersecurity Alert Warning']\n",
      "Normalized keyphrases: ['database access problem', 'security protocol change', 'hardware troubleshooting help', 'software issue resolution', 'user access problem', 'cybersecurity alert warning']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525133508dc58e3ead34 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8525733508dc58e3ead44 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8525833508dc58e3ead47 - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a8525f33508dc58e3ead58 - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8526833508dc58e3ead71 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8526933508dc58e3ead75 - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a8526e33508dc58e3ead81 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a8527333508dc58e3ead8f - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a8527433508dc58e3ead92 - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a8527833508dc58e3ead9d - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a8527e33508dc58e3eadad - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a8528533508dc58e3eadb8 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8528733508dc58e3eadbe - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a8528e33508dc58e3eadd2 - Topic: 'User Access Problem' matches keyphrase: 'user access problem'\n",
      "    Match found: 68a8529433508dc58e3eade1 - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8529633508dc58e3eade8 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8529733508dc58e3eadea - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8529833508dc58e3eadec - Topic: 'User Access Problem' matches keyphrase: 'user access problem'\n",
      "    Match found: 68a8529833508dc58e3eaded - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8529c33508dc58e3eadf7 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852a733508dc58e3eae15 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852a833508dc58e3eae17 - Topic: 'User Access Problem' matches keyphrase: 'user access problem'\n",
      "    Match found: 68a852aa33508dc58e3eae1e - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a852ad33508dc58e3eae25 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a852b233508dc58e3eae32 - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a852b833508dc58e3eae40 - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a852b933508dc58e3eae44 - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a852be33508dc58e3eae51 - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a852c233508dc58e3eae5d - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a852c433508dc58e3eae61 - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a852cd33508dc58e3eae79 - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a852ce33508dc58e3eae7b - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a852d633508dc58e3eae8d - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a852dc33508dc58e3eae9d - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a852dc33508dc58e3eae9e - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a852df33508dc58e3eaea7 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a852e233508dc58e3eaead - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852e533508dc58e3eaeb7 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a852ec33508dc58e3eaec8 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852ee33508dc58e3eaecf - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a852ef33508dc58e3eaed0 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852f033508dc58e3eaed2 - Topic: 'User Access Problem' matches keyphrase: 'user access problem'\n",
      "    Match found: 68a852f033508dc58e3eaed3 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852f633508dc58e3eaee1 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a852f633508dc58e3eaee2 - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a852f733508dc58e3eaee3 - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a8530033508dc58e3eaefd - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8530d33508dc58e3eaf1b - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a8531033508dc58e3eaf23 - Topic: 'User Access Problem' matches keyphrase: 'user access problem'\n",
      "    Match found: 68a8531233508dc58e3eaf27 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8531233508dc58e3eaf28 - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a8531433508dc58e3eaf2d - Topic: 'Hardware Troubleshooting Help' matches keyphrase: 'hardware troubleshooting help'\n",
      "    Match found: 68a8531d33508dc58e3eaf45 - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "    Match found: 68a8531f33508dc58e3eaf4b - Topic: 'Cybersecurity Alert Warning' matches keyphrase: 'cybersecurity alert warning'\n",
      "    Match found: 68a8532033508dc58e3eaf4f - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8532333508dc58e3eaf56 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8532d33508dc58e3eaf6f - Topic: 'Security Protocol Change' matches keyphrase: 'security protocol change'\n",
      "    Match found: 68a8533833508dc58e3eaf89 - Topic: 'Software Issue Resolution' matches keyphrase: 'software issue resolution'\n",
      "    Match found: 68a8533833508dc58e3eaf8a - Topic: 'Database Access Problem' matches keyphrase: 'database access problem'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 2 with 59 chat chunk IDs\n",
      "  Total unique chat chunks matched: 59\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 3\n",
      "Cluster Name: Operational Processes & Workflow\n",
      "Keyphrases: ['Process Coordination Discussion', 'Workflow Optimization Alert', 'Quality Standard Reminder', 'Case Management Discussion', 'Knowledge Management Update', 'Team Coordination Update', 'Daily Operational Procedure']\n",
      "Normalized keyphrases: ['process coordination discussion', 'workflow optimization alert', 'quality standard reminder', 'case management discussion', 'knowledge management update', 'team coordination update', 'daily operational procedure']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525533508dc58e3ead3f - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a8525d33508dc58e3ead54 - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a8526433508dc58e3ead65 - Topic: 'Workflow Optimization Alert' matches keyphrase: 'workflow optimization alert'\n",
      "    Match found: 68a8526c33508dc58e3ead7d - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a8527133508dc58e3ead8a - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8527233508dc58e3ead8c - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8527233508dc58e3ead8e - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a8527633508dc58e3ead96 - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a8527c33508dc58e3eada6 - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a8527e33508dc58e3eadac - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a8528233508dc58e3eadb1 - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a8528233508dc58e3eadb2 - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a8528533508dc58e3eadba - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a8528633508dc58e3eadbb - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8528d33508dc58e3eadce - Topic: 'Workflow Optimization Alert' matches keyphrase: 'workflow optimization alert'\n",
      "    Match found: 68a8529033508dc58e3eadd6 - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a8529033508dc58e3eadd8 - Topic: 'Workflow Optimization Alert' matches keyphrase: 'workflow optimization alert'\n",
      "    Match found: 68a8529233508dc58e3eaddd - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a852a133508dc58e3eae05 - Topic: 'Process Coordination Discussion' matches keyphrase: 'process coordination discussion'\n",
      "    Match found: 68a852a333508dc58e3eae0a - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a852a433508dc58e3eae0c - Topic: 'Workflow Optimization Alert' matches keyphrase: 'workflow optimization alert'\n",
      "    Match found: 68a852a433508dc58e3eae0d - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a852ab33508dc58e3eae20 - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a852ae33508dc58e3eae28 - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a852b133508dc58e3eae2f - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a852b133508dc58e3eae30 - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a852b233508dc58e3eae33 - Topic: 'Process Coordination Discussion' matches keyphrase: 'process coordination discussion'\n",
      "    Match found: 68a852b333508dc58e3eae37 - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a852b733508dc58e3eae3e - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a852b733508dc58e3eae3f - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a852be33508dc58e3eae53 - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a852bf33508dc58e3eae56 - Topic: 'Process Coordination Discussion' matches keyphrase: 'process coordination discussion'\n",
      "    Match found: 68a852c733508dc58e3eae6a - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a852c833508dc58e3eae6c - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a852c833508dc58e3eae6d - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a852db33508dc58e3eae9a - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a852dc33508dc58e3eae9f - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a852dd33508dc58e3eaea0 - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a852e233508dc58e3eaeaf - Topic: 'Process Coordination Discussion' matches keyphrase: 'process coordination discussion'\n",
      "    Match found: 68a852ea33508dc58e3eaec3 - Topic: 'Process Coordination Discussion' matches keyphrase: 'process coordination discussion'\n",
      "    Match found: 68a852eb33508dc58e3eaec7 - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a852ed33508dc58e3eaecb - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a852f833508dc58e3eaee6 - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a852fd33508dc58e3eaef3 - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a8530033508dc58e3eaefb - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a8530133508dc58e3eaefe - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a8530433508dc58e3eaf04 - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8530533508dc58e3eaf07 - Topic: 'Workflow Optimization Alert' matches keyphrase: 'workflow optimization alert'\n",
      "    Match found: 68a8531133508dc58e3eaf26 - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8531433508dc58e3eaf2e - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8531833508dc58e3eaf38 - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a8531933508dc58e3eaf3a - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a8531d33508dc58e3eaf47 - Topic: 'Case Management Discussion' matches keyphrase: 'case management discussion'\n",
      "    Match found: 68a8532333508dc58e3eaf55 - Topic: 'Daily Operational Procedure' matches keyphrase: 'daily operational procedure'\n",
      "    Match found: 68a8532833508dc58e3eaf64 - Topic: 'Workflow Optimization Alert' matches keyphrase: 'workflow optimization alert'\n",
      "    Match found: 68a8532c33508dc58e3eaf6c - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "    Match found: 68a8532d33508dc58e3eaf70 - Topic: 'Team Coordination Update' matches keyphrase: 'team coordination update'\n",
      "    Match found: 68a8533033508dc58e3eaf75 - Topic: 'Quality Standard Reminder' matches keyphrase: 'quality standard reminder'\n",
      "    Match found: 68a8533133508dc58e3eaf79 - Topic: 'Knowledge Management Update' matches keyphrase: 'knowledge management update'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 3 with 59 chat chunk IDs\n",
      "  Total unique chat chunks matched: 59\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 4\n",
      "Cluster Name: Compliance & Policy\n",
      "Keyphrases: ['Policy Clarification Request', 'Compliance Training Reminder', 'GDPR Access Request', 'Regulatory Update Alert', 'Regulatory Examination Preparation', 'Regulatory Response Management', 'Compliance Monitoring Update']\n",
      "Normalized keyphrases: ['policy clarification request', 'compliance training reminder', 'gdpr access request', 'regulatory update alert', 'regulatory examination preparation', 'regulatory response management', 'compliance monitoring update']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525333508dc58e3ead38 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8525b33508dc58e3ead4d - Topic: 'Compliance Training Reminder' matches keyphrase: 'compliance training reminder'\n",
      "    Match found: 68a8525b33508dc58e3ead4e - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8525c33508dc58e3ead52 - Topic: 'Policy Clarification Request' matches keyphrase: 'policy clarification request'\n",
      "    Match found: 68a8526b33508dc58e3ead7a - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a8527633508dc58e3ead97 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a8527933508dc58e3ead9e - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8527e33508dc58e3eadab - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8527f33508dc58e3eadae - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8528933508dc58e3eadc3 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a8528b33508dc58e3eadc8 - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a8528c33508dc58e3eadcb - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a8528d33508dc58e3eadcf - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a8529333508dc58e3eade0 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8529633508dc58e3eade7 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8529933508dc58e3eadf0 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8529a33508dc58e3eadf1 - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a8529a33508dc58e3eadf2 - Topic: 'Compliance Training Reminder' matches keyphrase: 'compliance training reminder'\n",
      "    Match found: 68a8529f33508dc58e3eae00 - Topic: 'Compliance Training Reminder' matches keyphrase: 'compliance training reminder'\n",
      "    Match found: 68a852a133508dc58e3eae06 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a852aa33508dc58e3eae1d - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a852ad33508dc58e3eae26 - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a852b333508dc58e3eae35 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a852b533508dc58e3eae3a - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a852c133508dc58e3eae59 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a852c633508dc58e3eae67 - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a852cb33508dc58e3eae75 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a852d933508dc58e3eae96 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a852da33508dc58e3eae99 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a852db33508dc58e3eae9c - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a852dd33508dc58e3eaea1 - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a852e033508dc58e3eaea9 - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a852e433508dc58e3eaeb4 - Topic: 'Compliance Training Reminder' matches keyphrase: 'compliance training reminder'\n",
      "    Match found: 68a852e833508dc58e3eaebd - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a852e933508dc58e3eaec0 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a852ea33508dc58e3eaec2 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a852ea33508dc58e3eaec4 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a852f433508dc58e3eaedd - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a852f933508dc58e3eaee9 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a852fa33508dc58e3eaeec - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a852fb33508dc58e3eaeef - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a852fc33508dc58e3eaef1 - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a852fc33508dc58e3eaef2 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8530033508dc58e3eaefc - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8530333508dc58e3eaf02 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8530733508dc58e3eaf0c - Topic: 'Policy Clarification Request' matches keyphrase: 'policy clarification request'\n",
      "    Match found: 68a8530733508dc58e3eaf0e - Topic: 'Compliance Training Reminder' matches keyphrase: 'compliance training reminder'\n",
      "    Match found: 68a8530833508dc58e3eaf0f - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8530a33508dc58e3eaf13 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8530b33508dc58e3eaf16 - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a8531633508dc58e3eaf32 - Topic: 'Policy Clarification Request' matches keyphrase: 'policy clarification request'\n",
      "    Match found: 68a8531833508dc58e3eaf37 - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a8531a33508dc58e3eaf3e - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a8531a33508dc58e3eaf3f - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8531c33508dc58e3eaf42 - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "    Match found: 68a8531e33508dc58e3eaf49 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8532433508dc58e3eaf59 - Topic: 'Regulatory Update Alert' matches keyphrase: 'regulatory update alert'\n",
      "    Match found: 68a8532a33508dc58e3eaf68 - Topic: 'GDPR Access Request' matches keyphrase: 'gdpr access request'\n",
      "    Match found: 68a8533133508dc58e3eaf78 - Topic: 'Compliance Monitoring Update' matches keyphrase: 'compliance monitoring update'\n",
      "    Match found: 68a8533233508dc58e3eaf7b - Topic: 'Regulatory Examination Preparation' matches keyphrase: 'regulatory examination preparation'\n",
      "    Match found: 68a8533633508dc58e3eaf83 - Topic: 'Regulatory Response Management' matches keyphrase: 'regulatory response management'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 4 with 61 chat chunk IDs\n",
      "  Total unique chat chunks matched: 61\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 5\n",
      "Cluster Name: Internal Audit & Reporting\n",
      "Keyphrases: ['Audit Coordination Schedule', 'Monthly Compliance Audit', 'Audit Feedback Review', 'Compliance Report Generation', 'Audit Planning Coordination', 'Audit Finding Resolution']\n",
      "Normalized keyphrases: ['audit coordination schedule', 'monthly compliance audit', 'audit feedback review', 'compliance report generation', 'audit planning coordination', 'audit finding resolution']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525133508dc58e3ead35 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8525533508dc58e3ead3d - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a8525533508dc58e3ead3e - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8525633508dc58e3ead40 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8525633508dc58e3ead41 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8525733508dc58e3ead43 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8525a33508dc58e3ead4c - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8525c33508dc58e3ead50 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8525d33508dc58e3ead55 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8525e33508dc58e3ead56 - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a8526033508dc58e3ead5b - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8526133508dc58e3ead5f - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8526533508dc58e3ead68 - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a8526933508dc58e3ead73 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8526c33508dc58e3ead7c - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a8527133508dc58e3ead89 - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8527433508dc58e3ead93 - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8527833508dc58e3ead9c - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8527b33508dc58e3eada5 - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8527c33508dc58e3eada7 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8528433508dc58e3eadb7 - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8528a33508dc58e3eadc6 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8528f33508dc58e3eadd5 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8529533508dc58e3eade4 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8529b33508dc58e3eadf3 - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a852a033508dc58e3eae03 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a852a533508dc58e3eae10 - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a852a533508dc58e3eae11 - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a852ab33508dc58e3eae21 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a852b033508dc58e3eae2d - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a852b433508dc58e3eae39 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a852b933508dc58e3eae43 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a852ba33508dc58e3eae46 - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a852ba33508dc58e3eae47 - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a852bc33508dc58e3eae4d - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a852be33508dc58e3eae52 - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a852c033508dc58e3eae57 - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a852c233508dc58e3eae5c - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a852c933508dc58e3eae6e - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a852cf33508dc58e3eae7d - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a852d033508dc58e3eae80 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a852d433508dc58e3eae88 - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a852d733508dc58e3eae8f - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a852d733508dc58e3eae90 - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a852de33508dc58e3eaea4 - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a852df33508dc58e3eaea5 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a852e033508dc58e3eaea8 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a852e133508dc58e3eaeab - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a852e733508dc58e3eaeba - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a852e733508dc58e3eaebc - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a852f133508dc58e3eaed5 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8530333508dc58e3eaf03 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8530633508dc58e3eaf0a - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8530733508dc58e3eaf0d - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8530f33508dc58e3eaf21 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8531233508dc58e3eaf29 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8531533508dc58e3eaf2f - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a8531933508dc58e3eaf3b - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a8531d33508dc58e3eaf46 - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8532033508dc58e3eaf4d - Topic: 'Audit Finding Resolution' matches keyphrase: 'audit finding resolution'\n",
      "    Match found: 68a8532033508dc58e3eaf4e - Topic: 'Compliance Report Generation' matches keyphrase: 'compliance report generation'\n",
      "    Match found: 68a8532233508dc58e3eaf52 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8532533508dc58e3eaf5a - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "    Match found: 68a8532633508dc58e3eaf5d - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a8532e33508dc58e3eaf72 - Topic: 'Audit Planning Coordination' matches keyphrase: 'audit planning coordination'\n",
      "    Match found: 68a8533033508dc58e3eaf77 - Topic: 'Audit Coordination Schedule' matches keyphrase: 'audit coordination schedule'\n",
      "    Match found: 68a8533433508dc58e3eaf80 - Topic: 'Audit Feedback Review' matches keyphrase: 'audit feedback review'\n",
      "    Match found: 68a8533633508dc58e3eaf85 - Topic: 'Monthly Compliance Audit' matches keyphrase: 'monthly compliance audit'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 5 with 68 chat chunk IDs\n",
      "  Total unique chat chunks matched: 68\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 6\n",
      "Cluster Name: Risk & Control Management\n",
      "Keyphrases: ['Risk Assessment Update', 'Risk Assessment Documentation', 'Control Testing Validation', 'Compliance Gap Remediation']\n",
      "Normalized keyphrases: ['risk assessment update', 'risk assessment documentation', 'control testing validation', 'compliance gap remediation']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525233508dc58e3ead37 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a8525833508dc58e3ead46 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a8526a33508dc58e3ead77 - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a8526d33508dc58e3ead80 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a8526e33508dc58e3ead82 - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a8527333508dc58e3ead90 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a8528333508dc58e3eadb4 - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a8528433508dc58e3eadb6 - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a8528633508dc58e3eadbc - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a8528f33508dc58e3eadd3 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a8529033508dc58e3eadd7 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a8529133508dc58e3eadd9 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a8529733508dc58e3eadeb - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a852a033508dc58e3eae02 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a852a333508dc58e3eae09 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852ac33508dc58e3eae22 - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a852b233508dc58e3eae34 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852b933508dc58e3eae45 - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a852c033508dc58e3eae58 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a852c333508dc58e3eae60 - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a852c533508dc58e3eae66 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852cc33508dc58e3eae76 - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a852cc33508dc58e3eae78 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a852d133508dc58e3eae81 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852d633508dc58e3eae8e - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852d933508dc58e3eae95 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852e133508dc58e3eaeaa - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a852e133508dc58e3eaeac - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852e933508dc58e3eaebf - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a852f133508dc58e3eaed6 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a852fb33508dc58e3eaeee - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a8530a33508dc58e3eaf14 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a8531433508dc58e3eaf2c - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a8531b33508dc58e3eaf40 - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a8531f33508dc58e3eaf4a - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a8532233508dc58e3eaf53 - Topic: 'Control Testing Validation' matches keyphrase: 'control testing validation'\n",
      "    Match found: 68a8532e33508dc58e3eaf73 - Topic: 'Risk Assessment Update' matches keyphrase: 'risk assessment update'\n",
      "    Match found: 68a8532f33508dc58e3eaf74 - Topic: 'Compliance Gap Remediation' matches keyphrase: 'compliance gap remediation'\n",
      "    Match found: 68a8533033508dc58e3eaf76 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "    Match found: 68a8533733508dc58e3eaf88 - Topic: 'Risk Assessment Documentation' matches keyphrase: 'risk assessment documentation'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 6 with 40 chat chunk IDs\n",
      "  Total unique chat chunks matched: 40\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 7\n",
      "Cluster Name: Business & Financial Planning\n",
      "Keyphrases: ['Budget Management Discussion', 'Financial Reporting Procedure', 'Performance Metric Tracking', 'Business Continuity Activation', 'Cross-Department Project Update']\n",
      "Normalized keyphrases: ['budget management discussion', 'financial reporting procedure', 'performance metric tracking', 'business continuity activation', 'crossdepartment project update']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525133508dc58e3ead33 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8525f33508dc58e3ead59 - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a8526433508dc58e3ead67 - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "    Match found: 68a8526633508dc58e3ead6b - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8526633508dc58e3ead6d - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8526733508dc58e3ead6e - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8526733508dc58e3ead6f - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8526833508dc58e3ead72 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8526b33508dc58e3ead78 - Topic: 'Business Continuity Activation' matches keyphrase: 'business continuity activation'\n",
      "    Match found: 68a8526e33508dc58e3ead83 - Topic: 'Business Continuity Activation' matches keyphrase: 'business continuity activation'\n",
      "    Match found: 68a8527233508dc58e3ead8d - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a8528433508dc58e3eadb5 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8528833508dc58e3eadc2 - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8528e33508dc58e3eadd1 - Topic: 'Business Continuity Activation' matches keyphrase: 'business continuity activation'\n",
      "    Match found: 68a8529d33508dc58e3eadfa - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8529f33508dc58e3eadff - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a852a233508dc58e3eae08 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a852a633508dc58e3eae13 - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "    Match found: 68a852b833508dc58e3eae41 - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "    Match found: 68a852bb33508dc58e3eae49 - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a852bf33508dc58e3eae54 - Topic: 'Business Continuity Activation' matches keyphrase: 'business continuity activation'\n",
      "    Match found: 68a852c133508dc58e3eae5b - Topic: 'Business Continuity Activation' matches keyphrase: 'business continuity activation'\n",
      "    Match found: 68a852c533508dc58e3eae65 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a852c733508dc58e3eae6b - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a852d233508dc58e3eae82 - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a852d333508dc58e3eae86 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a852d533508dc58e3eae8b - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a852de33508dc58e3eaea2 - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a852df33508dc58e3eaea6 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a852e333508dc58e3eaeb1 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a852ee33508dc58e3eaecd - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a852ee33508dc58e3eaece - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "    Match found: 68a852f433508dc58e3eaedc - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a852f533508dc58e3eaee0 - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a852ff33508dc58e3eaefa - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "    Match found: 68a8530833508dc58e3eaf10 - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8530c33508dc58e3eaf17 - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8530d33508dc58e3eaf1a - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8530d33508dc58e3eaf1c - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a8530e33508dc58e3eaf1d - Topic: 'Financial Reporting Procedure' matches keyphrase: 'financial reporting procedure'\n",
      "    Match found: 68a8531333508dc58e3eaf2b - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8531533508dc58e3eaf30 - Topic: 'Performance Metric Tracking' matches keyphrase: 'performance metric tracking'\n",
      "    Match found: 68a8531c33508dc58e3eaf44 - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "    Match found: 68a8532733508dc58e3eaf61 - Topic: 'Budget Management Discussion' matches keyphrase: 'budget management discussion'\n",
      "    Match found: 68a8532833508dc58e3eaf62 - Topic: 'Cross-Department Project Update' matches keyphrase: 'crossdepartment project update'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 7 with 45 chat chunk IDs\n",
      "  Total unique chat chunks matched: 45\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 8\n",
      "Cluster Name: Customer & Sales Strategy\n",
      "Keyphrases: ['Customer Insight Report', 'Campaign Coordination Discussion', 'Content Management Update', 'Customer Research Finding', 'Account Management Strategy', 'Product Update Communication', 'Pipeline Management Discussion']\n",
      "Normalized keyphrases: ['customer insight report', 'campaign coordination discussion', 'content management update', 'customer research finding', 'account management strategy', 'product update communication', 'pipeline management discussion']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525333508dc58e3ead3a - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8525933508dc58e3ead49 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a8526033508dc58e3ead5c - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8526233508dc58e3ead60 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8526233508dc58e3ead62 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a8526333508dc58e3ead64 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a8526533508dc58e3ead6a - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a8526f33508dc58e3ead84 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a8526f33508dc58e3ead86 - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8527333508dc58e3ead91 - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a8527533508dc58e3ead94 - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8527a33508dc58e3eada0 - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a8527b33508dc58e3eada3 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a8527d33508dc58e3eadaa - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8528133508dc58e3eadaf - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a8528233508dc58e3eadb0 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a8528733508dc58e3eadbf - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a8528833508dc58e3eadc0 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8528833508dc58e3eadc1 - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a8528c33508dc58e3eadca - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a8528d33508dc58e3eadcd - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8529133508dc58e3eadda - Topic: 'Account Management Strategy' matches keyphrase: 'account management strategy'\n",
      "    Match found: 68a8529233508dc58e3eaddb - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a8529333508dc58e3eadde - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8529333508dc58e3eaddf - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a8529433508dc58e3eade3 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a8529533508dc58e3eade5 - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8529633508dc58e3eade6 - Topic: 'Account Management Strategy' matches keyphrase: 'account management strategy'\n",
      "    Match found: 68a8529933508dc58e3eadef - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8529e33508dc58e3eadfc - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a852a133508dc58e3eae04 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a852a633508dc58e3eae12 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a852a933508dc58e3eae1a - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a852ab33508dc58e3eae1f - Topic: 'Account Management Strategy' matches keyphrase: 'account management strategy'\n",
      "    Match found: 68a852ac33508dc58e3eae23 - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a852b433508dc58e3eae38 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a852b533508dc58e3eae3c - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a852b833508dc58e3eae42 - Topic: 'Account Management Strategy' matches keyphrase: 'account management strategy'\n",
      "    Match found: 68a852bb33508dc58e3eae4a - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a852bd33508dc58e3eae4f - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a852c933508dc58e3eae70 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a852ca33508dc58e3eae72 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a852cc33508dc58e3eae77 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a852d233508dc58e3eae84 - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a852d433508dc58e3eae89 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a852e333508dc58e3eaeb0 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a852e533508dc58e3eaeb5 - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a852e533508dc58e3eaeb6 - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a852e633508dc58e3eaeb9 - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a852e733508dc58e3eaebb - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a852e833508dc58e3eaebe - Topic: 'Account Management Strategy' matches keyphrase: 'account management strategy'\n",
      "    Match found: 68a852ed33508dc58e3eaecc - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a852f233508dc58e3eaed8 - Topic: 'Product Update Communication' matches keyphrase: 'product update communication'\n",
      "    Match found: 68a852f333508dc58e3eaedb - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a852f733508dc58e3eaee4 - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a852f833508dc58e3eaee8 - Topic: 'Customer Insight Report' matches keyphrase: 'customer insight report'\n",
      "    Match found: 68a852ff33508dc58e3eaef8 - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a852ff33508dc58e3eaef9 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8530433508dc58e3eaf06 - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a8530533508dc58e3eaf08 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8531133508dc58e3eaf24 - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a8531633508dc58e3eaf33 - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8532133508dc58e3eaf50 - Topic: 'Customer Research Finding' matches keyphrase: 'customer research finding'\n",
      "    Match found: 68a8532633508dc58e3eaf5f - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8532833508dc58e3eaf63 - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a8532c33508dc58e3eaf6d - Topic: 'Content Management Update' matches keyphrase: 'content management update'\n",
      "    Match found: 68a8533233508dc58e3eaf7a - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "    Match found: 68a8533333508dc58e3eaf7e - Topic: 'Pipeline Management Discussion' matches keyphrase: 'pipeline management discussion'\n",
      "    Match found: 68a8533733508dc58e3eaf87 - Topic: 'Campaign Coordination Discussion' matches keyphrase: 'campaign coordination discussion'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 8 with 69 chat chunk IDs\n",
      "  Total unique chat chunks matched: 69\n",
      "--------------------------------------------------\n",
      "Processing Cluster ID: 9\n",
      "Cluster Name: External Relations & Vendor Management\n",
      "Keyphrases: ['Vendor Management Discussion', 'Account Access Problem', 'Transaction Status Inquiry', 'Documentation Request Alert', 'Technology Provider Communication']\n",
      "Normalized keyphrases: ['vendor management discussion', 'account access problem', 'transaction status inquiry', 'documentation request alert', 'technology provider communication']\n",
      "  Searching through chat chunks...\n",
      "    Match found: 68a8525933508dc58e3ead4a - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8525f33508dc58e3ead5a - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8526433508dc58e3ead66 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8526633508dc58e3ead6c - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8526a33508dc58e3ead76 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8527033508dc58e3ead87 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a8527733508dc58e3ead99 - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a8527833508dc58e3ead9b - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8527933508dc58e3ead9f - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8527a33508dc58e3eada2 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8529933508dc58e3eadee - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a8529d33508dc58e3eadf9 - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a8529d33508dc58e3eadfb - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8529f33508dc58e3eadfe - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a852a033508dc58e3eae01 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a852a733508dc58e3eae14 - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a852a933508dc58e3eae19 - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a852a933508dc58e3eae1b - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a852ae33508dc58e3eae27 - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a852af33508dc58e3eae2a - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a852b533508dc58e3eae3b - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a852b633508dc58e3eae3d - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a852ba33508dc58e3eae48 - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a852bd33508dc58e3eae4e - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a852c133508dc58e3eae5a - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a852c233508dc58e3eae5e - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a852c633508dc58e3eae68 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a852d333508dc58e3eae85 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a852d533508dc58e3eae8c - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a852d933508dc58e3eae97 - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a852de33508dc58e3eaea3 - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a852e433508dc58e3eaeb2 - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a852eb33508dc58e3eaec5 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a852ef33508dc58e3eaed1 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a852f133508dc58e3eaed7 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a852f333508dc58e3eaeda - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a852f533508dc58e3eaede - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a852fa33508dc58e3eaeed - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a852fe33508dc58e3eaef5 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a852fe33508dc58e3eaef6 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a852fe33508dc58e3eaef7 - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a8530433508dc58e3eaf05 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8530633508dc58e3eaf0b - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a8530933508dc58e3eaf11 - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a8530e33508dc58e3eaf1e - Topic: 'Vendor Management Discussion' matches keyphrase: 'vendor management discussion'\n",
      "    Match found: 68a8530f33508dc58e3eaf1f - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8531833508dc58e3eaf39 - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a8531a33508dc58e3eaf3d - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8532533508dc58e3eaf5b - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a8532533508dc58e3eaf5c - Topic: 'Account Access Problem' matches keyphrase: 'account access problem'\n",
      "    Match found: 68a8532633508dc58e3eaf5e - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8532b33508dc58e3eaf6b - Topic: 'Transaction Status Inquiry' matches keyphrase: 'transaction status inquiry'\n",
      "    Match found: 68a8533333508dc58e3eaf7c - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "    Match found: 68a8533633508dc58e3eaf84 - Topic: 'Documentation Request Alert' matches keyphrase: 'documentation request alert'\n",
      "    Match found: 68a8533733508dc58e3eaf86 - Topic: 'Technology Provider Communication' matches keyphrase: 'technology provider communication'\n",
      "  Finished processing 600 chat chunks\n",
      "  ✓ Successfully updated cluster 9 with 55 chat chunk IDs\n",
      "  Total unique chat chunks matched: 55\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "VERIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Cluster 0: Workforce & HR Management (data: chat-chunks)\n",
      "  Keyphrases: ['Shift Coverage Request', 'Training Schedule Update', 'Performance Review Planning', 'Break Schedule Coordination', 'Overtime Approval Need', 'Team Meeting Reminder', 'Staff Management Discussion', 'Workforce Planning Update', 'Employee Relations Coordination', 'Attendance Management Alert', 'Leave Request Approval', 'Skill Development Update']\n",
      "  Chat Chunk IDs count: 98\n",
      "  First 3 Chat Chunk IDs: ['68a8530233508dc58e3eaf00', '68a852c333508dc58e3eae5f', '68a8525a33508dc58e3ead4b']\n",
      "  ... and 95 more\n",
      "\n",
      "Cluster 1: IT Infrastructure & Systems (data: chat-chunks)\n",
      "  Keyphrases: ['System Status Alert', 'Network Performance Issue', 'Application Server Warning', 'Authentication Service Down', 'Technology Rollout Update', 'System Integration Progress']\n",
      "  Chat Chunk IDs count: 46\n",
      "  First 3 Chat Chunk IDs: ['68a8529233508dc58e3eaddc', '68a8531f33508dc58e3eaf4c', '68a852cb33508dc58e3eae73']\n",
      "  ... and 43 more\n",
      "\n",
      "Cluster 2: IT Security & Support (data: chat-chunks)\n",
      "  Keyphrases: ['Database Access Problem', 'Security Protocol Change', 'Hardware Troubleshooting Help', 'Software Issue Resolution', 'User Access Problem', 'Cybersecurity Alert Warning']\n",
      "  Chat Chunk IDs count: 59\n",
      "  First 3 Chat Chunk IDs: ['68a852e233508dc58e3eaead', '68a8531f33508dc58e3eaf4b', '68a8532d33508dc58e3eaf6f']\n",
      "  ... and 56 more\n",
      "\n",
      "Cluster 3: Operational Processes & Workflow (data: chat-chunks)\n",
      "  Keyphrases: ['Process Coordination Discussion', 'Workflow Optimization Alert', 'Quality Standard Reminder', 'Case Management Discussion', 'Knowledge Management Update', 'Team Coordination Update', 'Daily Operational Procedure']\n",
      "  Chat Chunk IDs count: 59\n",
      "  First 3 Chat Chunk IDs: ['68a852c833508dc58e3eae6d', '68a852a433508dc58e3eae0d', '68a852b333508dc58e3eae37']\n",
      "  ... and 56 more\n",
      "\n",
      "Cluster 4: Compliance & Policy (data: chat-chunks)\n",
      "  Keyphrases: ['Policy Clarification Request', 'Compliance Training Reminder', 'GDPR Access Request', 'Regulatory Update Alert', 'Regulatory Examination Preparation', 'Regulatory Response Management', 'Compliance Monitoring Update']\n",
      "  Chat Chunk IDs count: 61\n",
      "  First 3 Chat Chunk IDs: ['68a852ea33508dc58e3eaec2', '68a8530333508dc58e3eaf02', '68a852d933508dc58e3eae96']\n",
      "  ... and 58 more\n",
      "\n",
      "Cluster 5: Internal Audit & Reporting (data: chat-chunks)\n",
      "  Keyphrases: ['Audit Coordination Schedule', 'Monthly Compliance Audit', 'Audit Feedback Review', 'Compliance Report Generation', 'Audit Planning Coordination', 'Audit Finding Resolution']\n",
      "  Chat Chunk IDs count: 68\n",
      "  First 3 Chat Chunk IDs: ['68a8530733508dc58e3eaf0d', '68a8527133508dc58e3ead89', '68a8525133508dc58e3ead35']\n",
      "  ... and 65 more\n",
      "\n",
      "Cluster 6: Risk & Control Management (data: chat-chunks)\n",
      "  Keyphrases: ['Risk Assessment Update', 'Risk Assessment Documentation', 'Control Testing Validation', 'Compliance Gap Remediation']\n",
      "  Chat Chunk IDs count: 40\n",
      "  First 3 Chat Chunk IDs: ['68a8529133508dc58e3eadd9', '68a8533733508dc58e3eaf88', '68a852b233508dc58e3eae34']\n",
      "  ... and 37 more\n",
      "\n",
      "Cluster 7: Business & Financial Planning (data: chat-chunks)\n",
      "  Keyphrases: ['Budget Management Discussion', 'Financial Reporting Procedure', 'Performance Metric Tracking', 'Business Continuity Activation', 'Cross-Department Project Update']\n",
      "  Chat Chunk IDs count: 45\n",
      "  First 3 Chat Chunk IDs: ['68a852a633508dc58e3eae13', '68a8531333508dc58e3eaf2b', '68a8526633508dc58e3ead6b']\n",
      "  ... and 42 more\n",
      "\n",
      "Cluster 8: Customer & Sales Strategy (data: chat-chunks)\n",
      "  Keyphrases: ['Customer Insight Report', 'Campaign Coordination Discussion', 'Content Management Update', 'Customer Research Finding', 'Account Management Strategy', 'Product Update Communication', 'Pipeline Management Discussion']\n",
      "  Chat Chunk IDs count: 69\n",
      "  First 3 Chat Chunk IDs: ['68a852b533508dc58e3eae3c', '68a8528133508dc58e3eadaf', '68a852ca33508dc58e3eae72']\n",
      "  ... and 66 more\n",
      "\n",
      "Cluster 9: External Relations & Vendor Management (data: chat-chunks)\n",
      "  Keyphrases: ['Vendor Management Discussion', 'Account Access Problem', 'Transaction Status Inquiry', 'Documentation Request Alert', 'Technology Provider Communication']\n",
      "  Chat Chunk IDs count: 55\n",
      "  First 3 Chat Chunk IDs: ['68a8526433508dc58e3ead66', '68a8526a33508dc58e3ead76', '68a8527a33508dc58e3eada2']\n",
      "  ... and 52 more\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "Total clusters with data='chat-chunks': 10\n",
      "Clusters with matched chat chunks: 10\n",
      "Clusters without matches: 0\n",
      "Total chat chunks in database: 600\n",
      "Total chat chunk-cluster matches: 600\n",
      "Match percentage: 100.00%\n",
      "\n",
      "============================================================\n",
      "✅ Process completed successfully!\n",
      "============================================================\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pymongo import MongoClient\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MongoDB using environment variables\n",
    "MONGO_CONNECTION_STRING = os.getenv('MONGO_CONNECTION_STRING')\n",
    "MONGO_DATABASE_NAME = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not MONGO_CONNECTION_STRING or not MONGO_DATABASE_NAME:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "print(f\"Connecting to MongoDB...\")\n",
    "print(f\"Database: {MONGO_DATABASE_NAME}\")\n",
    "\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = client[MONGO_DATABASE_NAME]\n",
    "\n",
    "# Get collections\n",
    "clusters_collection = db['cluster']\n",
    "chat_chunks_collection = db['chat-chunks']\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for better matching\"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', text.lower().strip())\n",
    "\n",
    "def match_chat_chunks_to_clusters():\n",
    "    \"\"\"\n",
    "    Match chat-chunks to clusters based on dominant_topic matching keyphrases\n",
    "    and update cluster documents with chat_chunk_ids array\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Fetching clusters with data: 'chat-chunks'...\")\n",
    "    # Get only clusters that have data field set to \"chat-chunks\"\n",
    "    clusters = list(clusters_collection.find({\"data\": \"chat-chunks\"}))\n",
    "    print(f\"Found {len(clusters)} clusters with data='chat-chunks' to process\\n\")\n",
    "    \n",
    "    # Process each cluster\n",
    "    for cluster in clusters:\n",
    "        cluster_id = cluster['cluster_id']\n",
    "        keyphrases = cluster.get('keyphrases', [])\n",
    "        \n",
    "        print(f\"Processing Cluster ID: {cluster_id}\")\n",
    "        print(f\"Cluster Name: {cluster.get('cluster_name', 'N/A')}\")\n",
    "        print(f\"Keyphrases: {keyphrases}\")\n",
    "        \n",
    "        # Normalize keyphrases for matching\n",
    "        normalized_keyphrases = [normalize_text(phrase) for phrase in keyphrases]\n",
    "        print(f\"Normalized keyphrases: {normalized_keyphrases}\")\n",
    "        \n",
    "        # Find matching chat chunks\n",
    "        matching_chat_chunk_ids = []\n",
    "        \n",
    "        # Get all chat chunks - using cursor for better memory management\n",
    "        print(\"  Searching through chat chunks...\")\n",
    "        chat_chunks_cursor = chat_chunks_collection.find({}, {\n",
    "            '_id': 1, \n",
    "            'dominant_topic': 1\n",
    "        })\n",
    "        \n",
    "        chat_chunk_count = 0\n",
    "        for chat_chunk in chat_chunks_cursor:\n",
    "            chat_chunk_count += 1\n",
    "            if chat_chunk_count % 1000 == 0:\n",
    "                print(f\"    Processed {chat_chunk_count} chat chunks...\")\n",
    "                \n",
    "            chat_chunk_dominant_topic = chat_chunk.get('dominant_topic', '')\n",
    "            \n",
    "            if chat_chunk_dominant_topic:\n",
    "                normalized_topic = normalize_text(chat_chunk_dominant_topic)\n",
    "                \n",
    "                # Check if any keyphrase matches the dominant topic\n",
    "                for keyphrase in normalized_keyphrases:\n",
    "                    if keyphrase and normalized_topic:  # Ensure both are not empty\n",
    "                        if keyphrase in normalized_topic or normalized_topic in keyphrase:\n",
    "                            matching_chat_chunk_ids.append(str(chat_chunk['_id']))\n",
    "                            print(f\"    Match found: {chat_chunk['_id']} - Topic: '{chat_chunk_dominant_topic}' matches keyphrase: '{keyphrase}'\")\n",
    "                            break\n",
    "        \n",
    "        print(f\"  Finished processing {chat_chunk_count} chat chunks\")\n",
    "        \n",
    "        # Remove duplicates (in case a chat chunk matches multiple times)\n",
    "        matching_chat_chunk_ids = list(set(matching_chat_chunk_ids))\n",
    "        \n",
    "        # Update cluster with chat_chunk_ids (only for clusters with data: \"chat-chunks\")\n",
    "        try:\n",
    "            if matching_chat_chunk_ids:\n",
    "                result = clusters_collection.update_one(\n",
    "                    {'cluster_id': cluster_id, 'data': 'chat-chunks'},\n",
    "                    {'$set': {'chat_chunk_ids': matching_chat_chunk_ids}}\n",
    "                )\n",
    "                if result.modified_count > 0:\n",
    "                    print(f\"  ✓ Successfully updated cluster {cluster_id} with {len(matching_chat_chunk_ids)} chat chunk IDs\")\n",
    "                elif result.matched_count > 0:\n",
    "                    print(f\"  ⚠ Cluster {cluster_id} already has same chat chunk data\")\n",
    "                else:\n",
    "                    print(f\"  ❌ Cluster {cluster_id} not found or doesn't have data: 'chat-chunks'\")\n",
    "            else:\n",
    "                # Set empty array if no matches found\n",
    "                result = clusters_collection.update_one(\n",
    "                    {'cluster_id': cluster_id, 'data': 'chat-chunks'},\n",
    "                    {'$set': {'chat_chunk_ids': []}}\n",
    "                )\n",
    "                if result.modified_count > 0:\n",
    "                    print(f\"  ✓ Set empty chat_chunk_ids array for cluster {cluster_id} (no matches found)\")\n",
    "                elif result.matched_count > 0:\n",
    "                    print(f\"  ⚠ Cluster {cluster_id} already has empty chat_chunk_ids array\")\n",
    "                else:\n",
    "                    print(f\"  ❌ Cluster {cluster_id} not found or doesn't have data: 'chat-chunks'\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error updating cluster {cluster_id}: {str(e)}\")\n",
    "        \n",
    "        print(f\"  Total unique chat chunks matched: {len(matching_chat_chunk_ids)}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def verify_results():\n",
    "    \"\"\"\n",
    "    Verify the results by displaying updated clusters\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VERIFICATION RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        clusters = list(clusters_collection.find({\"data\": \"chat-chunks\"}, {\n",
    "            'cluster_id': 1, \n",
    "            'cluster_name': 1, \n",
    "            'keyphrases': 1, \n",
    "            'chat_chunk_ids': 1,\n",
    "            'data': 1\n",
    "        }).sort('cluster_id', 1))\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            chat_chunk_count = len(cluster.get('chat_chunk_ids', []))\n",
    "            print(f\"\\nCluster {cluster['cluster_id']}: {cluster.get('cluster_name', 'N/A')} (data: {cluster.get('data', 'N/A')})\")\n",
    "            print(f\"  Keyphrases: {cluster.get('keyphrases', [])}\")\n",
    "            print(f\"  Chat Chunk IDs count: {chat_chunk_count}\")\n",
    "            if chat_chunk_count > 0:\n",
    "                print(f\"  First 3 Chat Chunk IDs: {cluster['chat_chunk_ids'][:3]}\")\n",
    "                if chat_chunk_count > 3:\n",
    "                    print(f\"  ... and {chat_chunk_count - 3} more\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during verification: {str(e)}\")\n",
    "\n",
    "def get_summary_stats():\n",
    "    \"\"\"Get summary statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        total_clusters = clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        clusters_with_chat_chunks = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            'chat_chunk_ids': {'$exists': True, '$ne': []}\n",
    "        })\n",
    "        \n",
    "        pipeline = [\n",
    "            {'$match': {\"data\": \"chat-chunks\", 'chat_chunk_ids': {'$exists': True}}},\n",
    "            {'$project': {'chat_chunk_count': {'$size': '$chat_chunk_ids'}}},\n",
    "            {'$group': {'_id': None, 'total_chat_chunks_matched': {'$sum': '$chat_chunk_count'}}}\n",
    "        ]\n",
    "        \n",
    "        result = list(clusters_collection.aggregate(pipeline))\n",
    "        total_chat_chunks_matched = result[0]['total_chat_chunks_matched'] if result else 0\n",
    "        \n",
    "        total_chat_chunks = chat_chunks_collection.count_documents({})\n",
    "        \n",
    "        print(f\"Total clusters with data='chat-chunks': {total_clusters}\")\n",
    "        print(f\"Clusters with matched chat chunks: {clusters_with_chat_chunks}\")\n",
    "        print(f\"Clusters without matches: {total_clusters - clusters_with_chat_chunks}\")\n",
    "        print(f\"Total chat chunks in database: {total_chat_chunks}\")\n",
    "        print(f\"Total chat chunk-cluster matches: {total_chat_chunks_matched}\")\n",
    "        \n",
    "        if total_chat_chunks > 0:\n",
    "            match_percentage = (total_chat_chunks_matched / total_chat_chunks) * 100\n",
    "            print(f\"Match percentage: {match_percentage:.2f}%\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error getting statistics: {str(e)}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"🚀 Starting chat chunk-cluster matching process...\")\n",
    "        print(\"This will match chat chunks to clusters with data: 'chat-chunks'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Test database connection\n",
    "        test_cluster = clusters_collection.find_one({\"data\": \"chat-chunks\"})\n",
    "        test_chat_chunk = chat_chunks_collection.find_one()\n",
    "        \n",
    "        if not test_cluster:\n",
    "            print(\"⚠️  Warning: No clusters found with data: 'chat-chunks'\")\n",
    "        if not test_chat_chunk:\n",
    "            print(\"⚠️  Warning: No chat chunks found in chat-chunks collection\")\n",
    "            \n",
    "        print(\"✓ Database connection successful\\n\")\n",
    "        \n",
    "        # Execute the matching process\n",
    "        match_chat_chunks_to_clusters()\n",
    "        \n",
    "        # Verify results\n",
    "        verify_results()\n",
    "        \n",
    "        # Get summary statistics\n",
    "        get_summary_stats()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✅ Process completed successfully!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during execution: {str(e)}\")\n",
    "        print(\"Please check your environment variables and database connection.\")\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5305f742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MongoDB...\n",
      "Database: sparzaai\n",
      "💬 Starting domains update to 'Chat Support' for chat-chunks clusters...\n",
      "This will only update clusters with data: 'chat-chunks'\n",
      "============================================================\n",
      "✓ Database connection successful\n",
      "Sample chat-chunks cluster - data: chat-chunks, domains: ['banking']\n",
      "\n",
      "Starting domain update process for chat-chunks clusters...\n",
      "==================================================\n",
      "Total chat-chunks clusters in collection: 10\n",
      "Chat-chunks clusters with 'EU bank' domain: 0\n",
      "Chat-chunks clusters with 'Chat Support' domain: 0\n",
      "Chat-chunks clusters with other domains: 10\n",
      "\n",
      "==================================================\n",
      "UPDATING CHAT-CHUNKS CLUSTER DOMAINS...\n",
      "==================================================\n",
      "✓ Successfully updated 10 chat-chunks clusters\n",
      "  Matched chat-chunks clusters: 10\n",
      "\n",
      "==================================================\n",
      "CHAT-CHUNKS CLUSTER VERIFICATION\n",
      "==================================================\n",
      "Total chat-chunks clusters: 10\n",
      "Chat-chunks clusters with 'Chat Support' domain: 10\n",
      "Chat-chunks clusters with 'EU bank' domain: 0\n",
      "Chat-chunks clusters with other domains: 0\n",
      "\n",
      "✅ SUCCESS: All chat-chunks clusters now have 'Chat Support' domain!\n",
      "\n",
      "Sample of updated chat-chunks clusters:\n",
      "  Chat-chunks Cluster 0: data=chat-chunks, domains=['Chat Support'], label='Workforce & HR Management'\n",
      "  Chat-chunks Cluster 1: data=chat-chunks, domains=['Chat Support'], label='IT Infrastructure & Systems'\n",
      "  Chat-chunks Cluster 2: data=chat-chunks, domains=['Chat Support'], label='IT Security & Support'\n",
      "  Chat-chunks Cluster 3: data=chat-chunks, domains=['Chat Support'], label='Operational Processes & Workflow'\n",
      "  Chat-chunks Cluster 4: data=chat-chunks, domains=['Chat Support'], label='Compliance & Policy'\n",
      "\n",
      "==================================================\n",
      "CHAT-CHUNKS CLUSTER DOMAIN STATISTICS\n",
      "==================================================\n",
      "Domain distribution for chat-chunks clusters:\n",
      "  ['Chat Support']: 10 chat-chunks clusters\n",
      "\n",
      "Percentage of chat-chunks clusters with 'Chat Support' domain: 100.0%\n",
      "\n",
      "Comparison with other cluster types:\n",
      "  Clusters with data='email': 33\n",
      "  Clusters with data='tickets': 16\n",
      "  Clusters with data='chat-chunks': 10\n",
      "\n",
      "==================================================\n",
      "CHAT-CHUNKS CLUSTER SUMMARY\n",
      "==================================================\n",
      "Total chat-chunks clusters: 10\n",
      "Chat-chunks clusters with assigned chat chunks: 10\n",
      "Total chat chunks assigned to clusters: 600\n",
      "Average chat chunks per cluster: 60.00\n",
      "Maximum chat chunks in a cluster: 98\n",
      "\n",
      "============================================================\n",
      "✅ Chat-chunks cluster domain update process completed successfully!\n",
      "All chat-chunks clusters now have domains: ['Chat Support']\n",
      "============================================================\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MongoDB using environment variables\n",
    "MONGO_CONNECTION_STRING = os.getenv('MONGO_CONNECTION_STRING')\n",
    "MONGO_DATABASE_NAME = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not MONGO_CONNECTION_STRING or not MONGO_DATABASE_NAME:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "print(f\"Connecting to MongoDB...\")\n",
    "print(f\"Database: {MONGO_DATABASE_NAME}\")\n",
    "\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = client[MONGO_DATABASE_NAME]\n",
    "\n",
    "# Get collections\n",
    "clusters_collection = db['cluster']\n",
    "\n",
    "def update_domains_to_chat_support():\n",
    "    \"\"\"\n",
    "    Update chat-chunks cluster documents to change domains to [\"Chat Support\"]\n",
    "    Only processes clusters with data: \"chat-chunks\"\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting domain update process for chat-chunks clusters...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Count total chat-chunks clusters before update\n",
    "        total_chat_chunks_clusters = clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        print(f\"Total chat-chunks clusters in collection: {total_chat_chunks_clusters}\")\n",
    "        \n",
    "        if total_chat_chunks_clusters == 0:\n",
    "            print(\"⚠ No chat-chunks clusters found (data: 'chat-chunks')\")\n",
    "            return\n",
    "        \n",
    "        # Count chat-chunks clusters that currently have [\"EU bank\"] or other domains\n",
    "        eu_bank_count = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\", \n",
    "            \"domains\": [\"EU bank\"]\n",
    "        })\n",
    "        print(f\"Chat-chunks clusters with 'EU bank' domain: {eu_bank_count}\")\n",
    "        \n",
    "        old_chat_support_count = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\", \n",
    "            \"domains\": [\"Chat Support\"]\n",
    "        })\n",
    "        print(f\"Chat-chunks clusters with 'Chat Support' domain: {old_chat_support_count}\")\n",
    "        \n",
    "        # Count chat-chunks clusters with other domains\n",
    "        other_domains_count = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"domains\": {\"$nin\": [[\"EU bank\"], [\"Chat Support\"]]}\n",
    "        })\n",
    "        print(f\"Chat-chunks clusters with other domains: {other_domains_count}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"UPDATING CHAT-CHUNKS CLUSTER DOMAINS...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Update only chat-chunks clusters to have domains: [\"Chat Support\"]\n",
    "        update_result = clusters_collection.update_many(\n",
    "            {\"data\": \"chat-chunks\"},  # Only update clusters with data: \"chat-chunks\"\n",
    "            {\"$set\": {\"domains\": [\"Chat Support\"]}}\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Successfully updated {update_result.modified_count} chat-chunks clusters\")\n",
    "        print(f\"  Matched chat-chunks clusters: {update_result.matched_count}\")\n",
    "        \n",
    "        # Verify the update\n",
    "        verify_update()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during chat-chunks domain update: {str(e)}\")\n",
    "\n",
    "def verify_update():\n",
    "    \"\"\"\n",
    "    Verify that all chat-chunks clusters have been updated to [\"Chat Support\"]\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CHAT-CHUNKS CLUSTER VERIFICATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Count chat-chunks clusters with different domain values\n",
    "        chat_support_count = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"domains\": [\"Chat Support\"]\n",
    "        })\n",
    "        eu_bank_count = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"domains\": [\"EU bank\"]\n",
    "        })\n",
    "        other_domains = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"domains\": {\"$nin\": [[\"Chat Support\"], [\"EU bank\"]]}\n",
    "        })\n",
    "        \n",
    "        total_chat_chunks_clusters = clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        \n",
    "        print(f\"Total chat-chunks clusters: {total_chat_chunks_clusters}\")\n",
    "        print(f\"Chat-chunks clusters with 'Chat Support' domain: {chat_support_count}\")\n",
    "        print(f\"Chat-chunks clusters with 'EU bank' domain: {eu_bank_count}\")\n",
    "        print(f\"Chat-chunks clusters with other domains: {other_domains}\")\n",
    "        \n",
    "        if chat_support_count == total_chat_chunks_clusters:\n",
    "            print(\"\\n✅ SUCCESS: All chat-chunks clusters now have 'Chat Support' domain!\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ WARNING: {total_chat_chunks_clusters - chat_support_count} chat-chunks clusters still have different domains\")\n",
    "        \n",
    "        # Show sample of updated chat-chunks cluster documents\n",
    "        print(f\"\\nSample of updated chat-chunks clusters:\")\n",
    "        samples = list(clusters_collection.find(\n",
    "            {\"data\": \"chat-chunks\"}, \n",
    "            {\n",
    "                'cluster_id': 1, \n",
    "                'domains': 1, \n",
    "                'dominant_label': 1,\n",
    "                'data': 1\n",
    "            }\n",
    "        ).limit(5).sort('cluster_id', 1))\n",
    "        \n",
    "        for sample in samples:\n",
    "            cluster_id = sample.get('cluster_id', 'N/A')\n",
    "            domains = sample.get('domains', [])\n",
    "            label = sample.get('dominant_label', 'N/A')\n",
    "            data_type = sample.get('data', 'N/A')\n",
    "            print(f\"  Chat-chunks Cluster {cluster_id}: data={data_type}, domains={domains}, label='{label}'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during verification: {str(e)}\")\n",
    "\n",
    "def get_domain_statistics():\n",
    "    \"\"\"\n",
    "    Get detailed statistics about domains in chat-chunks clusters only\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CHAT-CHUNKS CLUSTER DOMAIN STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Aggregate to get all unique domain combinations for chat-chunks clusters only\n",
    "        pipeline = [\n",
    "            {'$match': {\"data\": \"chat-chunks\"}},\n",
    "            {'$group': {'_id': '$domains', 'count': {'$sum': 1}}},\n",
    "            {'$sort': {'count': -1}}\n",
    "        ]\n",
    "        \n",
    "        domain_stats = list(clusters_collection.aggregate(pipeline))\n",
    "        \n",
    "        print(\"Domain distribution for chat-chunks clusters:\")\n",
    "        for stat in domain_stats:\n",
    "            domains = stat['_id']\n",
    "            count = stat['count']\n",
    "            print(f\"  {domains}: {count} chat-chunks clusters\")\n",
    "            \n",
    "        total_chat_chunks_clusters = clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        if total_chat_chunks_clusters > 0:\n",
    "            chat_support_percentage = (clusters_collection.count_documents({\n",
    "                \"data\": \"chat-chunks\",\n",
    "                \"domains\": [\"Chat Support\"]\n",
    "            }) / total_chat_chunks_clusters) * 100\n",
    "            print(f\"\\nPercentage of chat-chunks clusters with 'Chat Support' domain: {chat_support_percentage:.1f}%\")\n",
    "        \n",
    "        # Show comparison with other data types\n",
    "        print(f\"\\nComparison with other cluster types:\")\n",
    "        all_data_types = list(clusters_collection.aggregate([\n",
    "            {'$group': {'_id': '$data', 'count': {'$sum': 1}}},\n",
    "            {'$sort': {'count': -1}}\n",
    "        ]))\n",
    "        \n",
    "        for data_type in all_data_types:\n",
    "            data_value = data_type['_id']\n",
    "            count = data_type['count']\n",
    "            print(f\"  Clusters with data='{data_value}': {count}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error getting statistics: {str(e)}\")\n",
    "\n",
    "def show_chat_chunks_cluster_summary():\n",
    "    \"\"\"\n",
    "    Show summary of chat-chunks cluster fields after domain update\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CHAT-CHUNKS CLUSTER SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Get chat-chunks cluster statistics\n",
    "        chat_chunks_clusters_with_chat_chunk_ids = clusters_collection.count_documents({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"chat_chunk_ids\": {\"$exists\": True, \"$ne\": []}\n",
    "        })\n",
    "        \n",
    "        # Get average chat chunk count per cluster\n",
    "        chat_chunks_pipeline = [\n",
    "            {'$match': {\"data\": \"chat-chunks\", \"chat_chunk_ids\": {\"$exists\": True}}},\n",
    "            {'$project': {'chat_chunk_count': {'$size': '$chat_chunk_ids'}}},\n",
    "            {'$group': {\n",
    "                '_id': None,\n",
    "                'total_chat_chunks': {'$sum': '$chat_chunk_count'},\n",
    "                'avg_chat_chunks_per_cluster': {'$avg': '$chat_chunk_count'},\n",
    "                'max_chat_chunks_per_cluster': {'$max': '$chat_chunk_count'}\n",
    "            }}\n",
    "        ]\n",
    "        \n",
    "        chat_chunks_result = list(clusters_collection.aggregate(chat_chunks_pipeline))\n",
    "        \n",
    "        total_chat_chunks_clusters = clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        \n",
    "        print(f\"Total chat-chunks clusters: {total_chat_chunks_clusters}\")\n",
    "        print(f\"Chat-chunks clusters with assigned chat chunks: {chat_chunks_clusters_with_chat_chunk_ids}\")\n",
    "        \n",
    "        if chat_chunks_result:\n",
    "            result = chat_chunks_result[0]\n",
    "            print(f\"Total chat chunks assigned to clusters: {result['total_chat_chunks']}\")\n",
    "            print(f\"Average chat chunks per cluster: {result['avg_chat_chunks_per_cluster']:.2f}\")\n",
    "            print(f\"Maximum chat chunks in a cluster: {result['max_chat_chunks_per_cluster']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error getting chat-chunks summary: {str(e)}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"💬 Starting domains update to 'Chat Support' for chat-chunks clusters...\")\n",
    "        print(\"This will only update clusters with data: 'chat-chunks'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Test database connection\n",
    "        test_doc = clusters_collection.find_one({\"data\": \"chat-chunks\"})\n",
    "        if test_doc:\n",
    "            print(\"✓ Database connection successful\")\n",
    "            current_domains = test_doc.get('domains', 'N/A')\n",
    "            data_type = test_doc.get('data', 'N/A')\n",
    "            print(f\"Sample chat-chunks cluster - data: {data_type}, domains: {current_domains}\\n\")\n",
    "        else:\n",
    "            print(\"⚠ No chat-chunks clusters found (data: 'chat-chunks') in clusters collection\")\n",
    "            print(\"Please ensure you have clusters with data: 'chat-chunks' before running this script\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Execute the domain update for chat-chunks clusters\n",
    "        update_domains_to_chat_support()\n",
    "        \n",
    "        # Get detailed statistics\n",
    "        get_domain_statistics()\n",
    "        \n",
    "        # Show chat-chunks cluster summary\n",
    "        show_chat_chunks_cluster_summary()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✅ Chat-chunks cluster domain update process completed successfully!\")\n",
    "        print(\"All chat-chunks clusters now have domains: ['Chat Support']\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during execution: {str(e)}\")\n",
    "        print(\"Please check your environment variables and database connection.\")\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "828ea9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database: sparzaai\n",
      "Loading chat-chunks cluster data into cache...\n",
      "Found 10 chat-chunks clusters to cache\n",
      "Cache loaded in 1.89 seconds\n",
      "Cached 65 cluster keyphrases\n",
      "Cached 65 subcluster keyphrases\n",
      "\n",
      "--- Database Statistics ---\n",
      "total_chat_chunks: 600\n",
      "chat_chunks_with_topic: 600\n",
      "total_chat_chunk_clusters: 10\n",
      "total_all_clusters: 59\n",
      "cached_cluster_keyphrases: 65\n",
      "cached_subcluster_keyphrases: 65\n",
      "\n",
      "--- Gap Analysis ---\n",
      "Analyzing matching gaps...\n",
      "Found 65 unique dominant topics in chat-chunks\n",
      "\n",
      "=== MATCHING GAP ANALYSIS ===\n",
      "Total unique topics: 65\n",
      "Matched topics: 65\n",
      "Unmatched topics: 0\n",
      "Matched chat-chunks: 600\n",
      "Unmatched chat-chunks: 0\n",
      "\n",
      "--- Debugging Mode ---\n",
      "\n",
      "--- Preview of Chat-Chunk Matches ---\n",
      "\n",
      "--- Chat-Chunk 1 ---\n",
      "Dominant Topic: Account Access Problem\n",
      "✓ Subcluster Match: Cluster ID=9, Subcluster ID=1, Label=Client & External Queries\n",
      "\n",
      "--- Chat-Chunk 2 ---\n",
      "Dominant Topic: Account Access Problem\n",
      "✓ Subcluster Match: Cluster ID=9, Subcluster ID=1, Label=Client & External Queries\n",
      "\n",
      "--- Chat-Chunk 3 ---\n",
      "Dominant Topic: Account Access Problem\n",
      "✓ Subcluster Match: Cluster ID=9, Subcluster ID=1, Label=Client & External Queries\n",
      "\n",
      "--- Chat-Chunk 4 ---\n",
      "Dominant Topic: Account Access Problem\n",
      "✓ Subcluster Match: Cluster ID=9, Subcluster ID=1, Label=Client & External Queries\n",
      "\n",
      "--- Chat-Chunk 5 ---\n",
      "Dominant Topic: Account Access Problem\n",
      "✓ Subcluster Match: Cluster ID=9, Subcluster ID=1, Label=Client & External Queries\n",
      "\n",
      "--- Processing Options ---\n",
      "1. Dry run (see what would be updated without changing DB)\n",
      "2. Full processing (actually update the database)\n",
      "3. Process with fallback cluster (100% match guarantee)\n",
      "\n",
      "Starting LIVE PROCESSING...\n",
      "Processing ~600 chat-chunks in batches of 600\n",
      "DRY RUN MODE: OFF\n",
      "✓ Index on dominant_topic created/verified\n",
      "\n",
      "--- Processing batch 1 (600 chat-chunks) ---\n",
      "Generated 600 update operations\n",
      "Batch matches - Clusters: 600, Subclusters: 600\n",
      "Executing bulk write...\n",
      "✓ Updated 600 documents in batch 1\n",
      "Sample updated documents: 3 found with cluster IDs\n",
      "Progress: 600 chat-chunks processed (214.0 chat-chunks/sec)\n",
      "\n",
      "--- Verification ---\n",
      "Total chat-chunk documents with kmeans_cluster_id: 600\n",
      "Total chat-chunk documents with subcluster_id: 600\n",
      "\n",
      "--- Final Results ---\n",
      "Total chat-chunks processed: 600\n",
      "Total updates made: 600\n",
      "Cluster matches: 600 (100.0%)\n",
      "Subcluster matches: 600 (100.0%)\n",
      "Processing time: 3.04 seconds\n",
      "Processing rate: 197.1 chat-chunks/second\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient, UpdateOne\n",
    "from typing import Dict, List, Optional, Set\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class OptimizedChatChunkClusterMatcher:\n",
    "    def __init__(self, connection_string: str, database_name: str):\n",
    "        \"\"\"\n",
    "        Initialize the matcher with MongoDB connection\n",
    "        \"\"\"\n",
    "        self.client = MongoClient(connection_string)\n",
    "        self.db = self.client[database_name]\n",
    "        self.chat_chunks_collection = self.db['chat-chunks']\n",
    "        self.clusters_collection = self.db['cluster']\n",
    "        \n",
    "        # Cache for cluster data - this is the key optimization\n",
    "        self._cluster_cache = None\n",
    "        self._subcluster_cache = None\n",
    "        self._load_cluster_cache()\n",
    "    \n",
    "    def _load_cluster_cache(self):\n",
    "        \"\"\"\n",
    "        Load all cluster data into memory for fast lookups\n",
    "        Only load clusters where data equals \"chat-chunks\"\n",
    "        \"\"\"\n",
    "        print(\"Loading chat-chunks cluster data into cache...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Dictionary mapping keyphrase -> cluster info\n",
    "        self._cluster_cache = {}\n",
    "        # Dictionary mapping keyphrase -> subcluster info\n",
    "        self._subcluster_cache = {}\n",
    "        \n",
    "        # Only get clusters where data = \"chat-chunks\"\n",
    "        clusters = list(self.clusters_collection.find({\"data\": \"chat-chunks\"}))\n",
    "        print(f\"Found {len(clusters)} chat-chunks clusters to cache\")\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            cluster_id = cluster.get('cluster_id')\n",
    "            dominant_label = cluster.get('dominant_label')\n",
    "            keyphrases = cluster.get('keyphrases', [])\n",
    "            subclusters = cluster.get('subclusters', {})\n",
    "            \n",
    "            # Cache cluster keyphrases\n",
    "            for keyphrase in keyphrases:\n",
    "                self._cluster_cache[keyphrase] = {\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'dominant_label': dominant_label,\n",
    "                    'subclusters': subclusters\n",
    "                }\n",
    "            \n",
    "            # Cache subcluster keyphrases\n",
    "            for subcluster_id, subcluster_data in subclusters.items():\n",
    "                if not isinstance(subcluster_data, dict):\n",
    "                    continue\n",
    "                    \n",
    "                subcluster_keyphrases = subcluster_data.get('keyphrases', [])\n",
    "                for keyphrase in subcluster_keyphrases:\n",
    "                    self._subcluster_cache[keyphrase] = {\n",
    "                        'cluster_id': cluster_id,\n",
    "                        'dominant_label': dominant_label,\n",
    "                        'subcluster_id': int(subcluster_id),\n",
    "                        'subcluster_label': subcluster_data.get('label')\n",
    "                    }\n",
    "        \n",
    "        cache_time = time.time() - start_time\n",
    "        print(f\"Cache loaded in {cache_time:.2f} seconds\")\n",
    "        print(f\"Cached {len(self._cluster_cache)} cluster keyphrases\")\n",
    "        print(f\"Cached {len(self._subcluster_cache)} subcluster keyphrases\")\n",
    "    \n",
    "    def find_matching_cluster_fast(self, dominant_topic: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Fast cluster lookup using cached data\n",
    "        \"\"\"\n",
    "        return self._cluster_cache.get(dominant_topic)\n",
    "    \n",
    "    def find_matching_subcluster_fast(self, dominant_topic: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Fast subcluster lookup using cached data\n",
    "        \"\"\"\n",
    "        return self._subcluster_cache.get(dominant_topic)\n",
    "    \n",
    "    def find_unmatched_chat_chunks(self, limit: int = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Find chat-chunks that don't match any cluster or subcluster\n",
    "        \"\"\"\n",
    "        unmatched = []\n",
    "        \n",
    "        # Get all chat-chunks with dominant_topic\n",
    "        query = {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}}\n",
    "        cursor = self.chat_chunks_collection.find(query, {\"dominant_topic\": 1})\n",
    "        \n",
    "        if limit:\n",
    "            cursor = cursor.limit(limit)\n",
    "        \n",
    "        for chat_chunk in cursor:\n",
    "            dominant_topic = chat_chunk.get('dominant_topic')\n",
    "            if not dominant_topic:\n",
    "                continue\n",
    "                \n",
    "            # Check if it matches any cluster or subcluster\n",
    "            cluster_match = self.find_matching_cluster_fast(dominant_topic)\n",
    "            subcluster_match = self.find_matching_subcluster_fast(dominant_topic)\n",
    "            \n",
    "            if not cluster_match and not subcluster_match:\n",
    "                unmatched.append({\n",
    "                    'chat_chunk_id': str(chat_chunk['_id']),\n",
    "                    'dominant_topic': dominant_topic\n",
    "                })\n",
    "        \n",
    "        return unmatched\n",
    "    \n",
    "    def get_unique_dominant_topics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get all unique dominant_topic values and their counts from chat-chunks\n",
    "        \"\"\"\n",
    "        pipeline = [\n",
    "            {\"$match\": {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}}},\n",
    "            {\"$group\": {\"_id\": \"$dominant_topic\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]\n",
    "        \n",
    "        result = list(self.chat_chunks_collection.aggregate(pipeline))\n",
    "        \n",
    "        topics_info = {\n",
    "            'total_unique_topics': len(result),\n",
    "            'topics': result\n",
    "        }\n",
    "        \n",
    "        return topics_info\n",
    "    \n",
    "    def analyze_matching_gaps(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze what dominant_topics exist but don't match any chat-chunks clusters\n",
    "        \"\"\"\n",
    "        print(\"Analyzing matching gaps...\")\n",
    "        \n",
    "        # Get all unique dominant topics\n",
    "        topics_info = self.get_unique_dominant_topics()\n",
    "        print(f\"Found {topics_info['total_unique_topics']} unique dominant topics in chat-chunks\")\n",
    "        \n",
    "        # Check which ones don't match\n",
    "        unmatched_topics = {}\n",
    "        matched_topics = {}\n",
    "        \n",
    "        for topic_data in topics_info['topics']:\n",
    "            topic = topic_data['_id']\n",
    "            count = topic_data['count']\n",
    "            \n",
    "            cluster_match = self.find_matching_cluster_fast(topic)\n",
    "            subcluster_match = self.find_matching_subcluster_fast(topic)\n",
    "            \n",
    "            if cluster_match or subcluster_match:\n",
    "                matched_topics[topic] = {\n",
    "                    'count': count,\n",
    "                    'cluster_match': bool(cluster_match),\n",
    "                    'subcluster_match': bool(subcluster_match)\n",
    "                }\n",
    "            else:\n",
    "                unmatched_topics[topic] = count\n",
    "        \n",
    "        return {\n",
    "            'total_topics': topics_info['total_unique_topics'],\n",
    "            'matched_topics': len(matched_topics),\n",
    "            'unmatched_topics': len(unmatched_topics),\n",
    "            'unmatched_details': unmatched_topics,\n",
    "            'matched_details': matched_topics,\n",
    "            'unmatched_chat_chunk_count': sum(unmatched_topics.values()),\n",
    "            'matched_chat_chunk_count': sum([data['count'] for data in matched_topics.values()])\n",
    "        }\n",
    "    \n",
    "    def create_fallback_cluster_entry(self, unmatched_topics: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Create a fallback cluster entry for unmatched topics (for chat-chunks)\n",
    "        \"\"\"\n",
    "        fallback_cluster = {\n",
    "            'cluster_id': 999,  # Use a high number to avoid conflicts\n",
    "            'dominant_label': 'Unclassified Chat-Chunk Topics',\n",
    "            'keyphrases': unmatched_topics,\n",
    "            'data': 'chat-chunks',  # Specify that this is for chat-chunks\n",
    "            'subclusters': {\n",
    "                '0': {\n",
    "                    'label': 'Miscellaneous Chat-Chunks',\n",
    "                    'keyphrases': unmatched_topics\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return fallback_cluster\n",
    "    \n",
    "    def add_fallback_cluster_to_cache(self, unmatched_topics: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Add unmatched topics to cache as a fallback cluster\n",
    "        \"\"\"\n",
    "        print(f\"Adding {len(unmatched_topics)} unmatched topics to fallback cluster...\")\n",
    "        \n",
    "        for topic in unmatched_topics:\n",
    "            # Add to cluster cache\n",
    "            self._cluster_cache[topic] = {\n",
    "                'cluster_id': 999,\n",
    "                'dominant_label': 'Unclassified Chat-Chunk Topics',\n",
    "                'subclusters': {'0': {'label': 'Miscellaneous Chat-Chunks', 'keyphrases': unmatched_topics}}\n",
    "            }\n",
    "            \n",
    "            # Add to subcluster cache\n",
    "            self._subcluster_cache[topic] = {\n",
    "                'cluster_id': 999,\n",
    "                'dominant_label': 'Unclassified Chat-Chunk Topics',\n",
    "                'subcluster_id': 0,\n",
    "                'subcluster_label': 'Miscellaneous Chat-Chunks'\n",
    "            }\n",
    "        \n",
    "        print(f\"✓ Added fallback cluster. Cache now has:\")\n",
    "        print(f\"  - Cluster keyphrases: {len(self._cluster_cache)}\")\n",
    "        print(f\"  - Subcluster keyphrases: {len(self._subcluster_cache)}\")\n",
    "    \n",
    "    def process_chat_chunks_batch(self, chat_chunks: List[Dict]) -> List:\n",
    "        \"\"\"\n",
    "        Process a batch of chat-chunks and return bulk operations in correct PyMongo format\n",
    "        \"\"\"\n",
    "        bulk_operations = []\n",
    "        \n",
    "        for chat_chunk in chat_chunks:\n",
    "            dominant_topic = chat_chunk.get('dominant_topic')\n",
    "            if not dominant_topic:\n",
    "                continue\n",
    "            \n",
    "            # Fast cluster lookup\n",
    "            cluster_match = self.find_matching_cluster_fast(dominant_topic)\n",
    "            subcluster_match = self.find_matching_subcluster_fast(dominant_topic)\n",
    "            \n",
    "            update_data = {}\n",
    "            \n",
    "            if cluster_match:\n",
    "                update_data.update({\n",
    "                    'kmeans_cluster_id': cluster_match['cluster_id'],\n",
    "                    'dominant_label': cluster_match['dominant_label']\n",
    "                })\n",
    "            \n",
    "            if subcluster_match:\n",
    "                update_data.update({\n",
    "                    'kmeans_cluster_id': subcluster_match['cluster_id'],\n",
    "                    'dominant_label': subcluster_match['dominant_label'],\n",
    "                    'subcluster_id': subcluster_match['subcluster_id'],\n",
    "                    'subcluster_label': subcluster_match['subcluster_label']\n",
    "                })\n",
    "            \n",
    "            if update_data:\n",
    "                # Use PyMongo's UpdateOne class instead of dict\n",
    "                bulk_operations.append(\n",
    "                    UpdateOne(\n",
    "                        {'_id': chat_chunk['_id']}, \n",
    "                        {'$set': update_data}\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        return bulk_operations\n",
    "    \n",
    "    def process_chat_chunks_optimized(self, batch_size: int = 5000, max_workers: int = 4, dry_run: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Optimized chat-chunks processing with larger batches and optional threading\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Get total count more efficiently\n",
    "        total_chat_chunks = self.chat_chunks_collection.estimated_document_count()\n",
    "        processed = 0\n",
    "        matched_clusters = 0\n",
    "        matched_subclusters = 0\n",
    "        total_updates = 0\n",
    "        \n",
    "        print(f\"Processing ~{total_chat_chunks} chat-chunks in batches of {batch_size}\")\n",
    "        print(f\"DRY RUN MODE: {'ON' if dry_run else 'OFF'}\")\n",
    "        \n",
    "        # Create index on dominant_topic if it doesn't exist (for faster queries)\n",
    "        try:\n",
    "            self.chat_chunks_collection.create_index([(\"dominant_topic\", 1)], background=True)\n",
    "            print(\"✓ Index on dominant_topic created/verified\")\n",
    "        except Exception as e:\n",
    "            print(f\"Index creation note: {e}\")\n",
    "        \n",
    "        # Process chat-chunks in larger batches\n",
    "        cursor = self.chat_chunks_collection.find(\n",
    "            {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}},  # Only get chat-chunks with dominant_topic\n",
    "            projection={'dominant_topic': 1}  # Only fetch the field we need\n",
    "        ).batch_size(batch_size)\n",
    "        \n",
    "        batch = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for chat_chunk in cursor:\n",
    "            batch.append(chat_chunk)\n",
    "            \n",
    "            if len(batch) >= batch_size:\n",
    "                batch_count += 1\n",
    "                print(f\"\\n--- Processing batch {batch_count} ({len(batch)} chat-chunks) ---\")\n",
    "                \n",
    "                # Process batch\n",
    "                bulk_operations = self.process_chat_chunks_batch(batch)\n",
    "                print(f\"Generated {len(bulk_operations)} update operations\")\n",
    "                \n",
    "                # Count matches for statistics\n",
    "                batch_cluster_matches = 0\n",
    "                batch_subcluster_matches = 0\n",
    "                for chat_chunk in batch:\n",
    "                    dominant_topic = chat_chunk.get('dominant_topic')\n",
    "                    if dominant_topic:\n",
    "                        if self.find_matching_cluster_fast(dominant_topic):\n",
    "                            matched_clusters += 1\n",
    "                            batch_cluster_matches += 1\n",
    "                        if self.find_matching_subcluster_fast(dominant_topic):\n",
    "                            matched_subclusters += 1\n",
    "                            batch_subcluster_matches += 1\n",
    "                \n",
    "                print(f\"Batch matches - Clusters: {batch_cluster_matches}, Subclusters: {batch_subcluster_matches}\")\n",
    "                \n",
    "                # Execute bulk update (or skip if dry run)\n",
    "                if bulk_operations and not dry_run:\n",
    "                    try:\n",
    "                        print(\"Executing bulk write...\")\n",
    "                        result = self.chat_chunks_collection.bulk_write(\n",
    "                            bulk_operations, \n",
    "                            ordered=False  # Faster unordered operations\n",
    "                        )\n",
    "                        total_updates += result.modified_count\n",
    "                        print(f\"✓ Updated {result.modified_count} documents in batch {batch_count}\")\n",
    "                        \n",
    "                        # Verify some updates\n",
    "                        if result.modified_count > 0:\n",
    "                            sample_updated = list(self.chat_chunks_collection.find(\n",
    "                                {\"kmeans_cluster_id\": {\"$exists\": True}},\n",
    "                                {\"dominant_topic\": 1, \"kmeans_cluster_id\": 1, \"subcluster_id\": 1}\n",
    "                            ).limit(3))\n",
    "                            print(f\"Sample updated documents: {len(sample_updated)} found with cluster IDs\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Bulk write error in batch {batch_count}: {e}\")\n",
    "                        print(f\"Error type: {type(e).__name__}\")\n",
    "                        # Show sample operation for debugging in readable format\n",
    "                        if bulk_operations:\n",
    "                            sample_op = bulk_operations[0]\n",
    "                            print(f\"Sample operation: Update {sample_op._filter} with {sample_op._doc}\")\n",
    "                elif bulk_operations and dry_run:\n",
    "                    print(f\"DRY RUN: Would update {len(bulk_operations)} documents\")\n",
    "                    # Show sample operations in readable format\n",
    "                    for i, op in enumerate(bulk_operations[:3]):\n",
    "                        print(f\"Sample operation {i+1}: Update {op._filter} with {op._doc}\")\n",
    "                else:\n",
    "                    print(\"No operations to execute (no matches found)\")\n",
    "                \n",
    "                processed += len(batch)\n",
    "                batch = []\n",
    "                \n",
    "                # Progress update\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = processed / elapsed if elapsed > 0 else 0\n",
    "                print(f\"Progress: {processed} chat-chunks processed ({rate:.1f} chat-chunks/sec)\")\n",
    "        \n",
    "        # Process remaining chat-chunks in the last batch\n",
    "        if batch:\n",
    "            batch_count += 1\n",
    "            print(f\"\\n--- Processing final batch {batch_count} ({len(batch)} chat-chunks) ---\")\n",
    "            \n",
    "            bulk_operations = self.process_chat_chunks_batch(batch)\n",
    "            print(f\"Generated {len(bulk_operations)} update operations\")\n",
    "            \n",
    "            # Count matches for final batch\n",
    "            batch_cluster_matches = 0\n",
    "            batch_subcluster_matches = 0\n",
    "            for chat_chunk in batch:\n",
    "                dominant_topic = chat_chunk.get('dominant_topic')\n",
    "                if dominant_topic:\n",
    "                    if self.find_matching_cluster_fast(dominant_topic):\n",
    "                        matched_clusters += 1\n",
    "                        batch_cluster_matches += 1\n",
    "                    if self.find_matching_subcluster_fast(dominant_topic):\n",
    "                        matched_subclusters += 1\n",
    "                        batch_subcluster_matches += 1\n",
    "            \n",
    "            print(f\"Final batch matches - Clusters: {batch_cluster_matches}, Subclusters: {batch_subcluster_matches}\")\n",
    "            \n",
    "            if bulk_operations and not dry_run:\n",
    "                try:\n",
    "                    print(\"Executing final bulk write...\")\n",
    "                    result = self.chat_chunks_collection.bulk_write(\n",
    "                        bulk_operations, \n",
    "                        ordered=False\n",
    "                    )\n",
    "                    total_updates += result.modified_count\n",
    "                    print(f\"✓ Updated {result.modified_count} documents in final batch\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Bulk write error in final batch: {e}\")\n",
    "                    print(f\"Error type: {type(e).__name__}\")\n",
    "            elif bulk_operations and dry_run:\n",
    "                print(f\"DRY RUN: Would update {len(bulk_operations)} documents\")\n",
    "            \n",
    "            processed += len(batch)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Final verification\n",
    "        if not dry_run and total_updates > 0:\n",
    "            print(f\"\\n--- Verification ---\")\n",
    "            updated_count = self.chat_chunks_collection.count_documents({\"kmeans_cluster_id\": {\"$exists\": True}})\n",
    "            print(f\"Total chat-chunk documents with kmeans_cluster_id: {updated_count}\")\n",
    "            \n",
    "            subcluster_count = self.chat_chunks_collection.count_documents({\"subcluster_id\": {\"$exists\": True}})\n",
    "            print(f\"Total chat-chunk documents with subcluster_id: {subcluster_count}\")\n",
    "        \n",
    "        stats = {\n",
    "            'total_chat_chunks': processed,\n",
    "            'matched_clusters': matched_clusters,\n",
    "            'matched_subclusters': matched_subclusters,\n",
    "            'total_updates': total_updates,\n",
    "            'processing_time': total_time,\n",
    "            'chat_chunks_per_second': processed / total_time if total_time > 0 else 0,\n",
    "            'cluster_match_rate': (matched_clusters / processed * 100) if processed > 0 else 0,\n",
    "            'subcluster_match_rate': (matched_subclusters / processed * 100) if processed > 0 else 0,\n",
    "            'dry_run': dry_run\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def process_with_fallback(self, batch_size: int = 5000, dry_run: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Process chat-chunks with automatic fallback cluster for unmatched topics\n",
    "        \"\"\"\n",
    "        print(\"=== PROCESSING CHAT-CHUNKS WITH FALLBACK CLUSTER ===\")\n",
    "        \n",
    "        # First, analyze gaps\n",
    "        gaps = self.analyze_matching_gaps()\n",
    "        \n",
    "        if gaps['unmatched_chat_chunk_count'] > 0:\n",
    "            print(f\"Found {gaps['unmatched_chat_chunk_count']} unmatched chat-chunks\")\n",
    "            print(f\"Unmatched topics: {list(gaps['unmatched_details'].keys())}\")\n",
    "            \n",
    "            # Add fallback cluster to cache\n",
    "            unmatched_topic_list = list(gaps['unmatched_details'].keys())\n",
    "            self.add_fallback_cluster_to_cache(unmatched_topic_list)\n",
    "            \n",
    "            # Optionally save fallback cluster to database\n",
    "            save_choice = input(\"Save fallback cluster to database permanently? (y/n): \")\n",
    "            if save_choice.lower() == 'y':\n",
    "                fallback_cluster = self.create_fallback_cluster_entry(unmatched_topic_list)\n",
    "                try:\n",
    "                    self.clusters_collection.insert_one(fallback_cluster)\n",
    "                    print(\"✓ Fallback cluster saved to database\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️  Could not save fallback cluster: {e}\")\n",
    "        \n",
    "        # Now process all chat-chunks (should be 100% match rate)\n",
    "        return self.process_chat_chunks_optimized(batch_size=batch_size, dry_run=dry_run)\n",
    "    \n",
    "    def get_performance_stats(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Get database performance statistics\n",
    "        \"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        # Collection sizes\n",
    "        stats['total_chat_chunks'] = self.chat_chunks_collection.estimated_document_count()\n",
    "        stats['chat_chunks_with_topic'] = self.chat_chunks_collection.count_documents({\n",
    "            \"dominant_topic\": {\"$exists\": True, \"$ne\": None}\n",
    "        })\n",
    "        stats['total_chat_chunk_clusters'] = self.clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        stats['total_all_clusters'] = self.clusters_collection.estimated_document_count()\n",
    "        \n",
    "        # Cache statistics\n",
    "        stats['cached_cluster_keyphrases'] = len(self._cluster_cache) if self._cluster_cache else 0\n",
    "        stats['cached_subcluster_keyphrases'] = len(self._subcluster_cache) if self._subcluster_cache else 0\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def debug_matching_process(self, limit: int = 5) -> None:\n",
    "        \"\"\"\n",
    "        Debug the matching process to see what's happening with chat-chunks\n",
    "        \"\"\"\n",
    "        print(\"\\n=== DEBUGGING CHAT-CHUNK MATCHING PROCESS ===\")\n",
    "        \n",
    "        # Check if we have any cluster data\n",
    "        if not self._cluster_cache and not self._subcluster_cache:\n",
    "            print(\"❌ NO CHAT-CHUNK CLUSTER CACHE DATA! This is why updates are failing.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✓ Chat-chunk cluster cache has {len(self._cluster_cache)} entries\")\n",
    "        print(f\"✓ Chat-chunk subcluster cache has {len(self._subcluster_cache)} entries\")\n",
    "        \n",
    "        # Sample some cluster keyphrases\n",
    "        print(f\"\\nSample chat-chunk cluster keyphrases:\")\n",
    "        for i, keyphrase in enumerate(list(self._cluster_cache.keys())[:10]):\n",
    "            cluster_info = self._cluster_cache[keyphrase]\n",
    "            print(f\"  {i+1}. '{keyphrase}' -> Cluster {cluster_info['cluster_id']}\")\n",
    "        \n",
    "        # Sample some subcluster keyphrases  \n",
    "        print(f\"\\nSample chat-chunk subcluster keyphrases:\")\n",
    "        for i, keyphrase in enumerate(list(self._subcluster_cache.keys())[:10]):\n",
    "            subcluster_info = self._subcluster_cache[keyphrase]\n",
    "            print(f\"  {i+1}. '{keyphrase}' -> Cluster {subcluster_info['cluster_id']}, Subcluster {subcluster_info['subcluster_id']}\")\n",
    "        \n",
    "        # Check some actual chat-chunks\n",
    "        print(f\"\\n=== TESTING {limit} CHAT-CHUNKS ===\")\n",
    "        chat_chunks = list(self.chat_chunks_collection.find(\n",
    "            {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}}\n",
    "        ).limit(limit))\n",
    "        \n",
    "        if not chat_chunks:\n",
    "            print(\"❌ NO CHAT-CHUNKS with dominant_topic found!\")\n",
    "            return\n",
    "        \n",
    "        for i, chat_chunk in enumerate(chat_chunks, 1):\n",
    "            dominant_topic = chat_chunk.get('dominant_topic', 'NO_TOPIC')\n",
    "            print(f\"\\n--- Chat-Chunk {i} ---\")\n",
    "            print(f\"Chat-Chunk ID: {chat_chunk['_id']}\")\n",
    "            print(f\"Dominant Topic: '{dominant_topic}'\")\n",
    "            \n",
    "            # Test cluster matching\n",
    "            cluster_match = self.find_matching_cluster_fast(dominant_topic)\n",
    "            if cluster_match:\n",
    "                print(f\"✓ CLUSTER MATCH: ID={cluster_match['cluster_id']}, Label='{cluster_match['dominant_label']}'\")\n",
    "            else:\n",
    "                print(f\"❌ No cluster match for '{dominant_topic}'\")\n",
    "            \n",
    "            # Test subcluster matching  \n",
    "            subcluster_match = self.find_matching_subcluster_fast(dominant_topic)\n",
    "            if subcluster_match:\n",
    "                print(f\"✓ SUBCLUSTER MATCH: Cluster={subcluster_match['cluster_id']}, Subcluster={subcluster_match['subcluster_id']}, Label='{subcluster_match['subcluster_label']}'\")\n",
    "            else:\n",
    "                print(f\"❌ No subcluster match for '{dominant_topic}'\")\n",
    "            \n",
    "            # Show what the update operation would look like\n",
    "            update_data = {}\n",
    "            if cluster_match:\n",
    "                update_data.update({\n",
    "                    'kmeans_cluster_id': cluster_match['cluster_id'],\n",
    "                    'dominant_label': cluster_match['dominant_label']\n",
    "                })\n",
    "            if subcluster_match:\n",
    "                update_data.update({\n",
    "                    'kmeans_cluster_id': subcluster_match['cluster_id'],\n",
    "                    'dominant_label': subcluster_match['dominant_label'],\n",
    "                    'subcluster_id': subcluster_match['subcluster_id'],\n",
    "                    'subcluster_label': subcluster_match['subcluster_label']\n",
    "                })\n",
    "            \n",
    "            if update_data:\n",
    "                print(f\"UPDATE OPERATION: {update_data}\")\n",
    "            else:\n",
    "                print(\"NO UPDATE OPERATION (no matches)\")\n",
    "        \n",
    "        print(f\"\\n=== DATABASE STATE CHECK ===\")\n",
    "        # Check existing updates\n",
    "        existing_with_cluster = self.chat_chunks_collection.count_documents({\"kmeans_cluster_id\": {\"$exists\": True}})\n",
    "        existing_with_subcluster = self.chat_chunks_collection.count_documents({\"subcluster_id\": {\"$exists\": True}})\n",
    "        chat_chunks_with_topic = self.chat_chunks_collection.count_documents({\"dominant_topic\": {\"$exists\": True, \"$ne\": None}})\n",
    "        \n",
    "        print(f\"Chat-chunks with dominant_topic: {chat_chunks_with_topic}\")\n",
    "        print(f\"Chat-chunks already with kmeans_cluster_id: {existing_with_cluster}\")\n",
    "        print(f\"Chat-chunks already with subcluster_id: {existing_with_subcluster}\")\n",
    "        \n",
    "        if chat_chunks_with_topic == 0:\n",
    "            print(\"❌ PROBLEM: No chat-chunks have 'dominant_topic' field!\")\n",
    "        elif existing_with_cluster == chat_chunks_with_topic:\n",
    "            print(\"✓ All chat-chunks already processed!\")\n",
    "        else:\n",
    "            print(f\"📝 {chat_chunks_with_topic - existing_with_cluster} chat-chunks need processing\")\n",
    "    \n",
    "    def get_preview(self, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get a preview of chat-chunk-cluster matches for testing\n",
    "        \"\"\"\n",
    "        chat_chunks = list(self.chat_chunks_collection.find(\n",
    "            {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}}\n",
    "        ).limit(limit))\n",
    "        \n",
    "        preview = []\n",
    "        \n",
    "        for chat_chunk in chat_chunks:\n",
    "            dominant_topic = chat_chunk.get('dominant_topic')\n",
    "            if not dominant_topic:\n",
    "                continue\n",
    "            \n",
    "            cluster_match = self.find_matching_cluster_fast(dominant_topic)\n",
    "            subcluster_match = self.find_matching_subcluster_fast(dominant_topic)\n",
    "            \n",
    "            preview.append({\n",
    "                'chat_chunk_id': str(chat_chunk['_id']),\n",
    "                'dominant_topic': dominant_topic,\n",
    "                'cluster_match': cluster_match,\n",
    "                'subcluster_match': subcluster_match\n",
    "            })\n",
    "        \n",
    "        return preview\n",
    "    \n",
    "    def close_connection(self):\n",
    "        \"\"\"Close MongoDB connection\"\"\"\n",
    "        self.client.close()\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    # Get configuration from environment variables\n",
    "    CONNECTION_STRING = os.getenv('MONGO_CONNECTION_STRING')\n",
    "    DATABASE_NAME = os.getenv('MONGO_DATABASE_NAME')\n",
    "    \n",
    "    if not CONNECTION_STRING:\n",
    "        raise ValueError(\"MONGO_CONNECTION_STRING not found in environment variables\")\n",
    "    if not DATABASE_NAME:\n",
    "        raise ValueError(\"MONGO_DATABASE_NAME not found in environment variables\")\n",
    "    \n",
    "    print(f\"Connecting to database: {DATABASE_NAME}\")\n",
    "    \n",
    "    # Initialize optimized chat-chunk matcher\n",
    "    matcher = OptimizedChatChunkClusterMatcher(CONNECTION_STRING, DATABASE_NAME)\n",
    "    \n",
    "    try:\n",
    "        # Show performance stats\n",
    "        print(\"\\n--- Database Statistics ---\")\n",
    "        perf_stats = matcher.get_performance_stats()\n",
    "        for key, value in perf_stats.items():\n",
    "            print(f\"{key}: {value:,}\")\n",
    "        \n",
    "        # Analyze matching gaps\n",
    "        print(\"\\n--- Gap Analysis ---\")\n",
    "        gap_choice = input(\"Analyze which chat-chunks aren't matching? (y/n): \")\n",
    "        if gap_choice.lower() == 'y':\n",
    "            gaps = matcher.analyze_matching_gaps()\n",
    "            print(f\"\\n=== MATCHING GAP ANALYSIS ===\")\n",
    "            print(f\"Total unique topics: {gaps['total_topics']}\")\n",
    "            print(f\"Matched topics: {gaps['matched_topics']}\")\n",
    "            print(f\"Unmatched topics: {gaps['unmatched_topics']}\")\n",
    "            print(f\"Matched chat-chunks: {gaps['matched_chat_chunk_count']}\")\n",
    "            print(f\"Unmatched chat-chunks: {gaps['unmatched_chat_chunk_count']}\")\n",
    "            \n",
    "            if gaps['unmatched_details']:\n",
    "                print(f\"\\n--- UNMATCHED DOMINANT TOPICS ---\")\n",
    "                for topic, count in list(gaps['unmatched_details'].items())[:10]:\n",
    "                    print(f\"'{topic}' - {count} chat-chunks\")\n",
    "                \n",
    "                if len(gaps['unmatched_details']) > 10:\n",
    "                    print(f\"... and {len(gaps['unmatched_details']) - 10} more\")\n",
    "                \n",
    "                print(f\"\\n💡 To get 100% matches, you need to:\")\n",
    "                print(f\"1. Add these topics to your chat-chunk cluster keyphrases, OR\")\n",
    "                print(f\"2. Create a 'catch-all' cluster for unmatched chat-chunk topics\")\n",
    "        \n",
    "        # Debug the matching process first\n",
    "        print(\"\\n--- Debugging Mode ---\")\n",
    "        debug_choice = input(\"Run debug mode to see why DB isn't updating? (y/n): \")\n",
    "        if debug_choice.lower() == 'y':\n",
    "            matcher.debug_matching_process()\n",
    "        \n",
    "        # Get a preview first\n",
    "        print(\"\\n--- Preview of Chat-Chunk Matches ---\")\n",
    "        preview = matcher.get_preview(limit=5)\n",
    "        \n",
    "        for i, item in enumerate(preview, 1):\n",
    "            print(f\"\\n--- Chat-Chunk {i} ---\")\n",
    "            print(f\"Dominant Topic: {item['dominant_topic']}\")\n",
    "            \n",
    "            if item['subcluster_match']:\n",
    "                print(f\"✓ Subcluster Match: Cluster ID={item['subcluster_match']['cluster_id']}, \"\n",
    "                      f\"Subcluster ID={item['subcluster_match']['subcluster_id']}, \"\n",
    "                      f\"Label={item['subcluster_match']['subcluster_label']}\")\n",
    "            elif item['cluster_match']:\n",
    "                print(f\"✓ Cluster Match: ID={item['cluster_match']['cluster_id']}, \"\n",
    "                      f\"Label={item['cluster_match']['dominant_label']}\")\n",
    "            else:\n",
    "                print(\"✗ No match found\")\n",
    "        \n",
    "        # Process all chat-chunks\n",
    "        print(\"\\n--- Processing Options ---\")\n",
    "        print(\"1. Dry run (see what would be updated without changing DB)\")\n",
    "        print(\"2. Full processing (actually update the database)\")\n",
    "        print(\"3. Process with fallback cluster (100% match guarantee)\")\n",
    "        choice = input(\"Choose option (1, 2, or 3): \")\n",
    "        \n",
    "        if choice in ['1', '2', '3']:\n",
    "            if choice == '3':\n",
    "                # Use fallback processing\n",
    "                dry_run = False\n",
    "                fallback_choice = input(\"Dry run with fallback first? (y/n): \")\n",
    "                if fallback_choice.lower() == 'y':\n",
    "                    dry_run = True\n",
    "                \n",
    "                print(f\"\\nStarting {'DRY RUN' if dry_run else 'LIVE'} processing with fallback...\")\n",
    "                batch_size = int(input(\"Enter batch size (recommended: 5000-10000): \") or \"5000\")\n",
    "                stats = matcher.process_with_fallback(batch_size=batch_size, dry_run=dry_run)\n",
    "            else:\n",
    "                # Regular processing\n",
    "                dry_run = (choice == '1')\n",
    "                \n",
    "                print(f\"\\nStarting {'DRY RUN' if dry_run else 'LIVE PROCESSING'}...\")\n",
    "                \n",
    "                # Use larger batch size for better performance\n",
    "                batch_size = int(input(\"Enter batch size (recommended: 5000-10000): \") or \"5000\")\n",
    "                \n",
    "                stats = matcher.process_chat_chunks_optimized(batch_size=batch_size, dry_run=dry_run)\n",
    "            \n",
    "            print(\"\\n--- Final Results ---\")\n",
    "            print(f\"Total chat-chunks processed: {stats['total_chat_chunks']:,}\")\n",
    "            print(f\"Total updates made: {stats['total_updates']:,}\")\n",
    "            print(f\"Cluster matches: {stats['matched_clusters']:,} ({stats['cluster_match_rate']:.1f}%)\")\n",
    "            print(f\"Subcluster matches: {stats['matched_subclusters']:,} ({stats['subcluster_match_rate']:.1f}%)\")\n",
    "            print(f\"Processing time: {stats['processing_time']:.2f} seconds\")\n",
    "            print(f\"Processing rate: {stats['chat_chunks_per_second']:.1f} chat-chunks/second\")\n",
    "        \n",
    "    finally:\n",
    "        matcher.close_connection()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3279007b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MongoDB...\n",
      "Database: sparzaai\n",
      "============================================================\n",
      "✓ Database connection successful\n",
      "Sample chat-chunk fields: ['_id', 'chat_id', 'chat_members', 'dominant_topic', 'subtopics', 'raw_segments', 'embeddings', 'kmeans_cluster_id', 'subcluster_id', 'subcluster_label', 'dominant_cluster_label', 'kmeans_cluster_keyphrase', 'domain', 'dominant_label']\n",
      "\n",
      "\n",
      "==================================================\n",
      "CHAT-CHUNK COLLECTION STRUCTURE ANALYSIS\n",
      "==================================================\n",
      "Available fields in sample chat-chunk document:\n",
      "  - _id: ObjectId\n",
      "  - chat_id: str\n",
      "  - chat_members: list\n",
      "  - domain: str\n",
      "  - dominant_cluster_label: NoneType\n",
      "  - dominant_label: str\n",
      "  - dominant_topic: str\n",
      "  - embeddings: list\n",
      "  - kmeans_cluster_id: int\n",
      "  - kmeans_cluster_keyphrase: str\n",
      "  - raw_segments: list\n",
      "  - subcluster_id: int\n",
      "  - subcluster_label: str\n",
      "  - subtopics: str\n",
      "\n",
      "Field frequency analysis (top 15 fields):\n",
      "  subtopics: 600/600 documents (100.0%)\n",
      "  embeddings: 600/600 documents (100.0%)\n",
      "  _id: 600/600 documents (100.0%)\n",
      "  kmeans_cluster_id: 600/600 documents (100.0%)\n",
      "  dominant_cluster_label: 600/600 documents (100.0%)\n",
      "  dominant_topic: 600/600 documents (100.0%)\n",
      "  kmeans_cluster_keyphrase: 600/600 documents (100.0%)\n",
      "  domain: 600/600 documents (100.0%)\n",
      "  subcluster_id: 600/600 documents (100.0%)\n",
      "  dominant_label: 600/600 documents (100.0%)\n",
      "  subcluster_label: 600/600 documents (100.0%)\n",
      "  chat_members: 600/600 documents (100.0%)\n",
      "  raw_segments: 600/600 documents (100.0%)\n",
      "  chat_id: 600/600 documents (100.0%)\n",
      "💬 Starting chat-chunk field rename process...\n",
      "Fields to rename:\n",
      "  - is_urgent → urgency\n",
      "  - dominant_label → dominant_cluster_label\n",
      "--------------------------------------------------\n",
      "Total chat-chunks in collection: 600\n",
      "Chat-chunks with 'is_urgent' field: 0\n",
      "Chat-chunks with 'dominant_label' field: 600\n",
      "Chat-chunks already with 'urgency' field: 0\n",
      "Chat-chunks already with 'dominant_cluster_label' field: 600\n",
      "\n",
      "==================================================\n",
      "RENAMING CHAT-CHUNK FIELDS...\n",
      "==================================================\n",
      "✓ Field rename operation completed:\n",
      "  Matched chat-chunks: 600\n",
      "  Modified chat-chunks: 600\n",
      "  Operation acknowledged: True\n",
      "\n",
      "==================================================\n",
      "VERIFICATION OF CHAT-CHUNK FIELD RENAME\n",
      "==================================================\n",
      "Sample chat-chunk document after rename:\n",
      "  Chat-chunk ID: 68a8525133508dc58e3ead33\n",
      "  Has 'urgency' field: False\n",
      "  Has 'dominant_cluster_label' field: True\n",
      "  Has old 'is_urgent' field: False\n",
      "  Has old 'dominant_label' field: False\n",
      "  Sample 'dominant_cluster_label' value: Business & Financial Planning\n",
      "\n",
      "Field counts after rename:\n",
      "  Chat-chunks with 'urgency' field: 0\n",
      "  Chat-chunks with 'dominant_cluster_label' field: 600\n",
      "  Chat-chunks with old 'is_urgent' field: 0\n",
      "  Chat-chunks with old 'dominant_label' field: 0\n",
      "\n",
      "✅ SUCCESS: All chat-chunk fields have been renamed successfully!\n",
      "\n",
      "==================================================\n",
      "CHAT-CHUNK FIELD STATISTICS\n",
      "==================================================\n",
      "Total chat-chunks: 600\n",
      "\n",
      "No chat-chunks found with 'urgency' field\n",
      "\n",
      "Top 10 dominant cluster labels:\n",
      "  1. 'Workforce & HR Management': 98 chat-chunks (16.3%)\n",
      "  2. 'Customer & Sales Strategy': 69 chat-chunks (11.5%)\n",
      "  3. 'Internal Audit & Reporting': 68 chat-chunks (11.3%)\n",
      "  4. 'Compliance & Policy': 61 chat-chunks (10.2%)\n",
      "  5. 'Operational Processes & Workflow': 59 chat-chunks (9.8%)\n",
      "  6. 'IT Security & Support': 59 chat-chunks (9.8%)\n",
      "  7. 'External Relations & Vendor Management': 55 chat-chunks (9.2%)\n",
      "  8. 'IT Infrastructure & Systems': 46 chat-chunks (7.7%)\n",
      "  9. 'Business & Financial Planning': 45 chat-chunks (7.5%)\n",
      "  10. 'Risk & Control Management': 40 chat-chunks (6.7%)\n",
      "\n",
      "==================================================\n",
      "SAMPLE CHAT-CHUNK DOCUMENTS\n",
      "==================================================\n",
      "No chat-chunks found with both renamed fields\n",
      "\n",
      "============================================================\n",
      "✅ Chat-chunk field rename process completed successfully!\n",
      "Fields renamed:\n",
      "  - is_urgent → urgency\n",
      "  - dominant_label → dominant_cluster_label\n",
      "============================================================\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not mongo_connection_string or not mongo_database_name:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "print(f\"Connecting to MongoDB...\")\n",
    "print(f\"Database: {mongo_database_name}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_connection_string)\n",
    "db = client[mongo_database_name]\n",
    "chat_chunks_collection = db['chat-chunks']\n",
    "\n",
    "def rename_chat_chunk_fields():\n",
    "    \"\"\"\n",
    "    Rename fields in chat-chunk documents:\n",
    "    - is_urgent -> urgency\n",
    "    - dominant_label -> dominant_cluster_label\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"💬 Starting chat-chunk field rename process...\")\n",
    "    print(\"Fields to rename:\")\n",
    "    print(\"  - is_urgent → urgency\")\n",
    "    print(\"  - dominant_label → dominant_cluster_label\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Check current state before rename\n",
    "        total_chat_chunks = chat_chunks_collection.count_documents({})\n",
    "        print(f\"Total chat-chunks in collection: {total_chat_chunks}\")\n",
    "        \n",
    "        if total_chat_chunks == 0:\n",
    "            print(\"⚠ No chat-chunks found in collection\")\n",
    "            return\n",
    "        \n",
    "        # Count existing fields before rename\n",
    "        is_urgent_count = chat_chunks_collection.count_documents({\"is_urgent\": {\"$exists\": True}})\n",
    "        dominant_label_count = chat_chunks_collection.count_documents({\"dominant_label\": {\"$exists\": True}})\n",
    "        \n",
    "        print(f\"Chat-chunks with 'is_urgent' field: {is_urgent_count}\")\n",
    "        print(f\"Chat-chunks with 'dominant_label' field: {dominant_label_count}\")\n",
    "        \n",
    "        # Count already renamed fields\n",
    "        urgency_count = chat_chunks_collection.count_documents({\"urgency\": {\"$exists\": True}})\n",
    "        dominant_cluster_label_count = chat_chunks_collection.count_documents({\"dominant_cluster_label\": {\"$exists\": True}})\n",
    "        \n",
    "        print(f\"Chat-chunks already with 'urgency' field: {urgency_count}\")\n",
    "        print(f\"Chat-chunks already with 'dominant_cluster_label' field: {dominant_cluster_label_count}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"RENAMING CHAT-CHUNK FIELDS...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Rename both fields in a single operation for all chat-chunks\n",
    "        result = chat_chunks_collection.update_many(\n",
    "            {},  # Empty filter to match all chat-chunk documents\n",
    "            {\n",
    "                \"$rename\": {\n",
    "                    \"is_urgent\": \"urgency\",\n",
    "                    \"dominant_label\": \"dominant_cluster_label\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"✓ Field rename operation completed:\")\n",
    "        print(f\"  Matched chat-chunks: {result.matched_count}\")\n",
    "        print(f\"  Modified chat-chunks: {result.modified_count}\")\n",
    "        print(f\"  Operation acknowledged: {result.acknowledged}\")\n",
    "        \n",
    "        # Verify the changes\n",
    "        verify_rename_changes()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during chat-chunk field rename: {str(e)}\")\n",
    "\n",
    "def verify_rename_changes():\n",
    "    \"\"\"\n",
    "    Verify that the field rename was successful\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"VERIFICATION OF CHAT-CHUNK FIELD RENAME\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Verify the changes by checking a sample chat-chunk document\n",
    "        sample_chat_chunk = chat_chunks_collection.find_one()\n",
    "        if sample_chat_chunk:\n",
    "            print(\"Sample chat-chunk document after rename:\")\n",
    "            print(f\"  Chat-chunk ID: {sample_chat_chunk.get('_id')}\")\n",
    "            print(f\"  Has 'urgency' field: {'urgency' in sample_chat_chunk}\")\n",
    "            print(f\"  Has 'dominant_cluster_label' field: {'dominant_cluster_label' in sample_chat_chunk}\")\n",
    "            print(f\"  Has old 'is_urgent' field: {'is_urgent' in sample_chat_chunk}\")\n",
    "            print(f\"  Has old 'dominant_label' field: {'dominant_label' in sample_chat_chunk}\")\n",
    "            \n",
    "            # Show sample values if they exist\n",
    "            if 'urgency' in sample_chat_chunk:\n",
    "                print(f\"  Sample 'urgency' value: {sample_chat_chunk['urgency']}\")\n",
    "            if 'dominant_cluster_label' in sample_chat_chunk:\n",
    "                print(f\"  Sample 'dominant_cluster_label' value: {sample_chat_chunk['dominant_cluster_label']}\")\n",
    "        else:\n",
    "            print(\"⚠ No chat-chunk documents found in the collection\")\n",
    "        \n",
    "        # Count chat-chunks with the new field names\n",
    "        urgency_count = chat_chunks_collection.count_documents({\"urgency\": {\"$exists\": True}})\n",
    "        cluster_label_count = chat_chunks_collection.count_documents({\"dominant_cluster_label\": {\"$exists\": True}})\n",
    "        \n",
    "        # Count chat-chunks with old field names (should be 0 after rename)\n",
    "        old_is_urgent_count = chat_chunks_collection.count_documents({\"is_urgent\": {\"$exists\": True}})\n",
    "        old_dominant_label_count = chat_chunks_collection.count_documents({\"dominant_label\": {\"$exists\": True}})\n",
    "        \n",
    "        print(f\"\\nField counts after rename:\")\n",
    "        print(f\"  Chat-chunks with 'urgency' field: {urgency_count}\")\n",
    "        print(f\"  Chat-chunks with 'dominant_cluster_label' field: {cluster_label_count}\")\n",
    "        print(f\"  Chat-chunks with old 'is_urgent' field: {old_is_urgent_count}\")\n",
    "        print(f\"  Chat-chunks with old 'dominant_label' field: {old_dominant_label_count}\")\n",
    "        \n",
    "        # Success check\n",
    "        if old_is_urgent_count == 0 and old_dominant_label_count == 0:\n",
    "            print(\"\\n✅ SUCCESS: All chat-chunk fields have been renamed successfully!\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ WARNING: Some chat-chunks still have old field names\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during verification: {str(e)}\")\n",
    "\n",
    "def get_chat_chunk_field_statistics():\n",
    "    \"\"\"\n",
    "    Get detailed statistics about chat-chunk fields after rename\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CHAT-CHUNK FIELD STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        total_chat_chunks = chat_chunks_collection.count_documents({})\n",
    "        \n",
    "        # Get statistics for new field names\n",
    "        urgency_stats = list(chat_chunks_collection.aggregate([\n",
    "            {\"$match\": {\"urgency\": {\"$exists\": True}}},\n",
    "            {\"$group\": {\"_id\": \"$urgency\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]))\n",
    "        \n",
    "        cluster_label_stats = list(chat_chunks_collection.aggregate([\n",
    "            {\"$match\": {\"dominant_cluster_label\": {\"$exists\": True}}},\n",
    "            {\"$group\": {\"_id\": \"$dominant_cluster_label\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 10}  # Show top 10 cluster labels\n",
    "        ]))\n",
    "        \n",
    "        print(f\"Total chat-chunks: {total_chat_chunks}\")\n",
    "        \n",
    "        if urgency_stats:\n",
    "            print(f\"\\nUrgency field distribution:\")\n",
    "            for stat in urgency_stats:\n",
    "                urgency_value = stat['_id']\n",
    "                count = stat['count']\n",
    "                percentage = (count / total_chat_chunks) * 100 if total_chat_chunks > 0 else 0\n",
    "                print(f\"  '{urgency_value}': {count} chat-chunks ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"\\nNo chat-chunks found with 'urgency' field\")\n",
    "        \n",
    "        if cluster_label_stats:\n",
    "            print(f\"\\nTop 10 dominant cluster labels:\")\n",
    "            for i, stat in enumerate(cluster_label_stats, 1):\n",
    "                label = stat['_id'] if stat['_id'] is not None else 'null'\n",
    "                count = stat['count']\n",
    "                percentage = (count / total_chat_chunks) * 100 if total_chat_chunks > 0 else 0\n",
    "                print(f\"  {i}. '{label}': {count} chat-chunks ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"\\nNo chat-chunks found with 'dominant_cluster_label' field\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error getting chat-chunk statistics: {str(e)}\")\n",
    "\n",
    "def show_sample_chat_chunks():\n",
    "    \"\"\"\n",
    "    Show sample chat-chunk documents with renamed fields\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SAMPLE CHAT-CHUNK DOCUMENTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Get sample chat-chunks with both new fields\n",
    "        sample_chat_chunks = list(chat_chunks_collection.find(\n",
    "            {\n",
    "                \"urgency\": {\"$exists\": True},\n",
    "                \"dominant_cluster_label\": {\"$exists\": True}\n",
    "            },\n",
    "            {\n",
    "                \"_id\": 1,\n",
    "                \"urgency\": 1,\n",
    "                \"dominant_cluster_label\": 1,\n",
    "                \"content\": 1,      # Include content if it exists\n",
    "                \"message\": 1,      # Include message if it exists\n",
    "                \"text\": 1,         # Include text if it exists\n",
    "                \"chunk_text\": 1,   # Include chunk_text if it exists\n",
    "                \"priority\": 1      # Include priority if it exists\n",
    "            }\n",
    "        ).limit(3))\n",
    "        \n",
    "        if sample_chat_chunks:\n",
    "            print(\"Sample chat-chunks with renamed fields:\")\n",
    "            for i, chat_chunk in enumerate(sample_chat_chunks, 1):\n",
    "                print(f\"\\nChat-chunk {i}:\")\n",
    "                print(f\"  ID: {chat_chunk.get('_id')}\")\n",
    "                print(f\"  Urgency: {chat_chunk.get('urgency', 'N/A')}\")\n",
    "                print(f\"  Dominant Cluster Label: {chat_chunk.get('dominant_cluster_label', 'N/A')}\")\n",
    "                \n",
    "                # Show text content from various possible field names\n",
    "                content_fields = ['content', 'message', 'text', 'chunk_text']\n",
    "                for field in content_fields:\n",
    "                    if field in chat_chunk and chat_chunk[field]:\n",
    "                        content = str(chat_chunk[field])[:100] + \"...\" if len(str(chat_chunk[field])) > 100 else chat_chunk[field]\n",
    "                        print(f\"  {field.title()}: {content}\")\n",
    "                        break\n",
    "                \n",
    "                if 'priority' in chat_chunk:\n",
    "                    print(f\"  Priority: {chat_chunk.get('priority', 'N/A')}\")\n",
    "        else:\n",
    "            print(\"No chat-chunks found with both renamed fields\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error showing sample chat-chunks: {str(e)}\")\n",
    "\n",
    "def check_collection_structure():\n",
    "    \"\"\"\n",
    "    Check the structure of chat-chunk documents to understand available fields\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CHAT-CHUNK COLLECTION STRUCTURE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Get a sample document to see its structure\n",
    "        sample_doc = chat_chunks_collection.find_one()\n",
    "        if sample_doc:\n",
    "            print(\"Available fields in sample chat-chunk document:\")\n",
    "            for field in sorted(sample_doc.keys()):\n",
    "                field_type = type(sample_doc[field]).__name__\n",
    "                print(f\"  - {field}: {field_type}\")\n",
    "        \n",
    "        # Get field frequency analysis\n",
    "        print(f\"\\nField frequency analysis (top 15 fields):\")\n",
    "        pipeline = [\n",
    "            {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},\n",
    "            {\"$unwind\": \"$fields\"},\n",
    "            {\"$group\": {\"_id\": \"$fields.k\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 15}\n",
    "        ]\n",
    "        \n",
    "        field_stats = list(chat_chunks_collection.aggregate(pipeline))\n",
    "        for stat in field_stats:\n",
    "            field_name = stat['_id']\n",
    "            count = stat['count']\n",
    "            total_docs = chat_chunks_collection.count_documents({})\n",
    "            percentage = (count / total_docs) * 100 if total_docs > 0 else 0\n",
    "            print(f\"  {field_name}: {count}/{total_docs} documents ({percentage:.1f}%)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error analyzing collection structure: {str(e)}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Test database connection\n",
    "        test_chat_chunk = chat_chunks_collection.find_one()\n",
    "        if test_chat_chunk:\n",
    "            print(\"✓ Database connection successful\")\n",
    "            print(f\"Sample chat-chunk fields: {list(test_chat_chunk.keys())}\\n\")\n",
    "        else:\n",
    "            print(\"⚠ No chat-chunks found in chat-chunks collection\")\n",
    "            print(\"Please ensure you have chat-chunk documents before running this script\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Check collection structure first\n",
    "        check_collection_structure()\n",
    "        \n",
    "        # Execute the field rename for chat-chunks\n",
    "        rename_chat_chunk_fields()\n",
    "        \n",
    "        # Get detailed statistics\n",
    "        get_chat_chunk_field_statistics()\n",
    "        \n",
    "        # Show sample chat-chunks\n",
    "        show_sample_chat_chunks()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✅ Chat-chunk field rename process completed successfully!\")\n",
    "        print(\"Fields renamed:\")\n",
    "        print(\"  - is_urgent → urgency\")\n",
    "        print(\"  - dominant_label → dominant_cluster_label\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during execution: {str(e)}\")\n",
    "        print(\"Please check your environment variables and database connection.\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a871e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database: sparzaai\n",
      "Processing chat-chunks with chat-chunk clusters (data: 'chat-chunks')\n",
      "Loading chat-chunk cluster keyphrase cache...\n",
      "Found 10 chat-chunk clusters to process\n",
      "Chat-chunk cluster cache loaded in 1.75 seconds\n",
      "Cached 65 chat-chunk cluster keyphrases\n",
      "\n",
      "--- Current Chat-Chunk Statistics ---\n",
      "total_chat_chunks_with_topic: 600\n",
      "chat_chunks_with_keyphrase_field: 600\n",
      "unique_dominant_topics: 65\n",
      "matchable_topics: 65\n",
      "topic_match_rate: 100.0\n",
      "cached_chat_chunk_cluster_keyphrases: 65\n",
      "total_chat_chunk_clusters: 10\n",
      "\n",
      "--- Debug Mode ---\n",
      "\n",
      "=== DEBUGGING CHAT-CHUNK CLUSTER KEYPHRASE MATCHING ===\n",
      "✓ Chat-chunk cluster keyphrase cache: 65 entries\n",
      "\n",
      "Sample chat-chunk cluster keyphrases:\n",
      "  1. 'Shift Coverage Request' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  2. 'Training Schedule Update' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  3. 'Performance Review Planning' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  4. 'Break Schedule Coordination' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  5. 'Overtime Approval Need' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  6. 'Team Meeting Reminder' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  7. 'Staff Management Discussion' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  8. 'Workforce Planning Update' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  9. 'Employee Relations Coordination' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "  10. 'Attendance Management Alert' -> Chat-Chunk Cluster 0 (Workforce & HR Management)\n",
      "\n",
      "=== TESTING 10 CHAT-CHUNKS ===\n",
      "\n",
      "--- Chat-Chunk 1 ---\n",
      "Chat-Chunk ID: 68a8527033508dc58e3ead87\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 2 ---\n",
      "Chat-Chunk ID: 68a852a033508dc58e3eae01\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 3 ---\n",
      "Chat-Chunk ID: 68a852eb33508dc58e3eaec5\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 4 ---\n",
      "Chat-Chunk ID: 68a852ef33508dc58e3eaed1\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 5 ---\n",
      "Chat-Chunk ID: 68a852fe33508dc58e3eaef5\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 6 ---\n",
      "Chat-Chunk ID: 68a852fe33508dc58e3eaef6\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 7 ---\n",
      "Chat-Chunk ID: 68a852fe33508dc58e3eaef7\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 8 ---\n",
      "Chat-Chunk ID: 68a8532533508dc58e3eaf5b\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 9 ---\n",
      "Chat-Chunk ID: 68a8532533508dc58e3eaf5c\n",
      "Dominant Topic: 'Account Access Problem'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Access Problem'\n",
      "  Cluster ID: 9\n",
      "  Cluster Label: External Relations & Vendor Management\n",
      "\n",
      "--- Chat-Chunk 10 ---\n",
      "Chat-Chunk ID: 68a8529133508dc58e3eadda\n",
      "Dominant Topic: 'Account Management Strategy'\n",
      "✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: 'Account Management Strategy'\n",
      "  Cluster ID: 8\n",
      "  Cluster Label: Customer & Sales Strategy\n",
      "\n",
      "--- Processing Options ---\n",
      "1. Dry run (see what would be updated)\n",
      "2. Live processing (actually add keyphrase field)\n",
      "\n",
      "Starting LIVE PROCESSING for chat-chunks...\n",
      "Processing 600 chat-chunks with dominant_topic\n",
      "Batch size: 600\n",
      "DRY RUN MODE: OFF\n",
      "✓ Index on dominant_topic verified for chat-chunks collection\n",
      "\n",
      "--- Processing chat-chunk batch 1 (600 chat-chunks) ---\n",
      "Generated 600 keyphrase updates for this chat-chunk batch\n",
      "✓ Updated 0 chat-chunks with keyphrase field\n",
      "Progress: 600/600 (297.3 chat-chunks/sec)\n",
      "\n",
      "--- Final Results ---\n",
      "Total chat-chunks processed: 600\n",
      "Chat-chunks with matching keyphrases: 600\n",
      "Total updates made: 0\n",
      "Match rate: 100.0%\n",
      "Processing time: 2.26 seconds\n",
      "Processing rate: 265.5 chat-chunks/second\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient, UpdateOne\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class ChatChunkClusterKeyphraseUpdater:\n",
    "    def __init__(self, connection_string: str, database_name: str):\n",
    "        \"\"\"Initialize the updater with MongoDB connection\"\"\"\n",
    "        self.client = MongoClient(connection_string)\n",
    "        self.db = self.client[database_name]\n",
    "        self.chat_chunks_collection = self.db['chat-chunks']\n",
    "        self.clusters_collection = self.db['cluster']\n",
    "        \n",
    "        # Cache for keyphrase -> cluster mapping (ONLY chat-chunk cluster level)\n",
    "        self._keyphrase_to_cluster = {}\n",
    "        self._load_keyphrase_cache()\n",
    "    \n",
    "    def _load_keyphrase_cache(self):\n",
    "        \"\"\"Load only chat-chunk cluster-level keyphrases into memory for fast lookups\"\"\"\n",
    "        print(\"Loading chat-chunk cluster keyphrase cache...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Only load clusters with data: \"chat-chunks\"\n",
    "        chat_chunk_clusters = list(self.clusters_collection.find({\"data\": \"chat-chunks\"}))\n",
    "        print(f\"Found {len(chat_chunk_clusters)} chat-chunk clusters to process\")\n",
    "        \n",
    "        for cluster in chat_chunk_clusters:\n",
    "            cluster_id = cluster.get('cluster_id')\n",
    "            dominant_label = cluster.get('dominant_label')\n",
    "            cluster_keyphrases = cluster.get('keyphrases', [])\n",
    "            \n",
    "            # Cache ONLY chat-chunk cluster-level keyphrases\n",
    "            for keyphrase in cluster_keyphrases:\n",
    "                self._keyphrase_to_cluster[keyphrase] = {\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'dominant_label': dominant_label,\n",
    "                    'matched_keyphrase': keyphrase\n",
    "                }\n",
    "        \n",
    "        cache_time = time.time() - start_time\n",
    "        print(f\"Chat-chunk cluster cache loaded in {cache_time:.2f} seconds\")\n",
    "        print(f\"Cached {len(self._keyphrase_to_cluster)} chat-chunk cluster keyphrases\")\n",
    "    \n",
    "    def find_matching_keyphrase(self, dominant_topic: str) -> Optional[Dict]:\n",
    "        \"\"\"Find the matching keyphrase for a dominant topic (chat-chunk cluster level only)\"\"\"\n",
    "        return self._keyphrase_to_cluster.get(dominant_topic)\n",
    "    \n",
    "    def process_chat_chunks_batch(self, chat_chunks: List[Dict]) -> List:\n",
    "        \"\"\"Process a batch of chat-chunks and return bulk operations\"\"\"\n",
    "        bulk_operations = []\n",
    "        \n",
    "        for chat_chunk in chat_chunks:\n",
    "            dominant_topic = chat_chunk.get('dominant_topic')\n",
    "            if not dominant_topic:\n",
    "                continue\n",
    "            \n",
    "            # Find matching keyphrase from chat-chunk clusters\n",
    "            match_info = self.find_matching_keyphrase(dominant_topic)\n",
    "            \n",
    "            if match_info:\n",
    "                update_data = {\n",
    "                    'kmeans_cluster_keyphrase': match_info['matched_keyphrase']\n",
    "                }\n",
    "                \n",
    "                bulk_operations.append(\n",
    "                    UpdateOne(\n",
    "                        {'_id': chat_chunk['_id']}, \n",
    "                        {'$set': update_data}\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        return bulk_operations\n",
    "    \n",
    "    def add_keyphrase_field(self, batch_size: int = 5000, dry_run: bool = False) -> Dict:\n",
    "        \"\"\"Add kmeans_cluster_keyphrase field to all matching chat-chunks\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Get total count\n",
    "        total_chat_chunks = self.chat_chunks_collection.count_documents({\n",
    "            \"dominant_topic\": {\"$exists\": True, \"$ne\": None}\n",
    "        })\n",
    "        \n",
    "        processed = 0\n",
    "        matched = 0\n",
    "        total_updates = 0\n",
    "        \n",
    "        print(f\"Processing {total_chat_chunks} chat-chunks with dominant_topic\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"DRY RUN MODE: {'ON' if dry_run else 'OFF'}\")\n",
    "        \n",
    "        # Create index for faster queries\n",
    "        try:\n",
    "            self.chat_chunks_collection.create_index([(\"dominant_topic\", 1)], background=True)\n",
    "            print(\"✓ Index on dominant_topic verified for chat-chunks collection\")\n",
    "        except Exception as e:\n",
    "            print(f\"Index note: {e}\")\n",
    "        \n",
    "        # Process in batches\n",
    "        cursor = self.chat_chunks_collection.find(\n",
    "            {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}},\n",
    "            projection={'dominant_topic': 1}\n",
    "        ).batch_size(batch_size)\n",
    "        \n",
    "        batch = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        for chat_chunk in cursor:\n",
    "            batch.append(chat_chunk)\n",
    "            \n",
    "            if len(batch) >= batch_size:\n",
    "                batch_count += 1\n",
    "                print(f\"\\n--- Processing chat-chunk batch {batch_count} ({len(batch)} chat-chunks) ---\")\n",
    "                \n",
    "                # Process batch\n",
    "                bulk_operations = self.process_chat_chunks_batch(batch)\n",
    "                batch_matched = len(bulk_operations)\n",
    "                matched += batch_matched\n",
    "                \n",
    "                print(f\"Generated {batch_matched} keyphrase updates for this chat-chunk batch\")\n",
    "                \n",
    "                # Execute bulk update (or skip if dry run)\n",
    "                if bulk_operations and not dry_run:\n",
    "                    try:\n",
    "                        result = self.chat_chunks_collection.bulk_write(\n",
    "                            bulk_operations, \n",
    "                            ordered=False\n",
    "                        )\n",
    "                        total_updates += result.modified_count\n",
    "                        print(f\"✓ Updated {result.modified_count} chat-chunks with keyphrase field\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Bulk write error in chat-chunk batch {batch_count}: {e}\")\n",
    "                \n",
    "                elif bulk_operations and dry_run:\n",
    "                    print(f\"DRY RUN: Would add keyphrase field to {batch_matched} chat-chunks\")\n",
    "                    # Show sample operations\n",
    "                    for i, op in enumerate(bulk_operations[:3]):\n",
    "                        keyphrase = op._doc['$set']['kmeans_cluster_keyphrase']\n",
    "                        print(f\"  Sample {i+1}: Would set keyphrase='{keyphrase}'\")\n",
    "                \n",
    "                processed += len(batch)\n",
    "                batch = []\n",
    "                \n",
    "                # Progress update\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = processed / elapsed if elapsed > 0 else 0\n",
    "                print(f\"Progress: {processed}/{total_chat_chunks} ({rate:.1f} chat-chunks/sec)\")\n",
    "        \n",
    "        # Process remaining chat-chunks in final batch\n",
    "        if batch:\n",
    "            batch_count += 1\n",
    "            print(f\"\\n--- Processing final chat-chunk batch {batch_count} ({len(batch)} chat-chunks) ---\")\n",
    "            \n",
    "            bulk_operations = self.process_chat_chunks_batch(batch)\n",
    "            batch_matched = len(bulk_operations)\n",
    "            matched += batch_matched\n",
    "            \n",
    "            print(f\"Generated {batch_matched} keyphrase updates for final chat-chunk batch\")\n",
    "            \n",
    "            if bulk_operations and not dry_run:\n",
    "                try:\n",
    "                    result = self.chat_chunks_collection.bulk_write(\n",
    "                        bulk_operations, \n",
    "                        ordered=False\n",
    "                    )\n",
    "                    total_updates += result.modified_count\n",
    "                    print(f\"✓ Updated {result.modified_count} chat-chunks in final batch\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Bulk write error in final chat-chunk batch: {e}\")\n",
    "            elif bulk_operations and dry_run:\n",
    "                print(f\"DRY RUN: Would add keyphrase field to {batch_matched} chat-chunks\")\n",
    "            \n",
    "            processed += len(batch)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Final verification\n",
    "        if not dry_run and total_updates > 0:\n",
    "            print(f\"\\n--- Verification ---\")\n",
    "            keyphrase_count = self.chat_chunks_collection.count_documents({\n",
    "                \"kmeans_cluster_keyphrase\": {\"$exists\": True}\n",
    "            })\n",
    "            print(f\"Total chat-chunks with kmeans_cluster_keyphrase: {keyphrase_count}\")\n",
    "            \n",
    "            # Show some sample results\n",
    "            samples = list(self.chat_chunks_collection.find(\n",
    "                {\"kmeans_cluster_keyphrase\": {\"$exists\": True}},\n",
    "                {\"dominant_topic\": 1, \"kmeans_cluster_keyphrase\": 1}\n",
    "            ).limit(5))\n",
    "            \n",
    "            print(f\"\\nSample chat-chunk results:\")\n",
    "            for i, sample in enumerate(samples, 1):\n",
    "                print(f\"  {i}. Topic: '{sample.get('dominant_topic')}' -> \"\n",
    "                      f\"Keyphrase: '{sample.get('kmeans_cluster_keyphrase')}'\")\n",
    "        \n",
    "        stats = {\n",
    "            'total_chat_chunks_processed': processed,\n",
    "            'chat_chunks_matched': matched,\n",
    "            'total_updates': total_updates,\n",
    "            'processing_time': total_time,\n",
    "            'chat_chunks_per_second': processed / total_time if total_time > 0 else 0,\n",
    "            'match_rate': (matched / processed * 100) if processed > 0 else 0,\n",
    "            'dry_run': dry_run\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def debug_keyphrase_matching(self, limit: int = 10) -> None:\n",
    "        \"\"\"Debug the keyphrase matching process for chat-chunks\"\"\"\n",
    "        print(\"\\n=== DEBUGGING CHAT-CHUNK CLUSTER KEYPHRASE MATCHING ===\")\n",
    "        \n",
    "        # Check cache\n",
    "        if not self._keyphrase_to_cluster:\n",
    "            print(\"❌ NO CHAT-CHUNK CLUSTER KEYPHRASE CACHE DATA!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✓ Chat-chunk cluster keyphrase cache: {len(self._keyphrase_to_cluster)} entries\")\n",
    "        \n",
    "        # Show sample keyphrases\n",
    "        print(f\"\\nSample chat-chunk cluster keyphrases:\")\n",
    "        for i, (keyphrase, info) in enumerate(list(self._keyphrase_to_cluster.items())[:10]):\n",
    "            print(f\"  {i+1}. '{keyphrase}' -> Chat-Chunk Cluster {info['cluster_id']} ({info['dominant_label']})\")\n",
    "        \n",
    "        # Test with actual chat-chunks\n",
    "        print(f\"\\n=== TESTING {limit} CHAT-CHUNKS ===\")\n",
    "        chat_chunks = list(self.chat_chunks_collection.find(\n",
    "            {\"dominant_topic\": {\"$exists\": True, \"$ne\": None}}\n",
    "        ).limit(limit))\n",
    "        \n",
    "        if not chat_chunks:\n",
    "            print(\"❌ NO CHAT-CHUNKS with dominant_topic found!\")\n",
    "            return\n",
    "        \n",
    "        for i, chat_chunk in enumerate(chat_chunks, 1):\n",
    "            dominant_topic = chat_chunk.get('dominant_topic', 'NO_TOPIC')\n",
    "            print(f\"\\n--- Chat-Chunk {i} ---\")\n",
    "            print(f\"Chat-Chunk ID: {chat_chunk['_id']}\")\n",
    "            print(f\"Dominant Topic: '{dominant_topic}'\")\n",
    "            \n",
    "            # Test keyphrase matching\n",
    "            match_info = self.find_matching_keyphrase(dominant_topic)\n",
    "            if match_info:\n",
    "                print(f\"✓ CHAT-CHUNK CLUSTER KEYPHRASE MATCH: '{match_info['matched_keyphrase']}'\")\n",
    "                print(f\"  Cluster ID: {match_info['cluster_id']}\")\n",
    "                print(f\"  Cluster Label: {match_info['dominant_label']}\")\n",
    "            else:\n",
    "                print(f\"❌ No chat-chunk cluster keyphrase match for '{dominant_topic}'\")\n",
    "    \n",
    "    def get_keyphrase_stats(self) -> Dict:\n",
    "        \"\"\"Get statistics about keyphrase matching for chat-chunks\"\"\"\n",
    "        # Count chat-chunks with dominant_topic\n",
    "        chat_chunks_with_topic = self.chat_chunks_collection.count_documents({\n",
    "            \"dominant_topic\": {\"$exists\": True, \"$ne\": None}\n",
    "        })\n",
    "        \n",
    "        # Count chat-chunks already with keyphrase field\n",
    "        chat_chunks_with_keyphrase = self.chat_chunks_collection.count_documents({\n",
    "            \"kmeans_cluster_keyphrase\": {\"$exists\": True}\n",
    "        })\n",
    "        \n",
    "        # Get unique dominant topics and check match rates\n",
    "        unique_topics = self.chat_chunks_collection.distinct(\"dominant_topic\")\n",
    "        unique_topics = [topic for topic in unique_topics if topic is not None]\n",
    "        \n",
    "        matchable_topics = 0\n",
    "        for topic in unique_topics:\n",
    "            if self.find_matching_keyphrase(topic):\n",
    "                matchable_topics += 1\n",
    "        \n",
    "        # Count chat-chunk clusters\n",
    "        total_chat_chunk_clusters = self.clusters_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "        \n",
    "        return {\n",
    "            'total_chat_chunks_with_topic': chat_chunks_with_topic,\n",
    "            'chat_chunks_with_keyphrase_field': chat_chunks_with_keyphrase,\n",
    "            'unique_dominant_topics': len(unique_topics),\n",
    "            'matchable_topics': matchable_topics,\n",
    "            'topic_match_rate': (matchable_topics / len(unique_topics) * 100) if unique_topics else 0,\n",
    "            'cached_chat_chunk_cluster_keyphrases': len(self._keyphrase_to_cluster),\n",
    "            'total_chat_chunk_clusters': total_chat_chunk_clusters\n",
    "        }\n",
    "    \n",
    "    def close_connection(self):\n",
    "        \"\"\"Close MongoDB connection\"\"\"\n",
    "        self.client.close()\n",
    "\n",
    "def main():\n",
    "    # Get configuration from environment variables\n",
    "    CONNECTION_STRING = os.getenv('MONGO_CONNECTION_STRING')\n",
    "    DATABASE_NAME = os.getenv('MONGO_DATABASE_NAME')\n",
    "    \n",
    "    if not CONNECTION_STRING:\n",
    "        raise ValueError(\"MONGO_CONNECTION_STRING not found in environment variables\")\n",
    "    if not DATABASE_NAME:\n",
    "        raise ValueError(\"MONGO_DATABASE_NAME not found in environment variables\")\n",
    "    \n",
    "    print(f\"Connecting to database: {DATABASE_NAME}\")\n",
    "    print(\"Processing chat-chunks with chat-chunk clusters (data: 'chat-chunks')\")\n",
    "    \n",
    "    # Initialize chat-chunk keyphrase updater\n",
    "    updater = ChatChunkClusterKeyphraseUpdater(CONNECTION_STRING, DATABASE_NAME)\n",
    "    \n",
    "    try:\n",
    "        # Show current statistics\n",
    "        print(\"\\n--- Current Chat-Chunk Statistics ---\")\n",
    "        stats = updater.get_keyphrase_stats()\n",
    "        for key, value in stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{key}: {value:.1f}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value:,}\")\n",
    "        \n",
    "        # Check if we have chat-chunk clusters\n",
    "        if stats['total_chat_chunk_clusters'] == 0:\n",
    "            print(\"\\n❌ No chat-chunk clusters found (data: 'chat-chunks')!\")\n",
    "            print(\"Please ensure you have clusters with data: 'chat-chunks' before running this script.\")\n",
    "            return\n",
    "        \n",
    "        # Debug keyphrase matching\n",
    "        print(\"\\n--- Debug Mode ---\")\n",
    "        debug_choice = input(\"Run debug mode to see chat-chunk keyphrase matching? (y/n): \")\n",
    "        if debug_choice.lower() == 'y':\n",
    "            updater.debug_keyphrase_matching()\n",
    "        \n",
    "        # Choose processing mode\n",
    "        print(\"\\n--- Processing Options ---\")\n",
    "        print(\"1. Dry run (see what would be updated)\")\n",
    "        print(\"2. Live processing (actually add keyphrase field)\")\n",
    "        choice = input(\"Choose option (1 or 2): \")\n",
    "        \n",
    "        if choice in ['1', '2']:\n",
    "            dry_run = (choice == '1')\n",
    "            \n",
    "            print(f\"\\nStarting {'DRY RUN' if dry_run else 'LIVE PROCESSING'} for chat-chunks...\")\n",
    "            \n",
    "            # Get batch size\n",
    "            batch_size = int(input(\"Enter batch size (recommended: 5000): \") or \"5000\")\n",
    "            \n",
    "            # Process chat-chunks\n",
    "            results = updater.add_keyphrase_field(batch_size=batch_size, dry_run=dry_run)\n",
    "            \n",
    "            print(\"\\n--- Final Results ---\")\n",
    "            print(f\"Total chat-chunks processed: {results['total_chat_chunks_processed']:,}\")\n",
    "            print(f\"Chat-chunks with matching keyphrases: {results['chat_chunks_matched']:,}\")\n",
    "            print(f\"Total updates made: {results['total_updates']:,}\")\n",
    "            print(f\"Match rate: {results['match_rate']:.1f}%\")\n",
    "            print(f\"Processing time: {results['processing_time']:.2f} seconds\")\n",
    "            print(f\"Processing rate: {results['chat_chunks_per_second']:.1f} chat-chunks/second\")\n",
    "            \n",
    "            if not dry_run and results['total_updates'] > 0:\n",
    "                print(f\"\\n✅ Successfully added kmeans_cluster_keyphrase field to {results['total_updates']:,} chat-chunks!\")\n",
    "            elif dry_run:\n",
    "                print(f\"\\nDRY RUN COMPLETE: Would add keyphrase field to {results['chat_chunks_matched']:,} chat-chunks\")\n",
    "        \n",
    "    finally:\n",
    "        updater.close_connection()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8580d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chat-chunks in collection: 600\n",
      "Matched chat-chunks: 600\n",
      "Modified chat-chunks: 0\n",
      "Successfully updated all 600 chat-chunks!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "MONGO_CONNECTION_STRING = os.getenv('MONGO_CONNECTION_STRING')\n",
    "MONGO_DATABASE_NAME = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not MONGO_CONNECTION_STRING or not MONGO_DATABASE_NAME:\n",
    "    raise ValueError(\"Please set MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME in your environment variables\")\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = client[MONGO_DATABASE_NAME]\n",
    "collection = db['chat-chunks']\n",
    "\n",
    "try:\n",
    "    # First, get the total count of chat-chunks\n",
    "    total_chat_chunks = collection.count_documents({})\n",
    "    print(f\"Total chat-chunks in collection: {total_chat_chunks}\")\n",
    "    \n",
    "    # Add domain field to all chat-chunks\n",
    "    result = collection.update_many(\n",
    "        {},  # Empty filter to match all documents\n",
    "        {\"$set\": {\"domain\": \"banking\"}}\n",
    "    )\n",
    "    \n",
    "    print(f\"Matched chat-chunks: {result.matched_count}\")\n",
    "    print(f\"Modified chat-chunks: {result.modified_count}\")\n",
    "    \n",
    "    if result.matched_count == total_chat_chunks:\n",
    "        print(f\"Successfully updated all {total_chat_chunks} chat-chunks!\")\n",
    "    else:\n",
    "        print(f\"Expected {total_chat_chunks} chat-chunks, but matched {result.matched_count}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the connection\n",
    "    client.close()\n",
    "\n",
    "# Alternative: Add domain field only to chat-chunks that don't already have it\n",
    "def add_domain_conditionally():\n",
    "    try:\n",
    "        # Count chat-chunks without domain field\n",
    "        chat_chunks_without_domain = collection.count_documents({\"domain\": {\"$exists\": False}})\n",
    "        print(f\"Chat-chunks without domain field: {chat_chunks_without_domain}\")\n",
    "        \n",
    "        if chat_chunks_without_domain == 0:\n",
    "            print(\"All chat-chunks already have domain field!\")\n",
    "            return\n",
    "        \n",
    "        result = collection.update_many(\n",
    "            {\"domain\": {\"$exists\": False}},  # Only chat-chunks without 'domain' field\n",
    "            {\"$set\": {\"domain\": \"banking\"}}\n",
    "        )\n",
    "        \n",
    "        print(f\"Chat-chunks matched for update: {result.matched_count}\")\n",
    "        print(f\"Modified chat-chunks: {result.modified_count}\")\n",
    "        \n",
    "        if result.modified_count > 0:\n",
    "            print(f\"Successfully added domain field to {result.modified_count} chat-chunks!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Function to verify domain field addition\n",
    "def verify_domain_update():\n",
    "    try:\n",
    "        # Count chat-chunks with domain field\n",
    "        chat_chunks_with_domain = collection.count_documents({\"domain\": {\"$exists\": True}})\n",
    "        total_chat_chunks = collection.count_documents({})\n",
    "        \n",
    "        print(f\"\\n--- Verification ---\")\n",
    "        print(f\"Total chat-chunks: {total_chat_chunks}\")\n",
    "        print(f\"Chat-chunks with domain field: {chat_chunks_with_domain}\")\n",
    "        print(f\"Chat-chunks without domain field: {total_chat_chunks - chat_chunks_with_domain}\")\n",
    "        \n",
    "        if chat_chunks_with_domain == total_chat_chunks:\n",
    "            print(\"✅ All chat-chunks have domain field!\")\n",
    "        else:\n",
    "            print(f\"❌ {total_chat_chunks - chat_chunks_with_domain} chat-chunks still missing domain field\")\n",
    "        \n",
    "        # Show sample chat-chunks with domain field\n",
    "        sample_chat_chunks = list(collection.find({\"domain\": {\"$exists\": True}}).limit(3))\n",
    "        if sample_chat_chunks:\n",
    "            print(f\"\\nSample chat-chunks with domain field:\")\n",
    "            for i, chat_chunk in enumerate(sample_chat_chunks, 1):\n",
    "                print(f\"  {i}. ID: {chat_chunk['_id']}, Domain: {chat_chunk.get('domain')}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during verification: {e}\")\n",
    "\n",
    "# Uncomment the line below if you want to run the conditional update instead\n",
    "# add_domain_conditionally()\n",
    "\n",
    "# Uncomment the line below to verify the domain field addition\n",
    "# verify_domain_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9610d68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MongoDB...\n",
      "Database: sparzaai\n",
      "Collection: chat-chunks\n",
      "============================================================\n",
      "✓ Database connection successful\n",
      "Sample chat-chunk fields: ['_id', 'chat_id', 'chat_members', 'dominant_topic', 'subtopics', 'raw_segments', 'embeddings', 'kmeans_cluster_id', 'subcluster_id', 'subcluster_label', 'dominant_cluster_label', 'kmeans_cluster_keyphrase', 'domain']\n",
      "\n",
      "Analyzing current urgency values...\n",
      "----------------------------------------\n",
      "Unique urgency values found: []\n",
      "\n",
      "Total chat-chunks: 600\n",
      "Urgency distribution:\n",
      "  'null/missing': 600 chat-chunks (100.0%)\n",
      "\n",
      "This will update urgency values:\n",
      "  'Critical' → true\n",
      "  'High' → false\n",
      "\n",
      "Starting urgency field update...\n",
      "Conversion rules:\n",
      "  'Critical' → true\n",
      "  'High' → false\n",
      "----------------------------------------\n",
      "✓ Updated 'Critical' urgency:\n",
      "  Matched: 0\n",
      "  Modified: 0\n",
      "✓ Updated 'High' urgency:\n",
      "  Matched: 0\n",
      "  Modified: 0\n",
      "\n",
      "Total chat-chunks updated: 0\n",
      "\n",
      "==================================================\n",
      "VERIFICATION OF URGENCY CONVERSION\n",
      "==================================================\n",
      "Boolean urgency values:\n",
      "  urgency: true → 0 chat-chunks\n",
      "  urgency: false → 0 chat-chunks\n",
      "\n",
      "Remaining string values:\n",
      "  urgency: 'Critical' → 0 chat-chunks\n",
      "  urgency: 'High' → 0 chat-chunks\n",
      "\n",
      "Other urgency values:\n",
      "  urgency: 'null/missing' → 600 chat-chunks\n",
      "\n",
      "Sample chat-chunks with boolean urgency:\n",
      "\n",
      "✅ SUCCESS: All 'Critical' and 'High' urgency values converted to boolean!\n",
      "Summary: 0 critical (true) + 0 high (false) = 0 total\n",
      "\n",
      "==================================================\n",
      "HANDLING OTHER URGENCY VALUES\n",
      "==================================================\n",
      "Found chat-chunks with other urgency values:\n",
      "  'null/missing': 600 chat-chunks\n",
      "\n",
      "Sample chat-chunks with other urgency values:\n",
      "  1. 68a8525133508dc58e3ead33: urgency=None, priority='N/A'\n",
      "     Content: N/A\n",
      "  2. 68a8525133508dc58e3ead34: urgency=None, priority='N/A'\n",
      "     Content: N/A\n",
      "  3. 68a8525133508dc58e3ead35: urgency=None, priority='N/A'\n",
      "     Content: N/A\n",
      "\n",
      "============================================================\n",
      "✅ URGENCY CONVERSION COMPLETED SUCCESSFULLY!\n",
      "Summary:\n",
      "  Critical chat-chunks (now true): 0\n",
      "  High chat-chunks (now false): 0\n",
      "  Total chat-chunks updated: 0\n",
      "============================================================\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not mongo_connection_string or not mongo_database_name:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "print(f\"Connecting to MongoDB...\")\n",
    "print(f\"Database: {mongo_database_name}\")\n",
    "print(\"Collection: chat-chunks\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_connection_string)\n",
    "db = client[mongo_database_name]\n",
    "chat_chunks_collection = db['chat-chunks']\n",
    "\n",
    "def analyze_urgency_values():\n",
    "    \"\"\"Analyze current urgency field values\"\"\"\n",
    "    print(\"Analyzing current urgency values...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Get all unique urgency values\n",
    "        urgency_values = chat_chunks_collection.distinct(\"urgency\")\n",
    "        print(f\"Unique urgency values found: {urgency_values}\")\n",
    "        \n",
    "        # Count each urgency value\n",
    "        urgency_stats = list(chat_chunks_collection.aggregate([\n",
    "            {\"$group\": {\"_id\": \"$urgency\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]))\n",
    "        \n",
    "        total_chat_chunks = chat_chunks_collection.count_documents({})\n",
    "        print(f\"\\nTotal chat-chunks: {total_chat_chunks}\")\n",
    "        print(f\"Urgency distribution:\")\n",
    "        \n",
    "        for stat in urgency_stats:\n",
    "            value = stat['_id'] if stat['_id'] is not None else 'null/missing'\n",
    "            count = stat['count']\n",
    "            percentage = (count / total_chat_chunks) * 100 if total_chat_chunks > 0 else 0\n",
    "            print(f\"  '{value}': {count} chat-chunks ({percentage:.1f}%)\")\n",
    "            \n",
    "        return urgency_stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing urgency values: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def update_urgency_to_boolean():\n",
    "    \"\"\"Update urgency field from string to boolean\"\"\"\n",
    "    print(\"\\nStarting urgency field update...\")\n",
    "    print(\"Conversion rules:\")\n",
    "    print(\"  'Critical' → true\")\n",
    "    print(\"  'High' → false\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Update Critical to true\n",
    "        critical_result = chat_chunks_collection.update_many(\n",
    "            {\"urgency\": \"Critical\"},\n",
    "            {\"$set\": {\"urgency\": True}}\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Updated 'Critical' urgency:\")\n",
    "        print(f\"  Matched: {critical_result.matched_count}\")\n",
    "        print(f\"  Modified: {critical_result.modified_count}\")\n",
    "        \n",
    "        # Update High to false\n",
    "        high_result = chat_chunks_collection.update_many(\n",
    "            {\"urgency\": \"High\"},\n",
    "            {\"$set\": {\"urgency\": False}}\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Updated 'High' urgency:\")\n",
    "        print(f\"  Matched: {high_result.matched_count}\")\n",
    "        print(f\"  Modified: {high_result.modified_count}\")\n",
    "        \n",
    "        total_updated = critical_result.modified_count + high_result.modified_count\n",
    "        print(f\"\\nTotal chat-chunks updated: {total_updated}\")\n",
    "        \n",
    "        return {\n",
    "            'critical_updated': critical_result.modified_count,\n",
    "            'high_updated': high_result.modified_count,\n",
    "            'total_updated': total_updated\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating urgency values: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def verify_boolean_conversion():\n",
    "    \"\"\"Verify that urgency values are now boolean\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"VERIFICATION OF URGENCY CONVERSION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Count boolean urgency values\n",
    "        true_count = chat_chunks_collection.count_documents({\"urgency\": True})\n",
    "        false_count = chat_chunks_collection.count_documents({\"urgency\": False})\n",
    "        \n",
    "        # Count any remaining string values\n",
    "        critical_count = chat_chunks_collection.count_documents({\"urgency\": \"Critical\"})\n",
    "        high_count = chat_chunks_collection.count_documents({\"urgency\": \"High\"})\n",
    "        \n",
    "        # Count other values\n",
    "        other_urgency = list(chat_chunks_collection.aggregate([\n",
    "            {\"$match\": {\"urgency\": {\"$nin\": [True, False, \"Critical\", \"High\"]}}},\n",
    "            {\"$group\": {\"_id\": \"$urgency\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]))\n",
    "        \n",
    "        print(f\"Boolean urgency values:\")\n",
    "        print(f\"  urgency: true → {true_count} chat-chunks\")\n",
    "        print(f\"  urgency: false → {false_count} chat-chunks\")\n",
    "        \n",
    "        print(f\"\\nRemaining string values:\")\n",
    "        print(f\"  urgency: 'Critical' → {critical_count} chat-chunks\")\n",
    "        print(f\"  urgency: 'High' → {high_count} chat-chunks\")\n",
    "        \n",
    "        if other_urgency:\n",
    "            print(f\"\\nOther urgency values:\")\n",
    "            for other in other_urgency:\n",
    "                value = other['_id'] if other['_id'] is not None else 'null/missing'\n",
    "                count = other['count']\n",
    "                print(f\"  urgency: '{value}' → {count} chat-chunks\")\n",
    "        \n",
    "        # Show sample chat-chunks with boolean urgency\n",
    "        print(f\"\\nSample chat-chunks with boolean urgency:\")\n",
    "        samples = list(chat_chunks_collection.find(\n",
    "            {\"urgency\": {\"$in\": [True, False]}},\n",
    "            {\n",
    "                \"chunk_id\": 1,\n",
    "                \"urgency\": 1,\n",
    "                \"priority\": 1,\n",
    "                \"content\": 1\n",
    "            }\n",
    "        ).limit(5))\n",
    "        \n",
    "        for i, sample in enumerate(samples, 1):\n",
    "            chunk_id = sample.get('chunk_id', sample.get('_id', 'N/A'))\n",
    "            urgency = sample.get('urgency')\n",
    "            priority = sample.get('priority', 'N/A')\n",
    "            content = sample.get('content', 'N/A')[:50] + '...' if len(sample.get('content', '')) > 50 else sample.get('content', 'N/A')\n",
    "            \n",
    "            print(f\"  {i}. {chunk_id}: urgency={urgency}, priority='{priority}'\")\n",
    "            print(f\"     Content: {content}\")\n",
    "        \n",
    "        # Success check\n",
    "        if critical_count == 0 and high_count == 0:\n",
    "            print(f\"\\n✅ SUCCESS: All 'Critical' and 'High' urgency values converted to boolean!\")\n",
    "            print(f\"Summary: {true_count} critical (true) + {false_count} high (false) = {true_count + false_count} total\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ WARNING: Some string urgency values remain\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during verification: {str(e)}\")\n",
    "\n",
    "def handle_other_urgency_values():\n",
    "    \"\"\"Check and optionally handle other urgency values\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"HANDLING OTHER URGENCY VALUES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Find chat-chunks with urgency values other than True/False/Critical/High\n",
    "        other_urgency = list(chat_chunks_collection.aggregate([\n",
    "            {\"$match\": {\"urgency\": {\"$nin\": [True, False, \"Critical\", \"High\"]}}},\n",
    "            {\"$group\": {\"_id\": \"$urgency\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]))\n",
    "        \n",
    "        if not other_urgency:\n",
    "            print(\"No other urgency values found - all chat-chunks have been processed!\")\n",
    "            return\n",
    "        \n",
    "        print(\"Found chat-chunks with other urgency values:\")\n",
    "        for other in other_urgency:\n",
    "            value = other['_id'] if other['_id'] is not None else 'null/missing'\n",
    "            count = other['count']\n",
    "            print(f\"  '{value}': {count} chat-chunks\")\n",
    "        \n",
    "        print(f\"\\nSample chat-chunks with other urgency values:\")\n",
    "        samples = list(chat_chunks_collection.find(\n",
    "            {\"urgency\": {\"$nin\": [True, False, \"Critical\", \"High\"]}},\n",
    "            {\n",
    "                \"chunk_id\": 1,\n",
    "                \"urgency\": 1,\n",
    "                \"priority\": 1,\n",
    "                \"content\": 1\n",
    "            }\n",
    "        ).limit(3))\n",
    "        \n",
    "        for i, sample in enumerate(samples, 1):\n",
    "            chunk_id = sample.get('chunk_id', sample.get('_id', 'N/A'))\n",
    "            urgency = sample.get('urgency')\n",
    "            priority = sample.get('priority', 'N/A')\n",
    "            content = sample.get('content', 'N/A')[:50] + '...' if len(sample.get('content', '')) > 50 else sample.get('content', 'N/A')\n",
    "            \n",
    "            print(f\"  {i}. {chunk_id}: urgency={urgency}, priority='{priority}'\")\n",
    "            print(f\"     Content: {content}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error handling other urgency values: {str(e)}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Test database connection\n",
    "        test_chat_chunk = chat_chunks_collection.find_one()\n",
    "        if test_chat_chunk:\n",
    "            print(\"✓ Database connection successful\")\n",
    "            print(f\"Sample chat-chunk fields: {list(test_chat_chunk.keys())}\\n\")\n",
    "        else:\n",
    "            print(\"⚠ No chat-chunks found in chat-chunks collection\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Analyze current urgency values\n",
    "        analyze_urgency_values()\n",
    "        \n",
    "        # Confirm before proceeding\n",
    "        print(f\"\\nThis will update urgency values:\")\n",
    "        print(f\"  'Critical' → true\")\n",
    "        print(f\"  'High' → false\")\n",
    "        \n",
    "        confirm = input(f\"\\nProceed with urgency conversion? (y/n): \")\n",
    "        if confirm.lower() != 'y':\n",
    "            print(\"Operation cancelled.\")\n",
    "            exit(0)\n",
    "        \n",
    "        # Execute the urgency update\n",
    "        update_result = update_urgency_to_boolean()\n",
    "        \n",
    "        if update_result:\n",
    "            # Verify the conversion\n",
    "            verify_boolean_conversion()\n",
    "            \n",
    "            # Handle other urgency values\n",
    "            handle_other_urgency_values()\n",
    "            \n",
    "            print(f\"\\n\" + \"=\" * 60)\n",
    "            print(\"✅ URGENCY CONVERSION COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\"Summary:\")\n",
    "            print(f\"  Critical chat-chunks (now true): {update_result['critical_updated']}\")\n",
    "            print(f\"  High chat-chunks (now false): {update_result['high_updated']}\")\n",
    "            print(f\"  Total chat-chunks updated: {update_result['total_updated']}\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during execution: {str(e)}\")\n",
    "        print(\"Please check your environment variables and database connection.\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1df49ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MongoDB...\n",
      "Database: sparzaai\n",
      "Collection: chat-chunks\n",
      "============================================================\n",
      "✓ Database connection successful\n",
      "Sample chat-chunk fields: ['_id', 'chat_id', 'chat_members', 'dominant_topic', 'subtopics', 'raw_segments', 'embeddings', 'kmeans_cluster_id', 'subcluster_id', 'subcluster_label', 'dominant_cluster_label', 'kmeans_cluster_keyphrase', 'domain']\n",
      "\n",
      "Analyzing current subcluster_id values...\n",
      "----------------------------------------\n",
      "Unique subcluster_id values found: [0, 1, 2]\n",
      "\n",
      "Total chat-chunks: 600\n",
      "Subcluster_id distribution:\n",
      "  '1' (type: int): 305 chat-chunks (50.8%)\n",
      "  '0' (type: int): 276 chat-chunks (46.0%)\n",
      "  '2' (type: int): 19 chat-chunks (3.2%)\n",
      "\n",
      "This will convert all integer subcluster_id values to strings\n",
      "Example: subcluster_id: 1 → subcluster_id: \"1\"\n",
      "\n",
      "Starting subcluster_id field update...\n",
      "Conversion rule: All integer values → string values\n",
      "----------------------------------------\n",
      "Found 600 chat-chunks with integer subcluster_id\n",
      "✓ Updated subcluster_id from integer to string:\n",
      "  Total processed: 600\n",
      "  Successfully updated: 600\n",
      "\n",
      "==================================================\n",
      "VERIFICATION OF SUBCLUSTER_ID CONVERSION\n",
      "==================================================\n",
      "Subcluster_id by data type:\n",
      "  string: 600 chat-chunks\n",
      "\n",
      "Sample chat-chunks with string subcluster_id:\n",
      "  1. 68a8525133508dc58e3ead33: subcluster_id=\"0\"\n",
      "     Content: N/A\n",
      "  2. 68a8525133508dc58e3ead34: subcluster_id=\"1\"\n",
      "     Content: N/A\n",
      "  3. 68a8525133508dc58e3ead35: subcluster_id=\"1\"\n",
      "     Content: N/A\n",
      "  4. 68a8525233508dc58e3ead36: subcluster_id=\"1\"\n",
      "     Content: N/A\n",
      "  5. 68a8525233508dc58e3ead37: subcluster_id=\"0\"\n",
      "     Content: N/A\n",
      "\n",
      "✅ SUCCESS: All integer subcluster_id values converted to strings!\n",
      "Summary: 600 chat-chunks now have string subcluster_id\n",
      "\n",
      "==================================================\n",
      "CHECKING FOR OTHER SUBCLUSTER_ID VALUES\n",
      "==================================================\n",
      "All chat-chunks have valid subcluster_id values!\n",
      "\n",
      "============================================================\n",
      "✅ SUBCLUSTER_ID CONVERSION COMPLETED SUCCESSFULLY!\n",
      "Summary:\n",
      "  Total chat-chunks updated: 600\n",
      "  All integer subcluster_id values converted to strings\n",
      "============================================================\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not mongo_connection_string or not mongo_database_name:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "print(f\"Connecting to MongoDB...\")\n",
    "print(f\"Database: {mongo_database_name}\")\n",
    "print(\"Collection: chat-chunks\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_connection_string)\n",
    "db = client[mongo_database_name]\n",
    "chat_chunks_collection = db['chat-chunks']\n",
    "\n",
    "def analyze_subcluster_id_values():\n",
    "    \"\"\"Analyze current subcluster_id field values\"\"\"\n",
    "    print(\"Analyzing current subcluster_id values...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Get all unique subcluster_id values\n",
    "        subcluster_values = chat_chunks_collection.distinct(\"subcluster_id\")\n",
    "        print(f\"Unique subcluster_id values found: {subcluster_values}\")\n",
    "        \n",
    "        # Count each subcluster_id value type\n",
    "        subcluster_stats = list(chat_chunks_collection.aggregate([\n",
    "            {\"$group\": {\n",
    "                \"_id\": {\"value\": \"$subcluster_id\", \"type\": {\"$type\": \"$subcluster_id\"}}, \n",
    "                \"count\": {\"$sum\": 1}\n",
    "            }},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]))\n",
    "        \n",
    "        total_chat_chunks = chat_chunks_collection.count_documents({})\n",
    "        print(f\"\\nTotal chat-chunks: {total_chat_chunks}\")\n",
    "        print(f\"Subcluster_id distribution:\")\n",
    "        \n",
    "        for stat in subcluster_stats:\n",
    "            value = stat['_id']['value'] if stat['_id']['value'] is not None else 'null/missing'\n",
    "            data_type = stat['_id']['type']\n",
    "            count = stat['count']\n",
    "            percentage = (count / total_chat_chunks) * 100 if total_chat_chunks > 0 else 0\n",
    "            print(f\"  '{value}' (type: {data_type}): {count} chat-chunks ({percentage:.1f}%)\")\n",
    "            \n",
    "        return subcluster_stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing subcluster_id values: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def update_subcluster_id_to_string():\n",
    "    \"\"\"Update subcluster_id field from integer to string\"\"\"\n",
    "    print(\"\\nStarting subcluster_id field update...\")\n",
    "    print(\"Conversion rule: All integer values → string values\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Find all chat-chunks with integer subcluster_id\n",
    "        integer_chat_chunks = list(chat_chunks_collection.find(\n",
    "            {\"subcluster_id\": {\"$type\": \"int\"}},\n",
    "            {\"_id\": 1, \"subcluster_id\": 1}\n",
    "        ))\n",
    "        \n",
    "        print(f\"Found {len(integer_chat_chunks)} chat-chunks with integer subcluster_id\")\n",
    "        \n",
    "        updated_count = 0\n",
    "        \n",
    "        # Update each chat-chunk individually to convert integer to string\n",
    "        for chat_chunk in integer_chat_chunks:\n",
    "            old_value = chat_chunk['subcluster_id']\n",
    "            new_value = str(old_value)\n",
    "            \n",
    "            result = chat_chunks_collection.update_one(\n",
    "                {\"_id\": chat_chunk['_id']},\n",
    "                {\"$set\": {\"subcluster_id\": new_value}}\n",
    "            )\n",
    "            \n",
    "            if result.modified_count > 0:\n",
    "                updated_count += 1\n",
    "        \n",
    "        print(f\"✓ Updated subcluster_id from integer to string:\")\n",
    "        print(f\"  Total processed: {len(integer_chat_chunks)}\")\n",
    "        print(f\"  Successfully updated: {updated_count}\")\n",
    "        \n",
    "        return updated_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating subcluster_id values: {str(e)}\")\n",
    "        return 0\n",
    "\n",
    "def verify_string_conversion():\n",
    "    \"\"\"Verify that subcluster_id values are now strings\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"VERIFICATION OF SUBCLUSTER_ID CONVERSION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Count string subcluster_id values\n",
    "        string_count = chat_chunks_collection.count_documents({\"subcluster_id\": {\"$type\": \"string\"}})\n",
    "        \n",
    "        # Count any remaining integer values\n",
    "        integer_count = chat_chunks_collection.count_documents({\"subcluster_id\": {\"$type\": \"int\"}})\n",
    "        \n",
    "        # Count other data types\n",
    "        other_types = list(chat_chunks_collection.aggregate([\n",
    "            {\"$match\": {\"subcluster_id\": {\"$nin\": [None]}}},\n",
    "            {\"$group\": {\"_id\": {\"$type\": \"$subcluster_id\"}, \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}}\n",
    "        ]))\n",
    "        \n",
    "        print(f\"Subcluster_id by data type:\")\n",
    "        for type_stat in other_types:\n",
    "            data_type = type_stat['_id']\n",
    "            count = type_stat['count']\n",
    "            print(f\"  {data_type}: {count} chat-chunks\")\n",
    "        \n",
    "        # Count null/missing values\n",
    "        null_count = chat_chunks_collection.count_documents({\"subcluster_id\": None})\n",
    "        missing_count = chat_chunks_collection.count_documents({\"subcluster_id\": {\"$exists\": False}})\n",
    "        \n",
    "        if null_count > 0:\n",
    "            print(f\"  null: {null_count} chat-chunks\")\n",
    "        if missing_count > 0:\n",
    "            print(f\"  missing: {missing_count} chat-chunks\")\n",
    "        \n",
    "        # Show sample chat-chunks with string subcluster_id\n",
    "        print(f\"\\nSample chat-chunks with string subcluster_id:\")\n",
    "        samples = list(chat_chunks_collection.find(\n",
    "            {\"subcluster_id\": {\"$type\": \"string\"}},\n",
    "            {\n",
    "                \"chunk_id\": 1,\n",
    "                \"subcluster_id\": 1,\n",
    "                \"content\": 1\n",
    "            }\n",
    "        ).limit(5))\n",
    "        \n",
    "        for i, sample in enumerate(samples, 1):\n",
    "            chunk_id = sample.get('chunk_id', sample.get('_id', 'N/A'))\n",
    "            subcluster_id = sample.get('subcluster_id')\n",
    "            content = sample.get('content', 'N/A')[:50] + '...' if len(sample.get('content', '')) > 50 else sample.get('content', 'N/A')\n",
    "            \n",
    "            print(f\"  {i}. {chunk_id}: subcluster_id=\\\"{subcluster_id}\\\"\")\n",
    "            print(f\"     Content: {content}\")\n",
    "        \n",
    "        # Success check\n",
    "        if integer_count == 0:\n",
    "            print(f\"\\n✅ SUCCESS: All integer subcluster_id values converted to strings!\")\n",
    "            print(f\"Summary: {string_count} chat-chunks now have string subcluster_id\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ WARNING: {integer_count} integer subcluster_id values remain\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during verification: {str(e)}\")\n",
    "\n",
    "def handle_other_subcluster_id_values():\n",
    "    \"\"\"Check for any unusual subcluster_id values\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"CHECKING FOR OTHER SUBCLUSTER_ID VALUES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Find chat-chunks with null or missing subcluster_id\n",
    "        null_count = chat_chunks_collection.count_documents({\"subcluster_id\": None})\n",
    "        missing_count = chat_chunks_collection.count_documents({\"subcluster_id\": {\"$exists\": False}})\n",
    "        \n",
    "        if null_count > 0:\n",
    "            print(f\"Found {null_count} chat-chunks with null subcluster_id\")\n",
    "            \n",
    "        if missing_count > 0:\n",
    "            print(f\"Found {missing_count} chat-chunks with missing subcluster_id field\")\n",
    "            \n",
    "        if null_count == 0 and missing_count == 0:\n",
    "            print(\"All chat-chunks have valid subcluster_id values!\")\n",
    "            \n",
    "        # Show sample of any problematic chat-chunks\n",
    "        if null_count > 0 or missing_count > 0:\n",
    "            print(f\"\\nSample chat-chunks with null/missing subcluster_id:\")\n",
    "            samples = list(chat_chunks_collection.find(\n",
    "                {\"$or\": [\n",
    "                    {\"subcluster_id\": None},\n",
    "                    {\"subcluster_id\": {\"$exists\": False}}\n",
    "                ]},\n",
    "                {\n",
    "                    \"chunk_id\": 1,\n",
    "                    \"subcluster_id\": 1,\n",
    "                    \"content\": 1\n",
    "                }\n",
    "            ).limit(3))\n",
    "            \n",
    "            for i, sample in enumerate(samples, 1):\n",
    "                chunk_id = sample.get('chunk_id', sample.get('_id', 'N/A'))\n",
    "                subcluster_id = sample.get('subcluster_id', 'MISSING_FIELD')\n",
    "                content = sample.get('content', 'N/A')[:50] + '...' if len(sample.get('content', '')) > 50 else sample.get('content', 'N/A')\n",
    "                \n",
    "                print(f\"  {i}. {chunk_id}: subcluster_id={subcluster_id}\")\n",
    "                print(f\"     Content: {content}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking other subcluster_id values: {str(e)}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Test database connection\n",
    "        test_chat_chunk = chat_chunks_collection.find_one()\n",
    "        if test_chat_chunk:\n",
    "            print(\"✓ Database connection successful\")\n",
    "            print(f\"Sample chat-chunk fields: {list(test_chat_chunk.keys())}\\n\")\n",
    "        else:\n",
    "            print(\"⚠ No chat-chunks found in chat-chunks collection\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Analyze current subcluster_id values\n",
    "        analyze_subcluster_id_values()\n",
    "        \n",
    "        # Confirm before proceeding\n",
    "        print(f\"\\nThis will convert all integer subcluster_id values to strings\")\n",
    "        print(f\"Example: subcluster_id: 1 → subcluster_id: \\\"1\\\"\")\n",
    "        \n",
    "        confirm = input(f\"\\nProceed with subcluster_id conversion? (y/n): \")\n",
    "        if confirm.lower() != 'y':\n",
    "            print(\"Operation cancelled.\")\n",
    "            exit(0)\n",
    "        \n",
    "        # Execute the subcluster_id update\n",
    "        updated_count = update_subcluster_id_to_string()\n",
    "        \n",
    "        if updated_count > 0:\n",
    "            # Verify the conversion\n",
    "            verify_string_conversion()\n",
    "            \n",
    "            # Handle other subcluster_id values\n",
    "            handle_other_subcluster_id_values()\n",
    "            \n",
    "            print(f\"\\n\" + \"=\" * 60)\n",
    "            print(\"✅ SUBCLUSTER_ID CONVERSION COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\"Summary:\")\n",
    "            print(f\"  Total chat-chunks updated: {updated_count}\")\n",
    "            print(f\"  All integer subcluster_id values converted to strings\")\n",
    "            print(\"=\" * 60)\n",
    "        else:\n",
    "            print(f\"\\n⚠ No updates were made. Check if subcluster_id fields are already strings or if there are no integer values.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error during execution: {str(e)}\")\n",
    "        print(\"Please check your environment variables and database connection.\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f22f4280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 documents matching criteria (data='chat-chunks' and chat_chunk_ids exists)\n",
      "Successfully updated 10 documents\n",
      "Matched 10 documents\n",
      "Verification: 10 documents now have 'chat_chunks_ids' field\n",
      "MongoDB connection closed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not mongo_connection_string or not mongo_database_name:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "def rename_field_in_cluster_collection():\n",
    "    \"\"\"\n",
    "    Rename field 'chat_chunk_ids' to 'chat_chunks_ids' in documents where data=\"chat-chunks\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        cluster_collection = db['cluster']\n",
    "       \n",
    "        # Define the filter for documents that have data=\"chat-chunks\" and chat_chunk_ids field exists\n",
    "        filter_query = {\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"chat_chunk_ids\": {\"$exists\": True}\n",
    "        }\n",
    "       \n",
    "        # Count documents that match the criteria before update\n",
    "        count_before = cluster_collection.count_documents(filter_query)\n",
    "        print(f\"Found {count_before} documents matching criteria (data='chat-chunks' and chat_chunk_ids exists)\")\n",
    "       \n",
    "        if count_before == 0:\n",
    "            print(\"No documents found to update.\")\n",
    "            return\n",
    "       \n",
    "        # Use $rename operator to rename the field\n",
    "        update_operation = {\n",
    "            \"$rename\": {\n",
    "                \"chat_chunk_ids\": \"chat_chunks_ids\"\n",
    "            }\n",
    "        }\n",
    "       \n",
    "        # Perform the update operation\n",
    "        result = cluster_collection.update_many(filter_query, update_operation)\n",
    "       \n",
    "        print(f\"Successfully updated {result.modified_count} documents\")\n",
    "        print(f\"Matched {result.matched_count} documents\")\n",
    "       \n",
    "        # Verify the update by counting documents with the new field name\n",
    "        verification_query = {\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"chat_chunks_ids\": {\"$exists\": True}\n",
    "        }\n",
    "        count_after = cluster_collection.count_documents(verification_query)\n",
    "        print(f\"Verification: {count_after} documents now have 'chat_chunks_ids' field\")\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"MongoDB connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rename_field_in_cluster_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b44b88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat-chunks keyphrase validation...\n",
      "================================================================================\n",
      "SAMPLE CHAT-CHUNKS DOCUMENT STRUCTURE:\n",
      "----------------------------------------\n",
      "Cluster ID: 0\n",
      "Cluster Name: Workforce & HR Management\n",
      "Data Type: chat-chunks\n",
      "Main keyphrases count: 12\n",
      "Subclusters count: 2\n",
      "Sample main keyphrases: ['Shift Coverage Request', 'Training Schedule Update', 'Performance Review Planning']...\n",
      "Subcluster structure:\n",
      "  0: 'Workforce Scheduling & Planning' (4 keyphrases)\n",
      "    Sample keyphrases: ['Shift Coverage Request', 'Break Schedule Coordination']...\n",
      "  1: 'Employee Development & Relations' (8 keyphrases)\n",
      "    Sample keyphrases: ['Training Schedule Update', 'Performance Review Planning']...\n",
      "Chat chunks count: 98\n",
      "----------------------------------------\n",
      "Total chat-chunks documents checked: 10\n",
      "Total missing keyphrases found: 0\n",
      "--------------------------------------------------------------------------------\n",
      "✅ All keyphrases from main field are present in subclusters for chat-chunks data!\n",
      "\n",
      "MongoDB connection closed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not mongo_connection_string or not mongo_database_name:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "def validate_keyphrases_in_subclusters():\n",
    "    \"\"\"\n",
    "    Cross-check keyphrases field with subclusters keyphrases for chat-chunks data.\n",
    "    Find any keyphrases that exist in main keyphrases but are missing from all subclusters.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        cluster_collection = db['cluster']\n",
    "        \n",
    "        # Find all documents that have both keyphrases and subclusters fields for chat-chunks data\n",
    "        query = {\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"keyphrases\": {\"$exists\": True, \"$ne\": None},\n",
    "            \"subclusters\": {\"$exists\": True, \"$ne\": None}\n",
    "        }\n",
    "        \n",
    "        documents = cluster_collection.find(query)\n",
    "        \n",
    "        missing_keyphrases = []\n",
    "        total_documents_checked = 0\n",
    "        \n",
    "        for doc in documents:\n",
    "            total_documents_checked += 1\n",
    "            cluster_id = doc.get('cluster_id')\n",
    "            main_keyphrases = doc.get('keyphrases', [])\n",
    "            subclusters = doc.get('subclusters', {})\n",
    "            \n",
    "            # Collect all keyphrases from all subclusters\n",
    "            subcluster_keyphrases = set()\n",
    "            \n",
    "            # subclusters is an object with keys like \"0\", \"1\", \"2\", etc.\n",
    "            for subcluster_key, subcluster_data in subclusters.items():\n",
    "                if isinstance(subcluster_data, dict) and 'keyphrases' in subcluster_data:\n",
    "                    subcluster_keyphrase_list = subcluster_data.get('keyphrases', [])\n",
    "                    if isinstance(subcluster_keyphrase_list, list):\n",
    "                        subcluster_keyphrases.update(subcluster_keyphrase_list)\n",
    "            \n",
    "            # Check each main keyphrase against subcluster keyphrases\n",
    "            for keyphrase in main_keyphrases:\n",
    "                if keyphrase not in subcluster_keyphrases:\n",
    "                    missing_keyphrases.append({\n",
    "                        'cluster_id': cluster_id,\n",
    "                        'missing_keyphrase': keyphrase,\n",
    "                        'total_main_keyphrases': len(main_keyphrases),\n",
    "                        'total_subcluster_keyphrases': len(subcluster_keyphrases)\n",
    "                    })\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"Total chat-chunks documents checked: {total_documents_checked}\")\n",
    "        print(f\"Total missing keyphrases found: {len(missing_keyphrases)}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        if missing_keyphrases:\n",
    "            print(\"MISSING KEYPHRASES REPORT (CHAT-CHUNKS):\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # Group by cluster_id for better readability\n",
    "            cluster_groups = {}\n",
    "            for item in missing_keyphrases:\n",
    "                cluster_id = item['cluster_id']\n",
    "                if cluster_id not in cluster_groups:\n",
    "                    cluster_groups[cluster_id] = []\n",
    "                cluster_groups[cluster_id].append(item)\n",
    "            \n",
    "            for cluster_id, missing_items in cluster_groups.items():\n",
    "                print(f\"Chat-Chunks Cluster ID: {cluster_id}\")\n",
    "                print(f\"Missing keyphrases ({len(missing_items)}):\")\n",
    "                for item in missing_items:\n",
    "                    print(f\"  - '{item['missing_keyphrase']}'\")\n",
    "                print(f\"Total main keyphrases: {missing_items[0]['total_main_keyphrases']}\")\n",
    "                print(f\"Total subcluster keyphrases: {missing_items[0]['total_subcluster_keyphrases']}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "        else:\n",
    "            print(\"✅ All keyphrases from main field are present in subclusters for chat-chunks data!\")\n",
    "            \n",
    "        # Summary statistics\n",
    "        if missing_keyphrases:\n",
    "            clusters_with_issues = len(set(item['cluster_id'] for item in missing_keyphrases))\n",
    "            print(f\"\\nSUMMARY (CHAT-CHUNKS):\")\n",
    "            print(f\"Chat-chunks clusters with missing keyphrases: {clusters_with_issues}\")\n",
    "            print(f\"Total missing keyphrase instances: {len(missing_keyphrases)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"\\nMongoDB connection closed\")\n",
    "\n",
    "def get_detailed_analysis():\n",
    "    \"\"\"\n",
    "    Get more detailed analysis including sample chat-chunks data structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        cluster_collection = db['cluster']\n",
    "        \n",
    "        # Get a sample document to understand structure for chat-chunks data\n",
    "        sample_doc = cluster_collection.find_one({\n",
    "            \"data\": \"chat-chunks\",\n",
    "            \"keyphrases\": {\"$exists\": True},\n",
    "            \"subclusters\": {\"$exists\": True}\n",
    "        })\n",
    "        \n",
    "        if sample_doc:\n",
    "            print(\"SAMPLE CHAT-CHUNKS DOCUMENT STRUCTURE:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"Cluster ID: {sample_doc.get('cluster_id')}\")\n",
    "            print(f\"Cluster Name: {sample_doc.get('cluster_name', 'N/A')}\")\n",
    "            print(f\"Data Type: {sample_doc.get('data')}\")\n",
    "            print(f\"Main keyphrases count: {len(sample_doc.get('keyphrases', []))}\")\n",
    "            \n",
    "            subclusters = sample_doc.get('subclusters', {})\n",
    "            print(f\"Subclusters count: {len(subclusters)}\")\n",
    "            \n",
    "            if sample_doc.get('keyphrases'):\n",
    "                print(f\"Sample main keyphrases: {sample_doc['keyphrases'][:3]}...\")\n",
    "            \n",
    "            if subclusters:\n",
    "                print(\"Subcluster structure:\")\n",
    "                for key, subcluster in list(subclusters.items())[:2]:  # Show first 2 subclusters\n",
    "                    if isinstance(subcluster, dict):\n",
    "                        label = subcluster.get('label', 'No label')\n",
    "                        keyphrases_count = len(subcluster.get('keyphrases', []))\n",
    "                        print(f\"  {key}: '{label}' ({keyphrases_count} keyphrases)\")\n",
    "                        if subcluster.get('keyphrases'):\n",
    "                            print(f\"    Sample keyphrases: {subcluster['keyphrases'][:2]}...\")\n",
    "            \n",
    "            # Check if chat_chunks_ids field exists\n",
    "            if 'chat_chunks_ids' in sample_doc:\n",
    "                print(f\"Chat chunks count: {len(sample_doc.get('chat_chunks_ids', []))}\")\n",
    "            elif 'chat_chunk_ids' in sample_doc:\n",
    "                print(f\"Chat chunks count: {len(sample_doc.get('chat_chunk_ids', []))}\")\n",
    "            \n",
    "            print(\"-\" * 40)\n",
    "        else:\n",
    "            print(\"No chat-chunks documents found with both keyphrases and subclusters fields.\")\n",
    "            \n",
    "            # Check what chat-chunks documents exist\n",
    "            chat_chunks_count = cluster_collection.count_documents({\"data\": \"chat-chunks\"})\n",
    "            print(f\"Total chat-chunks documents in collection: {chat_chunks_count}\")\n",
    "            \n",
    "            # Check structure of any chat-chunks document\n",
    "            any_chat_chunk_doc = cluster_collection.find_one({\"data\": \"chat-chunks\"})\n",
    "            if any_chat_chunk_doc:\n",
    "                print(\"Available fields in chat-chunks documents:\")\n",
    "                print(f\"  Fields: {list(any_chat_chunk_doc.keys())}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in detailed analysis: {str(e)}\")\n",
    "    finally:\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting chat-chunks keyphrase validation...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # First, get structure analysis\n",
    "    get_detailed_analysis()\n",
    "    \n",
    "    # Then run validation\n",
    "    validate_keyphrases_in_subclusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b30428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB Chat-Chunks subcluster_id Converter\n",
      "==================================================\n",
      "\n",
      "1. PREVIEW CHANGES FOR CHAT-CHUNKS:\n",
      "PREVIEW MODE - No changes will be made to chat-chunks\n",
      "Found 0 chat-chunks documents that would be updated:\n",
      "\n",
      "Total documents in chat-chunks collection: 600\n",
      "\n",
      "2. CONFIRMATION:\n",
      "Chat-chunks conversion cancelled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "if not mongo_connection_string or not mongo_database_name:\n",
    "    raise ValueError(\"MONGO_CONNECTION_STRING and MONGO_DATABASE_NAME must be set in environment variables\")\n",
    "\n",
    "def convert_subcluster_id_to_string():\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        collection = db['chat-chunks']\n",
    "        \n",
    "        # Find all documents where subcluster_id is an integer\n",
    "        query = {\"subcluster_id\": {\"$type\": \"number\"}}\n",
    "        documents_to_update = list(collection.find(query))\n",
    "        \n",
    "        print(f\"Found {len(documents_to_update)} chat-chunks documents with integer subcluster_id\")\n",
    "        \n",
    "        if len(documents_to_update) == 0:\n",
    "            print(\"No chat-chunks documents found with integer subcluster_id\")\n",
    "            return\n",
    "        \n",
    "        # Update each document\n",
    "        updated_count = 0\n",
    "        for doc in documents_to_update:\n",
    "            try:\n",
    "                # Convert the integer subcluster_id to string\n",
    "                new_subcluster_id = str(doc['subcluster_id'])\n",
    "                \n",
    "                # Update the document\n",
    "                result = collection.update_one(\n",
    "                    {\"_id\": doc[\"_id\"]},\n",
    "                    {\"$set\": {\"subcluster_id\": new_subcluster_id}}\n",
    "                )\n",
    "                \n",
    "                if result.modified_count > 0:\n",
    "                    updated_count += 1\n",
    "                    print(f\"Updated chat-chunk document {doc['_id']}: subcluster_id {doc['subcluster_id']} -> '{new_subcluster_id}'\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error updating chat-chunk document {doc['_id']}: {e}\")\n",
    "        \n",
    "        print(f\"\\nSummary: Successfully updated {updated_count} out of {len(documents_to_update)} chat-chunks documents\")\n",
    "        \n",
    "        # Verify the changes\n",
    "        remaining_int_docs = collection.count_documents({\"subcluster_id\": {\"$type\": \"number\"}})\n",
    "        string_docs = collection.count_documents({\"subcluster_id\": {\"$type\": \"string\"}})\n",
    "        \n",
    "        print(f\"Verification for chat-chunks collection:\")\n",
    "        print(f\"- Documents with integer subcluster_id: {remaining_int_docs}\")\n",
    "        print(f\"- Documents with string subcluster_id: {string_docs}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MongoDB or updating chat-chunks documents: {e}\")\n",
    "    finally:\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            print(\"MongoDB connection closed\")\n",
    "\n",
    "def preview_changes():\n",
    "    \"\"\"Preview what changes will be made to chat-chunks without actually updating\"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        collection = db['chat-chunks']\n",
    "        \n",
    "        # Find documents where subcluster_id is an integer\n",
    "        query = {\"subcluster_id\": {\"$type\": \"number\"}}\n",
    "        documents_to_update = list(collection.find(query, {\"_id\": 1, \"subcluster_id\": 1}))\n",
    "        \n",
    "        print(\"PREVIEW MODE - No changes will be made to chat-chunks\")\n",
    "        print(f\"Found {len(documents_to_update)} chat-chunks documents that would be updated:\")\n",
    "        \n",
    "        for i, doc in enumerate(documents_to_update[:10]):  # Show first 10\n",
    "            print(f\"  Chat-chunk document {doc['_id']}: subcluster_id {doc['subcluster_id']} -> '{str(doc['subcluster_id'])}'\")\n",
    "        \n",
    "        if len(documents_to_update) > 10:\n",
    "            print(f\"  ... and {len(documents_to_update) - 10} more chat-chunks documents\")\n",
    "        \n",
    "        # Also show total documents in collection for context\n",
    "        total_docs = collection.count_documents({})\n",
    "        print(f\"\\nTotal documents in chat-chunks collection: {total_docs}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during chat-chunks preview: {e}\")\n",
    "    finally:\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"MongoDB Chat-Chunks subcluster_id Converter\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # First, preview the changes\n",
    "    print(\"\\n1. PREVIEW CHANGES FOR CHAT-CHUNKS:\")\n",
    "    preview_changes()\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    print(\"\\n2. CONFIRMATION:\")\n",
    "    response = input(\"Do you want to proceed with the chat-chunks conversion? (yes/no): \").lower().strip()\n",
    "    \n",
    "    if response == 'yes':\n",
    "        print(\"\\n3. EXECUTING CHAT-CHUNKS CONVERSION:\")\n",
    "        convert_subcluster_id_to_string()\n",
    "    else:\n",
    "        print(\"Chat-chunks conversion cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the method to copy processed_at field:\n",
      "1. Copy based on matching document _id (recommended)\n",
      "2. Copy based on document order/position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 22:31:31,423 - INFO - Starting copy operation based on document order...\n",
      "2025-09-02 22:31:31,427 - INFO - Connected to MongoDB successfully\n",
      "2025-09-02 22:32:29,732 - INFO - Sample ticket collection has 0 documents\n",
      "2025-09-02 22:32:29,734 - INFO - Tickets collection has 2000 documents\n",
      "2025-09-02 22:32:29,735 - WARNING - Collections have different sizes. Will process 0 documents\n",
      "2025-09-02 22:32:29,735 - INFO - Successfully updated 0 documents with processed_at field\n",
      "2025-09-02 22:32:30,003 - INFO - Verification: 2000 documents in 'tickets' collection now have 'processed_at' field\n",
      "2025-09-02 22:32:30,263 - INFO - MongoDB connection closed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "def copy_processed_at_field():\n",
    "    \"\"\"\n",
    "    Copy processed_at field from 'sample ticket' collection to 'tickets' collection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        \n",
    "        # Get collections\n",
    "        sample_ticket_collection = db['sample ticket']\n",
    "        tickets_collection = db['tickets']\n",
    "        \n",
    "        logger.info(\"Connected to MongoDB successfully\")\n",
    "        \n",
    "        # Get all documents from sample ticket collection with processed_at field\n",
    "        sample_tickets = list(sample_ticket_collection.find(\n",
    "            {\"processed_at\": {\"$exists\": True}},\n",
    "            {\"_id\": 1, \"processed_at\": 1}\n",
    "        ))\n",
    "        \n",
    "        logger.info(f\"Found {len(sample_tickets)} documents with processed_at field in 'sample ticket' collection\")\n",
    "        \n",
    "        if not sample_tickets:\n",
    "            logger.warning(\"No documents found with processed_at field in 'sample ticket' collection\")\n",
    "            return\n",
    "        \n",
    "        # Create a mapping of _id to processed_at value\n",
    "        processed_at_mapping = {doc['_id']: doc['processed_at'] for doc in sample_tickets}\n",
    "        \n",
    "        # Update tickets collection\n",
    "        updated_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        for doc_id, processed_at_value in processed_at_mapping.items():\n",
    "            try:\n",
    "                # Update the document in tickets collection\n",
    "                result = tickets_collection.update_one(\n",
    "                    {\"_id\": doc_id},\n",
    "                    {\"$set\": {\"processed_at\": processed_at_value}},\n",
    "                    upsert=False  # Don't create new documents if they don't exist\n",
    "                )\n",
    "                \n",
    "                if result.matched_count > 0:\n",
    "                    updated_count += 1\n",
    "                    if updated_count % 100 == 0:  # Log progress every 100 updates\n",
    "                        logger.info(f\"Updated {updated_count} documents so far...\")\n",
    "                else:\n",
    "                    logger.warning(f\"Document with _id {doc_id} not found in tickets collection\")\n",
    "                    failed_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to update document {doc_id}: {str(e)}\")\n",
    "                failed_count += 1\n",
    "        \n",
    "        logger.info(f\"Operation completed:\")\n",
    "        logger.info(f\"- Successfully updated: {updated_count} documents\")\n",
    "        logger.info(f\"- Failed/Not found: {failed_count} documents\")\n",
    "        \n",
    "        # Verify the operation\n",
    "        verify_count = tickets_collection.count_documents({\"processed_at\": {\"$exists\": True}})\n",
    "        logger.info(f\"Verification: {verify_count} documents in 'tickets' collection now have 'processed_at' field\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        try:\n",
    "            client.close()\n",
    "            logger.info(\"MongoDB connection closed\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def copy_all_processed_at_regardless_of_id():\n",
    "    \"\"\"\n",
    "    Alternative approach: Copy processed_at values based on document order/position\n",
    "    Use this if documents don't have matching _ids between collections\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        \n",
    "        # Get collections\n",
    "        sample_ticket_collection = db['sample ticket']\n",
    "        tickets_collection = db['tickets']\n",
    "        \n",
    "        logger.info(\"Connected to MongoDB successfully\")\n",
    "        \n",
    "        # Get all documents from both collections\n",
    "        sample_tickets = list(sample_ticket_collection.find().sort(\"_id\", 1))\n",
    "        tickets = list(tickets_collection.find().sort(\"_id\", 1))\n",
    "        \n",
    "        logger.info(f\"Sample ticket collection has {len(sample_tickets)} documents\")\n",
    "        logger.info(f\"Tickets collection has {len(tickets)} documents\")\n",
    "        \n",
    "        # Ensure both collections have the same number of documents\n",
    "        min_count = min(len(sample_tickets), len(tickets))\n",
    "        \n",
    "        if len(sample_tickets) != len(tickets):\n",
    "            logger.warning(f\"Collections have different sizes. Will process {min_count} documents\")\n",
    "        \n",
    "        updated_count = 0\n",
    "        \n",
    "        # Update tickets with processed_at values from sample tickets\n",
    "        for i in range(min_count):\n",
    "            sample_doc = sample_tickets[i]\n",
    "            ticket_doc = tickets[i]\n",
    "            \n",
    "            # Check if sample document has processed_at field\n",
    "            if 'processed_at' in sample_doc:\n",
    "                try:\n",
    "                    # Update the corresponding ticket document\n",
    "                    result = tickets_collection.update_one(\n",
    "                        {\"_id\": ticket_doc['_id']},\n",
    "                        {\"$set\": {\"processed_at\": sample_doc['processed_at']}}\n",
    "                    )\n",
    "                    \n",
    "                    if result.modified_count > 0:\n",
    "                        updated_count += 1\n",
    "                        if updated_count % 100 == 0:\n",
    "                            logger.info(f\"Updated {updated_count} documents so far...\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to update document at index {i}: {str(e)}\")\n",
    "        \n",
    "        logger.info(f\"Successfully updated {updated_count} documents with processed_at field\")\n",
    "        \n",
    "        # Verify the operation\n",
    "        verify_count = tickets_collection.count_documents({\"processed_at\": {\"$exists\": True}})\n",
    "        logger.info(f\"Verification: {verify_count} documents in 'tickets' collection now have 'processed_at' field\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        try:\n",
    "            client.close()\n",
    "            logger.info(\"MongoDB connection closed\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if environment variables are set\n",
    "    if not mongo_connection_string:\n",
    "        logger.error(\"MONGO_CONNECTION_STRING environment variable is not set\")\n",
    "        exit(1)\n",
    "    \n",
    "    if not mongo_database_name:\n",
    "        logger.error(\"MONGO_DATABASE_NAME environment variable is not set\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"Choose the method to copy processed_at field:\")\n",
    "    print(\"1. Copy based on matching document _id (recommended)\")\n",
    "    print(\"2. Copy based on document order/position\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        logger.info(\"Starting copy operation based on matching _id...\")\n",
    "        copy_processed_at_field()\n",
    "    elif choice == \"2\":\n",
    "        logger.info(\"Starting copy operation based on document order...\")\n",
    "        copy_all_processed_at_regardless_of_id()\n",
    "    else:\n",
    "        logger.error(\"Invalid choice. Please run the script again and choose 1 or 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31dacf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 12:07:17,237 - INFO - Starting update process...\n",
      "2025-09-04 12:07:17,443 - INFO - Connected to MongoDB successfully\n",
      "2025-09-04 12:07:19,023 - INFO - Total documents to process: 600\n",
      "2025-09-04 12:07:19,025 - INFO - Starting bulk update operation...\n",
      "2025-09-04 12:07:19,824 - INFO - Update completed successfully!\n",
      "2025-09-04 12:07:19,825 - INFO - Documents matched: 600\n",
      "2025-09-04 12:07:19,827 - INFO - Documents modified: 600\n",
      "2025-09-04 12:07:19,829 - INFO - Verifying update with sample documents:\n",
      "2025-09-04 12:07:20,075 - INFO - Sample 1: ID=68a8525133508dc58e3ead33, raw_segments array length=9, total_messages=9\n",
      "2025-09-04 12:07:20,076 - INFO - Sample 2: ID=68a8525133508dc58e3ead34, raw_segments array length=9, total_messages=9\n",
      "2025-09-04 12:07:20,078 - INFO - Sample 3: ID=68a8525133508dc58e3ead35, raw_segments array length=9, total_messages=9\n",
      "2025-09-04 12:07:20,323 - INFO - MongoDB connection closed\n",
      "2025-09-04 12:07:20,328 - INFO - Update process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get connection details from environment variables\n",
    "mongo_connection_string = os.getenv('MONGO_CONNECTION_STRING')\n",
    "mongo_database_name = os.getenv('MONGO_DATABASE_NAME')\n",
    "\n",
    "def update_total_messages():\n",
    "    \"\"\"\n",
    "    Updates all documents in the chat-chunks collection to add a total_messages field\n",
    "    that contains the count of arrays in the raw_segments field.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        collection = db['chat-chunks']\n",
    "        \n",
    "        logger.info(\"Connected to MongoDB successfully\")\n",
    "        \n",
    "        # Get total document count for progress tracking\n",
    "        total_docs = collection.count_documents({})\n",
    "        logger.info(f\"Total documents to process: {total_docs}\")\n",
    "        \n",
    "        # Update documents using aggregation pipeline\n",
    "        # This approach is more efficient for large collections\n",
    "        update_pipeline = [\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"total_messages\": {\n",
    "                        \"$cond\": {\n",
    "                            \"if\": {\"$isArray\": \"$raw_segments\"},\n",
    "                            \"then\": {\"$size\": \"$raw_segments\"},\n",
    "                            \"else\": 0\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Execute the update\n",
    "        logger.info(\"Starting bulk update operation...\")\n",
    "        result = collection.update_many({}, update_pipeline)\n",
    "        \n",
    "        # Log results\n",
    "        logger.info(f\"Update completed successfully!\")\n",
    "        logger.info(f\"Documents matched: {result.matched_count}\")\n",
    "        logger.info(f\"Documents modified: {result.modified_count}\")\n",
    "        \n",
    "        # Verify the update with a sample\n",
    "        logger.info(\"Verifying update with sample documents:\")\n",
    "        sample_docs = collection.find({}, {\"_id\": 1, \"raw_segments\": 1, \"total_messages\": 1}).limit(3)\n",
    "        \n",
    "        for i, doc in enumerate(sample_docs, 1):\n",
    "            raw_segments_count = len(doc.get('raw_segments', [])) if doc.get('raw_segments') else 0\n",
    "            total_messages = doc.get('total_messages', 0)\n",
    "            logger.info(f\"Sample {i}: ID={doc['_id']}, raw_segments array length={raw_segments_count}, total_messages={total_messages}\")\n",
    "            \n",
    "            # Verify consistency\n",
    "            if raw_segments_count != total_messages:\n",
    "                logger.warning(f\"Mismatch found in document {doc['_id']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            logger.info(\"MongoDB connection closed\")\n",
    "\n",
    "def update_total_messages_batch_approach():\n",
    "    \"\"\"\n",
    "    Alternative approach using batch processing for very large collections\n",
    "    This processes documents in batches to avoid memory issues\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        client = MongoClient(mongo_connection_string)\n",
    "        db = client[mongo_database_name]\n",
    "        collection = db['chat-chunks']\n",
    "        \n",
    "        logger.info(\"Connected to MongoDB successfully (Batch Approach)\")\n",
    "        \n",
    "        batch_size = 1000  # Process 1000 documents at a time\n",
    "        skip = 0\n",
    "        total_processed = 0\n",
    "        \n",
    "        while True:\n",
    "            # Get batch of documents\n",
    "            documents = list(collection.find({}, {\"_id\": 1, \"raw_segments\": 1}).skip(skip).limit(batch_size))\n",
    "            \n",
    "            if not documents:\n",
    "                break\n",
    "            \n",
    "            # Prepare bulk operations\n",
    "            bulk_operations = []\n",
    "            \n",
    "            for doc in documents:\n",
    "                raw_segments = doc.get('raw_segments', [])\n",
    "                total_messages = len(raw_segments) if isinstance(raw_segments, list) else 0\n",
    "                \n",
    "                bulk_operations.append({\n",
    "                    \"updateOne\": {\n",
    "                        \"filter\": {\"_id\": doc[\"_id\"]},\n",
    "                        \"update\": {\"$set\": {\"total_messages\": total_messages}}\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # Execute bulk operations\n",
    "            if bulk_operations:\n",
    "                result = collection.bulk_write(bulk_operations)\n",
    "                total_processed += result.modified_count\n",
    "                logger.info(f\"Processed batch: {len(documents)} documents, Modified: {result.modified_count}\")\n",
    "            \n",
    "            skip += batch_size\n",
    "        \n",
    "        logger.info(f\"Batch update completed! Total documents processed: {total_processed}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in batch approach: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if 'client' in locals():\n",
    "            client.close()\n",
    "            logger.info(\"MongoDB connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Validate environment variables\n",
    "    if not mongo_connection_string:\n",
    "        logger.error(\"MONGO_CONNECTION_STRING environment variable is not set\")\n",
    "        exit(1)\n",
    "    \n",
    "    if not mongo_database_name:\n",
    "        logger.error(\"MONGO_DATABASE_NAME environment variable is not set\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Choose which approach to use\n",
    "    # For most cases, use the first approach (more efficient)\n",
    "    # For very large collections (millions of documents), consider the batch approach\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Starting update process...\")\n",
    "        update_total_messages()  # Use this for most cases\n",
    "        # update_total_messages_batch_approach()  # Uncomment for very large collections\n",
    "        logger.info(\"Update process completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Update process failed: {str(e)}\")\n",
    "        exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
